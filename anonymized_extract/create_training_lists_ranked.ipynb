{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import shutil\n",
    "# import os\n",
    "# import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "# Paths of datasets\n",
    "full_game_save_path = 'C:/Users/jaspa/Grant ML/ranked_full_subfolders'\n",
    "segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/ranked_segments_subfolders'\n",
    "segment_save_path_bulk = 'C:/Users/jaspa/Grant ML/ranked_segments_bulk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training, test, and holdout set for a particular set of charcters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/ranked_segments_subfolders'\n",
    "character_segment_counts = {'BOWSER': 9563, 'CAPTAIN_FALCON': 153832, 'DONKEY_KONG': 11970, 'DR_MARIO': 29235, 'FALCO': 424029, 'FOX': 489437, 'GAME_AND_WATCH': 14105, 'GANONDORF': 45758, 'ICE_CLIMBERS': 58698, 'JIGGLYPUFF': 138053, 'KIRBY': 3396, 'LINK': 21630, 'LUIGI': 39558, 'MARIO': 12368, 'MARTH': 249755, 'MEWTWO': 20922, 'NESS': 27592, 'PEACH': 144477, 'PICHU': 1726, 'PIKACHU': 30054, 'ROY': 9957, 'SAMUS': 85573, 'SHEIK': 189710, 'YOSHI': 41101, 'YOUNG_LINK': 12783, 'ZELDA': 3936}\n",
    "\n",
    "selected_characters = [\n",
    "    'FOX', \n",
    "    'FALCO', \n",
    "    # 'MARTH', \n",
    "    # 'SHEIK', \n",
    "    # 'CAPTAIN_FALCON', \n",
    "    # 'PEACH', \n",
    "    # 'JIGGLYPUFF', \n",
    "    # 'SAMUS', \n",
    "    # 'ICE_CLIMBERS', \n",
    "    # 'GANONDORF', \n",
    "    # 'YOSHI', \n",
    "    # 'LUIGI', \n",
    "    # 'PIKACHU', \n",
    "    # 'DR_MARIO', \n",
    "    # 'NESS', \n",
    "    # 'LINK', \n",
    "    # 'MEWTWO', \n",
    "    # 'GAME_AND_WATCH', \n",
    "    # 'DONKEY_KONG', \n",
    "    # 'YOUNG_LINK', \n",
    "    # 'MARIO', \n",
    "    # 'ROY', \n",
    "    # 'BOWSER', \n",
    "    # 'ZELDA', \n",
    "    # 'KIRBY', \n",
    "    # 'PICHU'\n",
    "    ]\n",
    "\n",
    "# Determine the minimum number of segments among the selected characters\n",
    "min_segments = min([character_segment_counts[char] for char in selected_characters])\n",
    "# min_segments = 2\n",
    "\n",
    "# Map each selected character to an integer\n",
    "char_to_int = {char: i for i, char in enumerate(selected_characters)}\n",
    "\n",
    "# Initialize a dictionary to hold file paths organized by character\n",
    "character_files = {char: [] for char in selected_characters}\n",
    "\n",
    "# Collect all file paths organized by character\n",
    "for character in selected_characters:\n",
    "    char_path = os.path.join(segment_save_path_subfolder, character)\n",
    "    for opponent in os.listdir(char_path):\n",
    "        opponent_path = os.path.join(char_path, opponent)\n",
    "        files = [os.path.join(opponent_path, file) for file in os.listdir(opponent_path)]\n",
    "        character_files[character].extend(files)\n",
    "\n",
    "# Sample min_segments for each selected character\n",
    "X = []\n",
    "y = []\n",
    "for character, files in character_files.items():\n",
    "    sampled_files = np.random.choice(files, min_segments, replace=False)\n",
    "    X.extend(sampled_files)\n",
    "    y.extend([char_to_int[character]] * min_segments)\n",
    "\n",
    "# Shuffle the dataset to mix up the order of characters\n",
    "X, y = shuffle(np.array(X), np.array(y), random_state=42)\n",
    "\n",
    "# At this point, X and y are your balanced dataset ready for further processing\n",
    "print('number of data points: ',X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/jaspa/Grant ML/slp/data/'\n",
    "\n",
    "\n",
    "with gzip.open(os.path.join(save_path,'ranked_file_paths.npy.gz'), 'wb') as f:\n",
    "    np.save(f, X)\n",
    "\n",
    "with gzip.open(os.path.join(save_path,'ranked_label_list.npy.gz'), 'wb') as f:\n",
    "    np.save(f, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('C:/Users/jaspa/Grant ML/slp/data/size_test.npy',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
