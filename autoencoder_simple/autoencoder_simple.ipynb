{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder_simple/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOX               103069\n",
      "FALCO              90719\n",
      "MARTH              53728\n",
      "CAPTAIN_FALCON     38006\n",
      "SHEIK              27623\n",
      "PEACH              17438\n",
      "JIGGLYPUFF         16374\n",
      "SAMUS               9524\n",
      "ICE_CLIMBERS        6849\n",
      "GANONDORF           6655\n",
      "YOSHI               5725\n",
      "LUIGI               5230\n",
      "DR_MARIO            4202\n",
      "PIKACHU             4096\n",
      "LINK                2502\n",
      "NESS                2306\n",
      "DONKEY_KONG         2026\n",
      "GAME_AND_WATCH      1967\n",
      "MEWTWO              1775\n",
      "MARIO               1713\n",
      "YOUNG_LINK          1447\n",
      "ROY                 1272\n",
      "BOWSER               940\n",
      "KIRBY                556\n",
      "PICHU                230\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())\n",
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Label   Count   Shift\n",
      "0              FOX  103069  193497\n",
      "1            FALCO   90717  168117\n",
      "2            MARTH   53728  106569\n",
      "3   CAPTAIN_FALCON   38006   70125\n",
      "4            SHEIK   27623   59145\n",
      "5            PEACH   17438   39398\n",
      "6       JIGGLYPUFF   16374   35581\n",
      "7            SAMUS    9524   23031\n",
      "8     ICE_CLIMBERS    6849   15620\n",
      "9        GANONDORF    6655   12805\n",
      "10           YOSHI    5725   12226\n",
      "11           LUIGI    5230   11464\n",
      "12        DR_MARIO    4202    9062\n",
      "13         PIKACHU    4096    8991\n",
      "14            LINK    2502    5598\n",
      "15            NESS    2306    5812\n",
      "16     DONKEY_KONG    2026    4333\n",
      "17  GAME_AND_WATCH    1967    3693\n",
      "18          MEWTWO    1775    4511\n",
      "19           MARIO    1713    3824\n",
      "20      YOUNG_LINK    1447    3278\n",
      "21             ROY    1272    2685\n",
      "22          BOWSER     940    2196\n",
      "23           KIRBY     556    1237\n",
      "24           PICHU     230     491\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(60,5000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           player_inputs_np_sub_path  length  num_segments  \\\n",
      "0  public\\FALCO\\bee06d45-fca6-437f-969a-901efa166...   28801             1   \n",
      "1  mango\\FALCO\\44e0962b-fdf7-4a16-acbe-61b5e5d609...   27200             1   \n",
      "2  ranked\\FALCO\\2f51bb81-4304-4c6d-ac53-960aba87c...   26024             1   \n",
      "3  ranked\\FALCO\\69cf9bb4-5f80-4e67-850d-ce0d7da1d...   25128             1   \n",
      "4  ranked\\FALCO\\04257d15-f02f-4001-a191-37b97d2ed...   24323             1   \n",
      "\n",
      "  labels  encoded_labels  \n",
      "0  FALCO               4  \n",
      "1  FALCO               4  \n",
      "2  FALCO               4  \n",
      "3  FALCO               4  \n",
      "4  FALCO               4  \n"
     ]
    }
   ],
   "source": [
    "train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(60, proportion_of_segments=1, test_ratio = .2, val = False)\n",
    "porportion = .8\n",
    "train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "porportion = .05\n",
    "test_df = test_df.sample(frac=porportion, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42970042, 6)\n",
      "(671279, 6)\n",
      "0.015381729622712384\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18418491</th>\n",
       "      <td>ranked\\FOX\\555c5173-1750-4a33-b785-b38d0ff8aaa...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>8142</td>\n",
       "      <td>138</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25236203</th>\n",
       "      <td>ranked\\FOX\\cb87e4b2-2873-453d-b039-b0128a6cf86...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>5487</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25261750</th>\n",
       "      <td>ranked\\FOX\\804be79f-5a9f-47ca-bfda-ef5d2b8c06d...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>472</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23561687</th>\n",
       "      <td>ranked\\FOX\\8fee85f6-9cb4-4914-9324-87f8d8e9b5e...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>8909</td>\n",
       "      <td>151</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974957</th>\n",
       "      <td>public\\FALCO\\8ea4f120-ad37-40a4-91bb-1aa235e12...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>4956</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  player_inputs_np_sub_path labels  \\\n",
       "18418491  ranked\\FOX\\555c5173-1750-4a33-b785-b38d0ff8aaa...    FOX   \n",
       "25236203  ranked\\FOX\\cb87e4b2-2873-453d-b039-b0128a6cf86...    FOX   \n",
       "25261750  ranked\\FOX\\804be79f-5a9f-47ca-bfda-ef5d2b8c06d...    FOX   \n",
       "23561687  ranked\\FOX\\8fee85f6-9cb4-4914-9324-87f8d8e9b5e...    FOX   \n",
       "3974957   public\\FALCO\\8ea4f120-ad37-40a4-91bb-1aa235e12...  FALCO   \n",
       "\n",
       "          encoded_labels  segment_start_index  segment_index  segment_length  \n",
       "18418491               5                 8142            138              60  \n",
       "25236203               5                 5487             93              60  \n",
       "25261750               5                  472              8              60  \n",
       "23561687               5                 8909            151              60  \n",
       "3974957                4                 4956             84              60  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,int(segment_start):int(segment_end)]\n",
    "        \n",
    "        # separate into positive and negative values\n",
    "        # if self.transform:\n",
    "        #     transformed = np.zeros((13,60))\n",
    "        #     transformed[0,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] > 0)\n",
    "        #     transformed[1,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] < 0)\n",
    "        #     transformed[2,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] > 0)\n",
    "        #     transformed[3,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] < 0)\n",
    "        #     transformed[4,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] > 0)\n",
    "        #     transformed[5,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] < 0)\n",
    "        #     transformed[6,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] > 0)\n",
    "        #     transformed[7,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] < 0)\n",
    "        #     transformed[8:,:] = segment[4:]\n",
    "        #     segment = transformed\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "        #     segment[0:4, :] -= .2875 * (segment[0:4, :] > 0)\n",
    "        #     segment[0:4, :] += .2875 * (segment[0:4, :] < 0)\n",
    "\n",
    "        #     # Scale inputs to be between -.5 and .5\n",
    "        #     segment[0:4, :] *= 1.40350877193 / 2\n",
    "        #     segment[0:4, :] += .5\n",
    "        segment[-5] = (segment[-5] > .5)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = np.zeros((9 + 5,60))\n",
    "            \n",
    "            # First 4 rows of transformed are the analog inputs transformed to have range [0,1]\n",
    "            # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            # Scale inputs to be between -.5 and .5\n",
    "            analog_transformed *= .5 / .725\n",
    "            # Add .5 to so final inputs are between 0 and 1\n",
    "            analog_transformed += .5\n",
    "            \n",
    "            transformed[0:4] = analog_transformed\n",
    "            # Next four rows are 1 if the corresponding analog input is 0\n",
    "            # transformed[4:8] += (segment[:4] == 0)\n",
    "            \n",
    "            \n",
    "            prepend = np.expand_dims(segment[-5:, 0], axis=1)\n",
    "            transitions= np.abs(np.diff(segment[-5:], axis=1, prepend=prepend))\n",
    "            \n",
    "            transformed[4:9] += transitions\n",
    "            \n",
    "            \n",
    "\n",
    "            # Transform the Trigger so that it is 0 or 1\n",
    "            \n",
    "            \n",
    "            # Remaining rows are button inputs\n",
    "            transformed[-5:] += segment[-5:]\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(transformed).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df,True)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df,True)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_virtual_epochs(model, criterion, optimizer, loaders, device, num_epochs=1):\n",
    "    scaler = GradScaler()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=15, factor=0.1)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    vepoch_total = 0\n",
    "    vepoch_loss_sum = 0\n",
    "    best_vepoch_loss = float('inf')\n",
    "\n",
    "    early_stopping_patience = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        virtual_epoch_start_time = time.time()\n",
    "\n",
    "        # Initialize variables for tracking gradient and parameter stats\n",
    "        grad_max = float('-inf')\n",
    "        grad_min = float('inf')\n",
    "        param_max = float('-inf')\n",
    "        param_min = float('inf')\n",
    "\n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output_gpu = model(target_gpu)\n",
    "                loss = criterion(output_gpu, target_gpu)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=100.0)\n",
    "            # Track max and min of gradients\n",
    "            batch_grad_max = max((p.grad.max().item() for p in model.parameters() if p.grad is not None), default=grad_max)\n",
    "            batch_grad_min = min((p.grad.min().item() for p in model.parameters() if p.grad is not None), default=grad_min)\n",
    "            grad_max = max(grad_max, batch_grad_max)\n",
    "            grad_min = min(grad_min, batch_grad_min)\n",
    "\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            vepoch_total += target_cpu.size(0)\n",
    "            vepoch_loss_sum += loss.item() * target_cpu.size(0)\n",
    "\n",
    "            if time.time() - virtual_epoch_start_time > 30:\n",
    "                vepoch_loss = vepoch_loss_sum / vepoch_total\n",
    "                if best_vepoch_loss > vepoch_loss:\n",
    "                    best_vepoch_loss = vepoch_loss\n",
    "                else:\n",
    "                    early_stopping_patience += 1\n",
    "                # Calculate max and min of model parameters at the end of the virtual epoch\n",
    "                param_max = max(p.data.max().item() for p in model.parameters())\n",
    "                param_min = min(p.data.min().item() for p in model.parameters())\n",
    "\n",
    "                train_loader_tqdm.set_postfix(\n",
    "                    Best=f'{best_vepoch_loss * 100:.10f}',\n",
    "                    Vepoch=f'{vepoch_loss * 100:.10f}',\n",
    "                    patience=early_stopping_patience,\n",
    "                    Grad_Max=grad_max,\n",
    "                    Grad_Min=grad_min,\n",
    "                    Param_Max=param_max,\n",
    "                    Param_Min=param_min\n",
    "                )\n",
    "                print('Grad Max:', grad_max, ' Grad Min:', grad_min)\n",
    "                virtual_epoch_start_time = time.time()\n",
    "                vepoch_total = 0\n",
    "                vepoch_loss_sum = 0\n",
    "                grad_max = float('-inf')  # Reset for next virtual epoch\n",
    "                grad_min = float('inf')   # Reset for next virtual epoch\n",
    "        \n",
    "    return best_model\n",
    "\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "def train_model_with_virtual_epochs(model, criterion, optimizer, loaders, device, num_epochs=1):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=15, factor=0.1)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    vepoch_total = 0\n",
    "    vepoch_loss_sum = 0\n",
    "    best_vepoch_loss = float('inf')\n",
    "    early_stopping_patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        virtual_epoch_start_time = time.time()\n",
    "\n",
    "        # Initialize variables for tracking gradient and parameter stats\n",
    "        grad_max = float('-inf')\n",
    "        grad_min = float('inf')\n",
    "        param_max = float('-inf')\n",
    "        param_min = float('inf')\n",
    "\n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output_gpu = model(target_gpu)\n",
    "            loss = criterion(output_gpu, target_gpu)\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            # Track max and min of gradients\n",
    "            batch_grad_max = max((p.grad.max().item() for p in model.parameters() if p.grad is not None), default=grad_max)\n",
    "            batch_grad_min = min((p.grad.min().item() for p in model.parameters() if p.grad is not None), default=grad_min)\n",
    "            grad_max = max(grad_max, batch_grad_max)\n",
    "            grad_min = min(grad_min, batch_grad_min)\n",
    "\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            vepoch_total += target_cpu.size(0)\n",
    "            vepoch_loss_sum += loss.item() * target_cpu.size(0)\n",
    "\n",
    "            if time.time() - virtual_epoch_start_time > 30:\n",
    "                vepoch_loss = vepoch_loss_sum / vepoch_total\n",
    "                if best_vepoch_loss > vepoch_loss:\n",
    "                    best_vepoch_loss = vepoch_loss\n",
    "                else:\n",
    "                    early_stopping_patience += 1\n",
    "\n",
    "                # Calculate max and min of model parameters at the end of the virtual epoch\n",
    "                param_max = max(p.data.max().item() for p in model.parameters())\n",
    "                param_min = min(p.data.min().item() for p in model.parameters())\n",
    "\n",
    "                train_loader_tqdm.set_postfix(\n",
    "                    Best=f'{best_vepoch_loss * 100:.10f}',\n",
    "                    Vepoch=f'{vepoch_loss * 100:.10f}',\n",
    "                    patience=early_stopping_patience,\n",
    "                    Grad_Max=grad_max,\n",
    "                    Grad_Min=grad_min,\n",
    "                    Param_Max=param_max,\n",
    "                    Param_Min=param_min\n",
    "                )\n",
    "                print('Grad Max:', grad_max, ' Grad Min:', grad_min)\n",
    "                virtual_epoch_start_time = time.time()\n",
    "                vepoch_total = 0\n",
    "                vepoch_loss_sum = 0\n",
    "                grad_max = float('-inf')  # Reset for next virtual epoch\n",
    "                grad_min = float('inf')   # Reset for next virtual epoch\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 14, 60]             210\n",
      "           Encoder-2               [-1, 14, 60]               0\n",
      "           Decoder-3               [-1, 14, 60]               0\n",
      "================================================================\n",
      "Total params: 210\n",
      "Trainable params: 210\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "from Autoencoder_Simple import Autoencoder\n",
    "\n",
    "\n",
    "channels = 9 + 5\n",
    "\n",
    "# Build model\n",
    "model = Autoencoder()\n",
    "# model.load_state_dict(torch.load('../../melee_project_data/baseline_2_60s_autoencoder_weights.pt'))\n",
    "model.to('cuda')\n",
    "# # With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(channels, 60))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   1%|          | 16533/2685628 [00:30<1:17:03, 577.33batch/s, Best=5.9417931770, Grad_Max=0.0433, Grad_Min=-0.0875, Param_Max=0.387, Param_Min=-0.281, Vepoch=5.9417931770, patience=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grad Max: 0.04325350373983383  Grad Min: -0.08749538660049438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   1%|          | 21173/2685628 [00:37<1:13:27, 604.48batch/s, Best=5.9417931770, Grad_Max=0.0433, Grad_Min=-0.0875, Param_Max=0.387, Param_Min=-0.281, Vepoch=5.9417931770, patience=0]"
     ]
    }
   ],
   "source": [
    "   \n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.BCE = nn.BCEWithLogitsLoss(reduction='sum')  # Consider using weighted BCE if needed\n",
    "        self.MSE = nn.MSELoss(reduction='sum')\n",
    "        self.bin_threshold = 2\n",
    "        # Self.bin_threshold bins to the left and right should account for the barely close enough threshold\n",
    "        self.barely_close_enough = (.5 + self.bin_threshold) * 0.00862#\n",
    "        self.scale_factor = - math.log(.5) / self.barely_close_enough ** 2\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        # Calculating losses\n",
    "        mse_loss = self.MSE(torch.sigmoid(pred[:,0:4,0:60]), target[:,0:4,0:60]) \n",
    "        bce_loss = self.BCE(pred[:,4:,0:60], target[:,4:,0:60])\n",
    "        \n",
    "        # Total loss\n",
    "        return mse_loss  + bce_loss / 100\n",
    "\n",
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "# Pepare data loaders\n",
    "batch_size =  16 * 32\n",
    "batch_size =  16\n",
    "# batch_size =  8\n",
    "num_workers = 22\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "criterion = CustomLoss()\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# def initialize_weights(m):\n",
    "    \n",
    "#     if isinstance(m, nn.Conv1d):\n",
    "#         nn.init.xavier_uniform_(m.weight)\n",
    "#         if m.bias is not None:\n",
    "#             nn.init.constant_(m.bias, 0)\n",
    "#     elif isinstance(m, nn.BatchNorm1d):\n",
    "#         nn.init.constant_(m.weight, 1)\n",
    "#         nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# # model = Autoencoder(9)\n",
    "# model.apply(initialize_weights)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.00001)\n",
    "num_epochs = 2\n",
    "\n",
    "\n",
    "\n",
    "# This seems to sometimes help\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "# start_time = time.time()\n",
    "# train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
