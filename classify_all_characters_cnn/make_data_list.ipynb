{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import shutil\n",
    "# import os\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import tqdm\n",
    "import pyarrow\n",
    "# Paths of datasets\n",
    "\n",
    "\n",
    "\n",
    "ranked_full_game_save_path = 'C:/Users/jaspa/Grant ML/ranked_full_subfolders'\n",
    "ranked_segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/ranked_segments_subfolders'\n",
    "ranked_segment_save_path_bulk = 'C:/Users/jaspa/Grant ML/ranked_segments_bulk'\n",
    "\n",
    "public_full_game_save_path = 'C:/Users/jaspa/Grant ML/public_full_subfolders'\n",
    "public_segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/public_segments_subfolders'\n",
    "public_segment_save_path_bulk = 'C:/Users/jaspa/Grant ML/public_segments_bulk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all slp game input arrays we want to process. Make a dataframe with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def list_files(directory):\n",
    "#     for root, dirs, files in os.walk(directory):\n",
    "#         for file in files:\n",
    "#             yield os.path.join(root, file)\n",
    "\n",
    "# def parse_file_path(file_path):\n",
    "#     parts = file_path.split('\\\\')\n",
    "#     # Extracting necessary details from the file path\n",
    "#     file_name = parts[-1]\n",
    "#     character = parts[-2]\n",
    "#     opponent = parts[-3]\n",
    "#     return {\n",
    "#         'file': file_name,\n",
    "#         'path': '\\\\'.join(parts[:-1]),\n",
    "#         'character': character,\n",
    "#         'opponent': opponent,\n",
    "#         'game_length': 0,  # Placeholder values\n",
    "#         'segment_shift': 0,\n",
    "#         'num_segments': 0\n",
    "#     }\n",
    "\n",
    "# def generate_dataframe_from_folders(folders):\n",
    "#     files_data = []\n",
    "#     for folder in folders:\n",
    "#         for file_path in list_files(folder):\n",
    "#             files_data.append(parse_file_path(file_path))\n",
    "#     return pd.DataFrame(files_data)\n",
    "\n",
    "# ranked_full_game_save_path = 'C:/Users/jaspa/Grant ML/ranked_full_subfolders'\n",
    "# public_full_game_save_path = 'C:/Users/jaspa/Grant ML/public_full_subfolders'\n",
    "# folders = [ranked_full_game_save_path, public_full_game_save_path]\n",
    "\n",
    "# df = generate_dataframe_from_folders(folders)\n",
    "# print(df.head())  # Display the first few rows to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Joblib to open the game arrays and get the length of the game in frames. Save the data frame. About 40 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_array_length(file_path):\n",
    "#     # Update this function based on how you want to handle the file reading,\n",
    "#     # For gzipped numpy files, you would do something like this:\n",
    "#     with gzip.open(file_path, 'rb') as f:\n",
    "#         arr = np.load(f)\n",
    "#         return arr.shape[1]\n",
    "\n",
    "# def process_row(row):\n",
    "#     # Call the get_array_length function with the path of the file\n",
    "#     length = get_array_length(row['path'] + '\\\\' + row['file'])\n",
    "#     return length\n",
    "\n",
    "\n",
    "# num_cores = -1  # Or however many cores you want to use\n",
    "# lengths = Parallel(n_jobs=num_cores,verbose = 0)(delayed(process_row)(row) for index, row in tqdm.tqdm(df.iterrows()))\n",
    "# df['game_length'] = lengths\n",
    "\n",
    "# df.to_feather('C:/Users/jaspa/Grant ML/slp/data/path_info_df.feather')\n",
    "\n",
    "\n",
    "# print(df.head())  # To check the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your feather file\n",
    "file_path = 'C:/Users/jaspa/Grant ML/slp/data/path_info_df.feather'\n",
    "\n",
    "# Load the feather file\n",
    "df = pd.read_feather(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of segments you want to use (same for each character). Check what the maximum power of two you need to shift each segment by to get the right number of segments. Can shift by as little as 64 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       file  \\\n",
      "0  107729__1__CAPTAIN_FALCON__BOWSER.npy.gz   \n",
      "1    1122__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "2  113580__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "3  116020__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "4   13522__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "\n",
      "                                                path       character opponent  \\\n",
      "0  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "1  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "2  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "3  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "4  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "\n",
      "   game_length  segment_shift  num_segments  \n",
      "0        10935           1024             0  \n",
      "1        11244           1024             0  \n",
      "2         7487           1024             0  \n",
      "3        12676           1024             0  \n",
      "4        15657           1024             0  \n"
     ]
    }
   ],
   "source": [
    "min_segments = 20000\n",
    "segment_length = 1024\n",
    "for character in df['character'].unique():\n",
    "    game_lengths = df.loc[df['character'] == character, 'game_length']\n",
    "    for i in range(5):\n",
    "        segment_shift = 2 ** (10-i)\n",
    "        num_segments = 0\n",
    "        for game_length in game_lengths:\n",
    "            num_segments += (game_length - segment_length) // segment_shift\n",
    "        if num_segments > min_segments:\n",
    "            break\n",
    "    # Correct way to set values to avoid SettingWithCopyWarning\n",
    "    df.loc[df['character'] == character, 'segment_shift'] = segment_shift\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many segments you will get from each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       file  \\\n",
      "0  107729__1__CAPTAIN_FALCON__BOWSER.npy.gz   \n",
      "1    1122__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "2  113580__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "3  116020__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "4   13522__0__BOWSER__CAPTAIN_FALCON.npy.gz   \n",
      "\n",
      "                                                path       character opponent  \\\n",
      "0  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "1  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "2  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "3  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "4  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   BOWSER   \n",
      "\n",
      "   game_length  segment_shift  num_segments  \n",
      "0        10935           1024             9  \n",
      "1        11244           1024             9  \n",
      "2         7487           1024             6  \n",
      "3        12676           1024            11  \n",
      "4        15657           1024            14  \n"
     ]
    }
   ],
   "source": [
    "df['num_segments'] = (df['game_length']- segment_length) // df['segment_shift']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See haw many extra segments you have for each character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAPTAIN_FALCON :  297909\n",
      "DONKEY_KONG :  434\n",
      "DR_MARIO :  19104\n",
      "FALCO :  621333\n",
      "FOX :  816085\n",
      "GAME_AND_WATCH :  15886\n",
      "GANONDORF :  42149\n",
      "ICE_CLIMBERS :  57542\n",
      "JIGGLYPUFF :  148477\n",
      "KIRBY :  6073\n",
      "LINK :  6538\n",
      "LUIGI :  36019\n",
      "MARIO :  16559\n",
      "MARTH :  424374\n",
      "MEWTWO :  1621\n",
      "NESS :  8442\n",
      "PEACH :  173956\n",
      "PICHU :  623\n",
      "PIKACHU :  23279\n",
      "ROY :  5573\n",
      "SAMUS :  93468\n",
      "SHEIK :  262434\n",
      "YOSHI :  32627\n",
      "YOUNG_LINK :  11191\n",
      "ZELDA :  8814\n",
      "BOWSER :  961\n"
     ]
    }
   ],
   "source": [
    "# min_segments = 20000\n",
    "# segment_length = 1024\n",
    "for character in df['character'].unique():\n",
    "    character_df = df.loc[df['character'] == character]\n",
    "    print(character, ': ', sum(character_df['num_segments'])-min_segments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomize the games from each character. Cound how many segments you are going to get for each character. Split the games up so that 15% of the segments end up in the test set and the validation and 70% of the segments end up in the train set. No segments from the same game will end up in different data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62857, 7)\n",
      "(62831, 7)\n",
      "(293391, 7)\n",
      "                                               file  \\\n",
      "0           250642__0__MARTH__CAPTAIN_FALCON.npy.gz   \n",
      "1  233849__1__CAPTAIN_FALCON__CAPTAIN_FALCON.npy.gz   \n",
      "2       108447__0__GANONDORF__CAPTAIN_FALCON.npy.gz   \n",
      "3       53622__1__CAPTAIN_FALCON__JIGGLYPUFF.npy.gz   \n",
      "4               4174__0__FOX__CAPTAIN_FALCON.npy.gz   \n",
      "\n",
      "                                                path       character  \\\n",
      "0  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON   \n",
      "1  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON   \n",
      "2  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   \n",
      "3  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   \n",
      "4  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   \n",
      "\n",
      "         opponent  game_length  segment_shift  num_segments  \n",
      "0           MARTH        10871           1024             9  \n",
      "1  CAPTAIN_FALCON         9740           1024             8  \n",
      "2       GANONDORF         8513           1024             7  \n",
      "3      JIGGLYPUFF         9089           1024             7  \n",
      "4             FOX        11069           1024             9  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize empty DataFrames for test, validation, and training sets\n",
    "test_df = pd.DataFrame()\n",
    "val_df = pd.DataFrame()\n",
    "train_df = pd.DataFrame()\n",
    "\n",
    "min_segments = 20000\n",
    "# target_segments_for_test_and_val = min_segments * 0.15\n",
    "\n",
    "for character in df['character'].unique():\n",
    "    character_df = df.loc[df['character'] == character].sample(frac=1).reset_index(drop=True)  # Shuffle the rows\n",
    "    sum_segments = 0\n",
    "    test_idx = 0\n",
    "    val_idx = 0\n",
    "    \n",
    "    #split the games of each character by .15, .15, and .7\n",
    "    target_segments_for_test_and_val = sum(character_df['num_segments']) * 0.15\n",
    "    # Determine the split indices for test and validation sets\n",
    "    for i, row in character_df.iterrows():\n",
    "        sum_segments += row['num_segments']\n",
    "        if sum_segments >= target_segments_for_test_and_val:\n",
    "            if test_idx == 0:  # First batch for test set\n",
    "                test_idx = i\n",
    "                sum_segments = 0  # Reset sum for validation set calculation\n",
    "            elif val_idx == 0:  # Next batch for validation set\n",
    "                val_idx = i\n",
    "                break\n",
    "    \n",
    "    # Split the character_df into test, val, and train based on the indices\n",
    "    test_rows = character_df.iloc[:test_idx+1]\n",
    "    val_rows = character_df.iloc[test_idx+1:val_idx+1]\n",
    "    train_rows = character_df.iloc[val_idx+1:]\n",
    "\n",
    "    # Append to respective DataFrames\n",
    "    test_df = pd.concat([test_df, test_rows], ignore_index=True)\n",
    "    val_df = pd.concat([val_df, val_rows], ignore_index=True)\n",
    "    train_df = pd.concat([train_df, train_rows], ignore_index=True)\n",
    "    \n",
    "print(test_df.shape)\n",
    "print(val_df.shape)\n",
    "print(train_df.shape)\n",
    "\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expand the data frames so that there is one path for each segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(547961, 7)\n",
      "(547923, 7)\n",
      "(2555587, 7)\n",
      "                                      file  \\\n",
      "0  242318__3__CAPTAIN_FALCON__ZELDA.npy.gz   \n",
      "1  242318__3__CAPTAIN_FALCON__ZELDA.npy.gz   \n",
      "2  242318__3__CAPTAIN_FALCON__ZELDA.npy.gz   \n",
      "3  242318__3__CAPTAIN_FALCON__ZELDA.npy.gz   \n",
      "4  242318__3__CAPTAIN_FALCON__ZELDA.npy.gz   \n",
      "\n",
      "                                                path       character opponent  \\\n",
      "0  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON    ZELDA   \n",
      "1  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON    ZELDA   \n",
      "2  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON    ZELDA   \n",
      "3  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON    ZELDA   \n",
      "4  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON    ZELDA   \n",
      "\n",
      "   game_length  segment_shift  segment_index  \n",
      "0         7450           1024              0  \n",
      "1         7450           1024              1  \n",
      "2         7450           1024              2  \n",
      "3         7450           1024              3  \n",
      "4         7450           1024              4  \n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "def expand_df_vectorized(df):\n",
    "    # Calculate the repeat count for each row based on 'num_segments'\n",
    "    repeats = df['num_segments'].values\n",
    "    \n",
    "    # Repeat each index according to its corresponding 'num_segments' value\n",
    "    index_repeated = np.repeat(df.index, repeats)\n",
    "    \n",
    "    # Create a new DataFrame by repeating rows\n",
    "    df_repeated = df.loc[index_repeated].reset_index(drop=True)\n",
    "    \n",
    "    # Create a 'segment_index' column that counts up for each group of repeated rows\n",
    "    segment_indices = np.concatenate([np.arange(n) for n in repeats])\n",
    "    \n",
    "    # Assign 'segment_index' to the repeated DataFrame\n",
    "    df_repeated['segment_index'] = segment_indices\n",
    "    \n",
    "    # Optionally, drop the 'num_segments' column if it's no longer needed\n",
    "    df_repeated = df_repeated.drop(columns=['num_segments'])\n",
    "    \n",
    "    return df_repeated\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "expanded_test_df = expand_df_vectorized(test_df)\n",
    "expanded_val_df = expand_df_vectorized(val_df)\n",
    "expanded_train_df = expand_df_vectorized(train_df)\n",
    "\n",
    "print(expanded_test_df.shape)\n",
    "print(expanded_val_df.shape)\n",
    "print(expanded_train_df.shape)\n",
    "print(expanded_test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomly sample the right number of segments to create each data set.  Encode the character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78000, 8)\n",
      "(78000, 8)\n",
      "(364000, 8)\n",
      "                                               file  \\\n",
      "0             264047__3__CAPTAIN_FALCON__FOX.npy.gz   \n",
      "1            24132__1__CAPTAIN_FALCON__MARTH.npy.gz   \n",
      "2  247147__1__CAPTAIN_FALCON__CAPTAIN_FALCON.npy.gz   \n",
      "3            59959__0__FALCO__CAPTAIN_FALCON.npy.gz   \n",
      "4            31335__1__CAPTAIN_FALCON__MARTH.npy.gz   \n",
      "\n",
      "                                                path       character  \\\n",
      "0  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON   \n",
      "1  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   \n",
      "2  C:/Users/jaspa/Grant ML/public_full_subfolders...  CAPTAIN_FALCON   \n",
      "3  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   \n",
      "4  C:/Users/jaspa/Grant ML/ranked_full_subfolders...  CAPTAIN_FALCON   \n",
      "\n",
      "         opponent  game_length  segment_shift  segment_index  labels  \n",
      "0             FOX        10708           1024              0       1  \n",
      "1           MARTH         8775           1024              5       1  \n",
      "2  CAPTAIN_FALCON        13119           1024              3       1  \n",
      "3           FALCO         7141           1024              2       1  \n",
      "4           MARTH         7369           1024              5       1  \n"
     ]
    }
   ],
   "source": [
    "def sample_rows_per_character(df, proportion, min_segments, encoder):\n",
    "    rows_per_character = int(min_segments * proportion)\n",
    "    sampled_df = pd.DataFrame()\n",
    "    \n",
    "    for character in df['character'].unique():\n",
    "        character_df = df[df['character'] == character]\n",
    "        sampled_rows = character_df.sample(n=min(rows_per_character, len(character_df)), random_state=1)\n",
    "        sampled_df = pd.concat([sampled_df, sampled_rows], ignore_index=True)\n",
    "    \n",
    "    # Add the 'labels' column using the fitted encoder\n",
    "    sampled_df['labels'] = encoder.transform(sampled_df['character'])\n",
    "    \n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "# Assuming 'characters' is your array of unique character names\n",
    "characters = ['CAPTAIN_FALCON', 'DONKEY_KONG', 'DR_MARIO', 'FALCO', 'FOX',\n",
    "              'GAME_AND_WATCH', 'GANONDORF', 'ICE_CLIMBERS', 'JIGGLYPUFF',\n",
    "              'KIRBY', 'LINK', 'LUIGI', 'MARIO', 'MARTH', 'MEWTWO', 'NESS',\n",
    "              'PEACH', 'PICHU', 'PIKACHU', 'ROY', 'SAMUS', 'SHEIK', 'YOSHI',\n",
    "              'YOUNG_LINK', 'ZELDA', 'BOWSER']\n",
    "\n",
    "# Initialize and fit the LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(characters)\n",
    "\n",
    "sampled_test_df = sample_rows_per_character(expanded_test_df, 0.15, min_segments, encoder)\n",
    "sampled_val_df = sample_rows_per_character(expanded_val_df, 0.15, min_segments, encoder)\n",
    "sampled_train_df = sample_rows_per_character(expanded_train_df, 0.70, min_segments, encoder)\n",
    "\n",
    "\n",
    "print(sampled_test_df.shape)\n",
    "print(sampled_val_df.shape)\n",
    "print(sampled_train_df.shape)\n",
    "\n",
    "print(sampled_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_test_df.to_feather('C:/Users/jaspa/Grant ML/slp/data/sample_test_df.feather')\n",
    "sampled_val_df.to_feather('C:/Users/jaspa/Grant ML/slp/data/sample_val_df.feather')\n",
    "sampled_train_df.to_feather('C:/Users/jaspa/Grant ML/slp/data/sample_train_df.feather')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
