{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import shutil\n",
    "# import os\n",
    "# import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "# Paths of datasets\n",
    "full_game_save_path = 'C:/Users/jaspa/Grant ML/ranked_full_subfolders'\n",
    "segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/ranked_segments_subfolders'\n",
    "segment_save_path_bulk = 'C:/Users/jaspa/Grant ML/ranked_segments_bulk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training, test, and holdout set for a particular set of charcters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of data points:  769160\n"
     ]
    }
   ],
   "source": [
    "segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/ranked_segments_subfolders'\n",
    "character_segment_counts = {'BOWSER': 9563, 'CAPTAIN_FALCON': 153832, 'DONKEY_KONG': 11970, 'DR_MARIO': 29235, 'FALCO': 424029, 'FOX': 489437, 'GAME_AND_WATCH': 14105, 'GANONDORF': 45758, 'ICE_CLIMBERS': 58698, 'JIGGLYPUFF': 138053, 'KIRBY': 3396, 'LINK': 21630, 'LUIGI': 39558, 'MARIO': 12368, 'MARTH': 249755, 'MEWTWO': 20922, 'NESS': 27592, 'PEACH': 144477, 'PICHU': 1726, 'PIKACHU': 30054, 'ROY': 9957, 'SAMUS': 85573, 'SHEIK': 189710, 'YOSHI': 41101, 'YOUNG_LINK': 12783, 'ZELDA': 3936}\n",
    "\n",
    "selected_characters = [\n",
    "    'FOX', \n",
    "    'FALCO', \n",
    "    'MARTH', \n",
    "    'SHEIK', \n",
    "    'CAPTAIN_FALCON', \n",
    "    'PEACH', \n",
    "    'JIGGLYPUFF', \n",
    "    'SAMUS', \n",
    "    # 'ICE_CLIMBERS', \n",
    "    # 'GANONDORF', \n",
    "    # 'YOSHI', \n",
    "    # 'LUIGI', \n",
    "    # 'PIKACHU', \n",
    "    # 'DR_MARIO', \n",
    "    # 'NESS', \n",
    "    # 'LINK', \n",
    "    # 'MEWTWO', \n",
    "    # 'GAME_AND_WATCH', \n",
    "    # 'DONKEY_KONG', \n",
    "    # 'YOUNG_LINK', \n",
    "    # 'MARIO', \n",
    "    # 'ROY', \n",
    "    # 'BOWSER', \n",
    "    # 'ZELDA', \n",
    "    # 'KIRBY', \n",
    "    # 'PICHU'\n",
    "    ]\n",
    "\n",
    "# Determine the minimum number of segments among the selected characters\n",
    "min_segments = min([character_segment_counts[char] for char in selected_characters])\n",
    "# min_segments = 2\n",
    "\n",
    "# Map each selected character to an integer\n",
    "char_to_int = {char: i for i, char in enumerate(selected_characters)}\n",
    "\n",
    "# Initialize a dictionary to hold file paths organized by character\n",
    "character_files = {char: [] for char in selected_characters}\n",
    "\n",
    "# Collect all file paths organized by character\n",
    "for character in selected_characters:\n",
    "    char_path = os.path.join(segment_save_path_subfolder, character)\n",
    "    for opponent in os.listdir(char_path):\n",
    "        opponent_path = os.path.join(char_path, opponent)\n",
    "        files = [os.path.join(opponent_path, file) for file in os.listdir(opponent_path)]\n",
    "        character_files[character].extend(files)\n",
    "\n",
    "# Sample min_segments for each selected character\n",
    "X = []\n",
    "y = []\n",
    "for character, files in character_files.items():\n",
    "    sampled_files = np.random.choice(files, min_segments, replace=False)\n",
    "    X.extend(sampled_files)\n",
    "    y.extend([char_to_int[character]] * min_segments)\n",
    "\n",
    "# Shuffle the dataset to mix up the order of characters\n",
    "X, y = shuffle(np.array(X), np.array(y), random_state=42)\n",
    "\n",
    "# At this point, X and y are your balanced dataset ready for further processing\n",
    "print('number of data points: ',X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot mmap an empty file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     y_mmap[:] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m y_mmap  \u001b[38;5;66;03m# Flush the changes\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43msave_data_with_mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/jaspa/Grant ML/slp/data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 20\u001b[0m, in \u001b[0;36msave_data_with_mmap\u001b[1;34m(X, y, save_path)\u001b[0m\n\u001b[0;32m     16\u001b[0m labels_mmap \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mranked_label_list.dat\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Create and save the memory-mapped arrays\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Mode 'w+' creates a file for reading and writing, initializing the file to the given shape and dtype\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m X_mmap \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_paths_mmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m X_mmap[:] \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_mmap  \u001b[38;5;66;03m# Flush the changes\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jaspa\\.conda\\envs\\pytorch\\Lib\\site-packages\\numpy\\core\\memmap.py:268\u001b[0m, in \u001b[0;36mmemmap.__new__\u001b[1;34m(subtype, filename, dtype, mode, offset, shape, order)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28mbytes\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m start\n\u001b[0;32m    267\u001b[0m array_offset \u001b[38;5;241m=\u001b[39m offset \u001b[38;5;241m-\u001b[39m start\n\u001b[1;32m--> 268\u001b[0m mm \u001b[38;5;241m=\u001b[39m \u001b[43mmmap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileno\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccess\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m ndarray\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(subtype, shape, dtype\u001b[38;5;241m=\u001b[39mdescr, buffer\u001b[38;5;241m=\u001b[39mmm,\n\u001b[0;32m    271\u001b[0m                        offset\u001b[38;5;241m=\u001b[39marray_offset, order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mmap \u001b[38;5;241m=\u001b[39m mm\n",
      "\u001b[1;31mValueError\u001b[0m: cannot mmap an empty file"
     ]
    }
   ],
   "source": [
    "\n",
    "def save_data_with_mmap(X, y, save_path):\n",
    "    \"\"\"\n",
    "    Saves file paths and labels using numpy.memmap for efficient memory usage.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.array): Array of file paths.\n",
    "        y (numpy.array): Array of labels.\n",
    "        save_path (str): Directory where the data should be saved.\n",
    "    \"\"\"\n",
    "    # Ensure save_path exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Define the paths for the memory-mapped files\n",
    "    file_paths_mmap = os.path.join(save_path, 'ranked_file_paths.dat')\n",
    "    labels_mmap = os.path.join(save_path, 'ranked_label_list.dat')\n",
    "\n",
    "    # Create and save the memory-mapped arrays\n",
    "    # Mode 'w+' creates a file for reading and writing, initializing the file to the given shape and dtype\n",
    "    X_mmap = np.memmap(file_paths_mmap, dtype=np.str_, mode='w+', shape=X.shape)\n",
    "    X_mmap[:] = X\n",
    "    del X_mmap  # Flush the changes\n",
    "\n",
    "    y_mmap = np.memmap(labels_mmap, dtype=np.int16, mode='w+', shape=y.shape)\n",
    "    y_mmap[:] = y\n",
    "    del y_mmap  # Flush the changes\n",
    "    \n",
    "save_data_with_mmap(X,y,'C:/Users/jaspa/Grant ML/slp/data/' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(769160,)\n",
      "(769160,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39828285574913025\n"
     ]
    }
   ],
   "source": [
    "def array_memory_size(array):\n",
    "    \"\"\"\n",
    "    Calculate the memory size of a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        array (numpy.array): The NumPy array for which to calculate memory usage.\n",
    "\n",
    "    Returns:\n",
    "        int: Memory usage of the array in bytes.\n",
    "    \"\"\"\n",
    "    # Get the size of one array element in bytes\n",
    "    element_size = array.dtype.itemsize\n",
    "    # Get the total number of elements in the array\n",
    "    total_elements = array.size\n",
    "    # Calculate total memory usage\n",
    "    memory_usage = element_size * total_elements/ (1024**3)\n",
    "    return memory_usage\n",
    "\n",
    "print(array_memory_size(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/jaspa/Grant ML/slp/data/'\n",
    "\n",
    "\n",
    "with gzip.open(os.path.join(save_path,'ranked_file_paths.npy.gz'), 'wb') as f:\n",
    "    np.save(f, X)\n",
    "\n",
    "with gzip.open(os.path.join(save_path,'ranked_label_list.npy.gz'), 'wb') as f:\n",
    "    np.save(f, y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
