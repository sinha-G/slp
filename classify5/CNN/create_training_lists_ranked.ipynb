{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import gzip\n",
    "import shutil\n",
    "# import os\n",
    "# import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "# Paths of datasets\n",
    "full_game_save_path = 'C:/Users/jaspa/Grant ML/ranked_full_subfolders'\n",
    "segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/ranked_segments_subfolders'\n",
    "segment_save_path_bulk = 'C:/Users/jaspa/Grant ML/ranked_segments_bulk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training, test, and holdout set for a particular set of charcters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_save_path_subfolder = 'C:/Users/jaspa/Grant ML/ranked_segments_subfolders'\n",
    "character_segment_counts = {'BOWSER': 9563, 'CAPTAIN_FALCON': 153832, 'DONKEY_KONG': 11970, 'DR_MARIO': 29235, 'FALCO': 424029, 'FOX': 489437, 'GAME_AND_WATCH': 14105, 'GANONDORF': 45758, 'ICE_CLIMBERS': 58698, 'JIGGLYPUFF': 138053, 'KIRBY': 3396, 'LINK': 21630, 'LUIGI': 39558, 'MARIO': 12368, 'MARTH': 249755, 'MEWTWO': 20922, 'NESS': 27592, 'PEACH': 144477, 'PICHU': 1726, 'PIKACHU': 30054, 'ROY': 9957, 'SAMUS': 85573, 'SHEIK': 189710, 'YOSHI': 41101, 'YOUNG_LINK': 12783, 'ZELDA': 3936}\n",
    "\n",
    "selected_characters = [\n",
    "    'FOX', \n",
    "    'FALCO', \n",
    "    'MARTH', \n",
    "    'SHEIK', \n",
    "    'CAPTAIN_FALCON', \n",
    "    'PEACH', \n",
    "    'JIGGLYPUFF', \n",
    "    'SAMUS', \n",
    "    'ICE_CLIMBERS', \n",
    "    'GANONDORF', \n",
    "    'YOSHI', \n",
    "    'LUIGI', \n",
    "    'PIKACHU', \n",
    "    'DR_MARIO', \n",
    "    'NESS', \n",
    "    'LINK', \n",
    "    'MEWTWO', \n",
    "    'GAME_AND_WATCH', \n",
    "    'DONKEY_KONG', \n",
    "    'YOUNG_LINK', \n",
    "    'MARIO', \n",
    "    'ROY', \n",
    "    'BOWSER', \n",
    "    # 'ZELDA', \n",
    "    # 'KIRBY', \n",
    "    # 'PICHU'\n",
    "    ]\n",
    "\n",
    "# Determine the minimum number of segments among the selected characters\n",
    "min_segments = min([character_segment_counts[char] for char in selected_characters])\n",
    "# min_segments = 2\n",
    "\n",
    "# Map each selected character to an integer\n",
    "char_to_int = {char: i for i, char in enumerate(selected_characters)}\n",
    "\n",
    "# Initialize a dictionary to hold file paths organized by character\n",
    "character_files = {char: [] for char in selected_characters}\n",
    "\n",
    "# Collect all file paths organized by character\n",
    "for character in selected_characters:\n",
    "    char_path = os.path.join(segment_save_path_subfolder, character)\n",
    "    for opponent in os.listdir(char_path):\n",
    "        opponent_path = os.path.join(char_path, opponent)\n",
    "        files = [os.path.join(opponent_path, file) for file in os.listdir(opponent_path)]\n",
    "        character_files[character].extend(files)\n",
    "\n",
    "# Sample min_segments for each selected character\n",
    "X = []\n",
    "y = []\n",
    "for character, files in character_files.items():\n",
    "    sampled_files = np.random.choice(files, min_segments, replace=False)\n",
    "    X.extend(sampled_files)\n",
    "    y.extend([char_to_int[character]] * min_segments)\n",
    "\n",
    "# Shuffle the dataset to mix up the order of characters\n",
    "X, y = shuffle(np.array(X), np.array(y), random_state=42)\n",
    "\n",
    "# At this point, X and y are your balanced dataset ready for further processing\n",
    "print('number of data points: ',X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_data_with_mmap(X, y, save_path):\n",
    "    \"\"\"\n",
    "    Saves file paths and labels using numpy.memmap for efficient memory usage.\n",
    "\n",
    "    Args:\n",
    "        X (numpy.array): Array of file paths.\n",
    "        y (numpy.array): Array of labels.\n",
    "        save_path (str): Directory where the data should be saved.\n",
    "    \"\"\"\n",
    "    # Ensure save_path exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Define the paths for the memory-mapped files\n",
    "    file_paths_mmap = os.path.join(save_path, 'ranked_file_paths.dat')\n",
    "    labels_mmap = os.path.join(save_path, 'ranked_label_list.dat')\n",
    "\n",
    "    # Create and save the memory-mapped arrays\n",
    "    # Mode 'w+' creates a file for reading and writing, initializing the file to the given shape and dtype\n",
    "    X_mmap = np.memmap(file_paths_mmap, dtype=np.str_, mode='w+', shape=X.shape)\n",
    "    X_mmap[:] = X\n",
    "    del X_mmap  # Flush the changes\n",
    "\n",
    "    y_mmap = np.memmap(labels_mmap, dtype=np.int16, mode='w+', shape=y.shape)\n",
    "    y_mmap[:] = y\n",
    "    del y_mmap  # Flush the changes\n",
    "    \n",
    "save_data_with_mmap(X,y,'C:/Users/jaspa/Grant ML/slp/data/' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_memory_size(array):\n",
    "    \"\"\"\n",
    "    Calculate the memory size of a NumPy array.\n",
    "\n",
    "    Args:\n",
    "        array (numpy.array): The NumPy array for which to calculate memory usage.\n",
    "\n",
    "    Returns:\n",
    "        int: Memory usage of the array in bytes.\n",
    "    \"\"\"\n",
    "    # Get the size of one array element in bytes\n",
    "    element_size = array.dtype.itemsize\n",
    "    # Get the total number of elements in the array\n",
    "    total_elements = array.size\n",
    "    # Calculate total memory usage\n",
    "    memory_usage = element_size * total_elements/ (1024**3)\n",
    "    return memory_usage\n",
    "\n",
    "print(array_memory_size(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/jaspa/Grant ML/slp/data/'\n",
    "\n",
    "\n",
    "with gzip.open(os.path.join(save_path,'ranked_file_paths.npy.gz'), 'wb') as f:\n",
    "    np.save(f, X)\n",
    "\n",
    "with gzip.open(os.path.join(save_path,'ranked_label_list.npy.gz'), 'wb') as f:\n",
    "    np.save(f, y)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
