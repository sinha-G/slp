{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/melee_project_data/input_np/mango/FALCO/72a00ff5-b2a2-4afa-9b63-9523feaf9beb.npy.gz\"\n",
    "\n",
    "with gzip.open(path, 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "for n in range(5,9):\n",
    "    print(np.unique(segment[n,:]))\n",
    "    \n",
    "non_zero = segment[0] != 0\n",
    "print(np.min(np.abs(segment[0,non_zero])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/melee_project_data/input_np/mango/FALCO/72a00ff5-b2a2-4afa-9b63-9523feaf9beb.npy.gz\"\n",
    "\n",
    "with gzip.open(path, 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "for n in range(5,9):\n",
    "    print(np.unique(segment[n,:]))\n",
    "    print('ones:', np.sum(segment[n,:]), ', zeros:', segment.shape[1] - np.sum(segment[n,:]))\n",
    "\n",
    "# print(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/workspace/melee_project_data/input_np/mango/FALCO/e55c959c-533d-4b0e-82b1-4e79decd25e2.npy.gz\"\n",
    "\n",
    "with gzip.open(path, 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "for n in range(5,9):\n",
    "    print(np.unique(segment[n,:]))\n",
    "    print('ones:', np.sum(segment[n,:]), ', zeros:', segment.shape[1] - np.sum(segment[n,:]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "df = dataset.dataset\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df.sample(n=10000, random_state=42)\n",
    "print(sample_df.shape)\n",
    "print(sample_df.describe())\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_key = { \n",
    "    'JSTICK_X':[],\n",
    "    'JSTICK_Y':[], \n",
    "    'CSTICK_X':[], \n",
    "    'CSTICK_Y':[],  \n",
    "    'TRIGGER_LOGICAL':[],  \n",
    "    'Z':[],  \n",
    "    'A':[],  \n",
    "    'B':[], \n",
    "    'X_or_Y':[]\n",
    "}\n",
    "\n",
    "def load_and_process(path, length, row_sums_dict):\n",
    "    \n",
    "    with gzip.open(path, 'rb') as f:\n",
    "            inputs = np.load(f)\n",
    "    \n",
    "    \n",
    "    # Want a new dictionary with each the sum of each row of inputs being added the values of data_key\n",
    "    row_sums_np = np.sum(np.abs(inputs), axis=1) / length\n",
    "    # Map each sum to the corresponding key in data_key\n",
    "    keys = row_sums_dict.keys()\n",
    "    for index, key in enumerate(keys):\n",
    "        row_sums_dict[key].append(row_sums_np[index])\n",
    "    \n",
    "    row_sums_dict.update(row_sums_dict)\n",
    "    return \n",
    "\n",
    "row_sums_dict = data_key.copy()\n",
    "for i in range(sample_df.shape[0]):\n",
    "# for i in range(3):\n",
    "    load_and_process('/workspace/melee_project_data/input_np/' + sample_df['player_inputs_np_sub_path'].iloc[i].replace('\\\\','/'),sample_df['length'].iloc[i],row_sums_dict)\n",
    "\n",
    "row_sums_df = pd.DataFrame(row_sums_dict)\n",
    "# print(row_sums_df.head())\n",
    "row_sums_df.describe()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define input keys\n",
    "input_keys = ['JSTICK_X', 'JSTICK_Y', 'CSTICK_X', 'CSTICK_Y', 'TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "binary_keys = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "\n",
    "# Initialize global histograms with appropriate bin edges\n",
    "bin_edges = {\n",
    "    key: np.linspace(-1, 1, 21) if key not in binary_keys else np.array([0, 1, 2])\n",
    "    for key in input_keys\n",
    "}\n",
    "global_histograms = {key: np.zeros(len(bin_edges[key]) - 1) for key in input_keys}\n",
    "\n",
    "def load_and_process(path, length, histograms):\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        inputs = np.load(f)\n",
    "\n",
    "    # Ensure inputs have the correct number of columns\n",
    "    if inputs.shape[0] != len(input_keys):\n",
    "        raise ValueError(f\"Expected number of columns: {len(input_keys)}, but got {inputs.shape[0]}\")\n",
    "\n",
    "    # Compute histograms for each column\n",
    "    for index, key in enumerate(input_keys):\n",
    "        row_histogram, _ = np.histogram(inputs[index,:], bins=bin_edges[key])\n",
    "        histograms[key] += row_histogram / length\n",
    "\n",
    "# Example DataFrame loading and processing loop\n",
    "# sample_df = pd.read_csv('path_to_your_dataframe.csv')\n",
    "for i in range(sample_df.shape[0]):\n",
    "    path = '/workspace/melee_project_data/input_np/' + sample_df['player_inputs_np_sub_path'].iloc[i].replace('\\\\', '/')\n",
    "    load_and_process(path, sample_df['length'].iloc[i], global_histograms)\n",
    "\n",
    "# Display histograms\n",
    "for key, counts in global_histograms.items():\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(f'Histogram for {key}')\n",
    "    plt.bar(range(len(counts)), counts / sample_df.shape[0], tick_label=bin_edges[key][:-1])\n",
    "    plt.xlabel('Bins')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
