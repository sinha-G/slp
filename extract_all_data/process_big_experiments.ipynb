{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import polars as pl\n",
    "import tqdm\n",
    "import slippi as slp\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager\n",
    "import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "import gzip\n",
    "import pickle\n",
    "import feather\n",
    "import uuid\n",
    "import sys\n",
    "import time\n",
    "sys.path.append('../..')\n",
    "from slp.slp_package.slp_functions import one_hot_encode_flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"C:\\\\Users\\\\jaspa\\\\Grant ML\\\\slp\\\\data\\\\all_game_data_df.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "# print(df.info())\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.loc[df['is_teams'] == False]\n",
    "filtered_df = filtered_df.loc[filtered_df['num_players'] == 2]\n",
    "filtered_df = filtered_df.loc[filtered_df['player_1_type_name'] == 'HUMAN']\n",
    "filtered_df = filtered_df.loc[filtered_df['player_2_type_name'] == 'HUMAN']\n",
    "filtered_df = filtered_df.loc[filtered_df['conclusive'] == True]\n",
    "filtered_df = filtered_df.loc[filtered_df['source'] == 'mango']\n",
    "reduced_df = filtered_df[['slippi','source','length','player_1_character_name','player_2_character_name','player_1_display_name','player_2_display_name','player_1_netplay_code','player_2_netplay_code','stage_name','winning_player','player_1_did_win','player_2_did_win','player_1_inputs_np_save_path','player_2_inputs_np_save_path']]\n",
    "# Assuming filtered_df is your DataFrame\n",
    "# Concatenate the two columns into one Series\n",
    "all_netplay_codes = pd.concat([filtered_df['player_1_netplay_code'], filtered_df['player_2_netplay_code']])\n",
    "\n",
    "# Count the occurrences of each netplay code\n",
    "code_counts = all_netplay_codes.value_counts()\n",
    "\n",
    "# Display the top 10 most common values\n",
    "top_10 = code_counts.head(20)\n",
    "print(top_10)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['is_teams'].unique())\n",
    "reduced_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_np_path = os.path.join(df['inputs_np_common_path'][10],df['player_2_inputs_np_sub_path'][10])\n",
    "with gzip.open(input_np_path, 'rb') as f:\n",
    "    input_np = np.load(f)\n",
    "\n",
    "\n",
    "print(input_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_file(path,time_1,time_2,time_3):\n",
    "#     save_path = \"C:\\\\Users\\\\jaspa\\\\Grant ML\\\\feather df frame date test\"\n",
    "    \n",
    "#     time_1_start = time.time()\n",
    "#     frame_data_df = pd.read_feather(path)\n",
    "#     time_1.append(time.time()-time_1_start)\n",
    "    \n",
    "#     time_2_start = time.time()\n",
    "#     inputs = np.empty((4,frame_data_df.shape[0]),dtype = float)\n",
    "#     for i in range(frame_data_df.shape[0]):\n",
    "#         inputs[0, i] = frame_data_df['pre_joystick_x'][i]\n",
    "#         inputs[1, i] = frame_data_df['pre_joystick_y'][i]\n",
    "#         inputs[2, i] = frame_data_df['pre_cstick_x'][i]\n",
    "#         inputs[3, i] = frame_data_df['pre_cstick_y'][i] \n",
    "#         # inputs[4:,i] = one_hot_encode_flags(slp.event.Buttons.Physical,frame_data_df['pre_buttons_physical'][i])\n",
    "#     time_2.append(time.time()-time_2_start)\n",
    "    \n",
    "#     time_3_start = time.time()\n",
    "#     full_path = os.path.join(save_path, str(uuid.uuid4()) + '.npy.gz')\n",
    "#     with gzip.open(full_path, 'wb') as f:\n",
    "#         np.save(f, inputs)\n",
    "#     time_3.append(time.time() - time_3_start)\n",
    "#     return inputs         \n",
    "\n",
    "\n",
    "def process_file(path,time_1,time_2,time_3,buttons):\n",
    "    save_path = \"C:\\\\Users\\\\jaspa\\\\Grant ML\\\\feather df frame date test\"\n",
    "    time_1_start = time.time()\n",
    "    frame_data_df = pd.read_parquet(path,engine='pyarrow')\n",
    "    time_1.append(time.time()-time_1_start)\n",
    "    num_rows = frame_data_df.shape[0]\n",
    "\n",
    "    # Assuming one_hot_encode_flags can process a series and return a 2D array\n",
    "    # encoded_flags = one_hot_encode_flags(slp.event.Buttons.Physical, frame_data_df['pre_buttons_physical'])\n",
    "\n",
    "\n",
    "    time_2_start = time.time()\n",
    "\n",
    "    # button_states = frame_data_df['pre_buttons_logical'].to_numpy()[:, None]\n",
    "    # bitmasks = np.array([button.value for button in buttons if button != buttons.NONE])[None, :]\n",
    "    # encoded = (button_states & bitmasks) != 0\n",
    "    # inputs = np.empty((num_rows,25), dtype=float)\n",
    "    # inputs[ :,0] = frame_data_df['pre_joystick_x']\n",
    "    # inputs[ :,1] = frame_data_df['pre_joystick_y']\n",
    "    # inputs[ :,2] = frame_data_df['pre_cstick_x']\n",
    "    # inputs[ :,2] = frame_data_df['pre_cstick_y']\n",
    "    # inputs[:,4:] = encoded\n",
    "    # inputs.T\n",
    "    \n",
    "    # Convert the 'pre_buttons_logical' column to a NumPy array\n",
    "    button_states = frame_data_df['pre_buttons_logical'].values\n",
    "\n",
    "    # For each button, apply the bitmask and add a column to the DataFrame\n",
    "    for button in buttons:\n",
    "        if button == buttons.NONE:  # Skip the NONE value to avoid an unnecessary column\n",
    "            continue\n",
    "        # Use broadcasting to apply the bitmask and generate the one-hot encoded array\n",
    "    frame_data_df[button.name] = (button_states & button.value) != 0\n",
    "    \n",
    "    time_2.append(time.time()-time_2_start)\n",
    "    \n",
    "    time_3_start = time.time()\n",
    "    # full_path = os.path.join(save_path, f\"{uuid.uuid4()}.npy.gz\")\n",
    "    # with gzip.open(full_path, 'wb') as f:\n",
    "    #     np.save(f, inputs)\n",
    "    time_3.append(time.time() - time_3_start)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_file(path_list[0],1)\n",
    "manager = Manager()\n",
    "time_1 = manager.list()\n",
    "time_2 = manager.list()\n",
    "time_3 = manager.list()\n",
    "\n",
    "buttons = slp.event.Buttons.Logical\n",
    "        \n",
    "# Use joblib to parallelize processing of SLP files\n",
    "Parallel(n_jobs=-1, verbose=1)(delayed(process_file)(path,time_1,time_2,time_3,buttons) for path in tqdm.tqdm(path_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(time_1))\n",
    "print(sum(time_2))\n",
    "print(sum(time_3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_data_df =   pd.read_parquet(path_list[1],engine='pyarrow')\n",
    "\n",
    "button_states = frame_data_df['pre_buttons_logical'].values\n",
    "\n",
    "# For each button, apply the bitmask and add a column to the DataFrame\n",
    "for button in buttons:\n",
    "    if button == buttons.NONE:  # Skip the NONE value to avoid an unnecessary column\n",
    "        continue\n",
    "    # Use broadcasting to apply the bitmask and generate the one-hot enco\n",
    "    # ed array\n",
    "    frame_data_df[button.name] = (button_states & button.value) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_pd_load_test(df_row,time_1,time_2):\n",
    "    path_df  = os.path.join(df_row['inputs_df_common_path'],df_row['player_2_inputs_df_sub_path'])\n",
    "    path_np = os.path.join(df_row['inputs_np_common_path'],df_row['player_2_inputs_np_sub_path'])\n",
    "    \n",
    "    time_1_start = time.time()\n",
    "    frame_data_df = pd.read_parquet(path_df,engine='pyarrow')\n",
    "    time_1.append(time.time()-time_1_start)\n",
    "\n",
    "\n",
    "    time_2_start = time.time()\n",
    "    with gzip.open(path_np, 'rb') as f:\n",
    "        input_np = np.load(f)\n",
    "    time_2.append(time.time()-time_2_start)\n",
    "    \n",
    "    return \n",
    "\n",
    "# process_file(path_list[0],1)\n",
    "manager = Manager()\n",
    "time_1 = manager.list()\n",
    "time_2 = manager.list()\n",
    "        \n",
    "# Use joblib to parallelize processing of SLP files\n",
    "Parallel(n_jobs=-1, verbose=1)(delayed(np_pd_load_test)(df_row,time_1,time_2) for index, df_row in tqdm.tqdm(df.iterrows()))\n",
    "\n",
    "print(sum(time_1))\n",
    "print(sum(time_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_slp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
