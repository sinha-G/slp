{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager\n",
    "\n",
    "sys.path.append('../..')\n",
    "from slp.slp_package.slp_functions import create_merged_game_data_df, prepare_data_for_training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_merged_game_data_df(['public','ranked','mango'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "source_data = ['ranked', 'public']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True]\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK', 'PEACH', 'JIGGLYPUFF']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}\n",
    "    \n",
    "processed_df = prepare_data_for_training(source_data, general_features, player_features, opposing_player_features, label_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(processed_df['labels'].value_counts(), columns=['labels', 'count'])\n",
    "\n",
    "# Get the value counts of the 'labels' column\n",
    "label_counts = processed_df['labels'].value_counts()\n",
    "\n",
    "# Create a DataFrame from the value counts\n",
    "label_counts_df = pd.DataFrame(label_counts).reset_index()\n",
    "label_counts_df.columns = ['labels', 'count']\n",
    "\n",
    "print(label_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_segments_per_label = 50000\n",
    "segment_length_power = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def number_of_segments_per_game(df, segment_length_power, num_segments_per_label):\n",
    "#     \"\"\"\n",
    "    \n",
    "#     :param df: column 'length' should have 123 less already\n",
    "#     \"\"\"\n",
    "#     segment_length = 2 ** segment_length_power\n",
    "#     unique_labels = df['labels'].unique()\n",
    "    \n",
    "#     # Eventually, I do want to modify the original dataframe.\n",
    "#     df = df.copy()\n",
    "#     df = df[df['length'] > segment_length]\n",
    "#     df['float_num_segments'] = 0.\n",
    "#     # df['int_num_segments'] = 0 \n",
    "#     # df['frac_num_segments'] = 0.\n",
    "    \n",
    "#     label_info_list = []\n",
    "    \n",
    "#     for label in unique_labels:\n",
    "#         label_indices = df['labels'] == label\n",
    "#         adjusted_game_length = df.loc[label_indices, 'length'] - segment_length # A segment must start its own length before the end of the game.\n",
    "#         game_length_sum = adjusted_game_length.sum()\n",
    "#         shift_estimate = game_length_sum / num_segments_per_label # Idea: Put all the frame data in a (9,-) array, evenly space out segments.\n",
    "#         # The number of segments we take from each game will be roughly round(adjusted_game_length / shift_estimate).\n",
    "#         # df['int_num_segments'].sum() - num_segments_per_label =~ (number of games with this label) / 2\n",
    "#         # If we simply took round(adjusted_game_length / shift_estimate) segments per game, we would be off by a little bit.\n",
    "#         # Idea is to sort the games with this label decreasing by df['frac_num_segments'] and take one extra segment from the first\n",
    "#         # however many games needed to get the right number of segments.\n",
    "#         # Because we want exactly the right number of segments per label in each of test, train, and possibly val, we will calculate the\n",
    "#         # number of segments we take from each game after we split the games into those sets.\n",
    "#         df.loc[label_indices, 'float_num_segments'] = (adjusted_game_length / shift_estimate)\n",
    "#         # df.loc[label_indices, 'int_num_segments'] = adjusted_game_length // shift_estimate \n",
    "#         # df.loc[label_indices, 'frac_num_segments'] = adjusted_game_length / shift_estimate - df.loc[label_indices, 'int_num_segments']\n",
    "        \n",
    "#         label_info_list.append([label, df.loc[label_indices].shape[0], round(shift_estimate)])\n",
    "    \n",
    "#     label_info = pd.DataFrame(label_info_list, columns=['Label', 'Count', 'Estimated Shift'])\n",
    "    \n",
    "#     # Sort the label_info DataFrame by 'Count' in descending order\n",
    "#     label_info = label_info.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "#     return df, label_info\n",
    "\n",
    "# segments_per_game_df, label_info_df = number_of_segments_per_game(processed_df, segment_length_power, num_segments_per_label)\n",
    "# print(segments_per_game_df.groupby('labels')['float_num_segments'].sum())\n",
    "# print(segments_per_game_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def number_of_segments_per_game(df, segment_length_power, num_segments_per_label):\n",
    "    \"\"\"\n",
    "    Calculate the floating-point number of segments for each game in the dataframe based on the game's length\n",
    "    and the desired total number of segments per label.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): Dataframe containing game data with at least 'labels' and 'length' columns.\n",
    "    segment_length_power (int): Power of 2 to determine the segment length.\n",
    "    num_segments_per_label (int): Desired total number of segments per label.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: Updated dataframe with an additional column 'float_num_segments'.\n",
    "    DataFrame: Summary information about the labels, their counts, and estimated shift values.\n",
    "    \"\"\"\n",
    "    # Copy the dataframe to avoid modifying the original data\n",
    "    df = df.copy()\n",
    "\n",
    "    # Calculate segment length as a power of 2\n",
    "    segment_length = 2 ** segment_length_power\n",
    "\n",
    "    # Filter out games where length is less than or equal to the segment length\n",
    "    df = df[df['length'] > segment_length]\n",
    "\n",
    "    # Initialize the column to store the floating-point number of segments\n",
    "    df['float_num_segments'] = 0.0\n",
    "\n",
    "    # Initialize a list to store information about each label for later summary\n",
    "    label_info_list = []\n",
    "\n",
    "    # Iterate through each unique label to process segments\n",
    "    for label in df['labels'].unique():\n",
    "        # Identify rows matching the current label\n",
    "        label_indices = df['labels'] == label\n",
    "\n",
    "        # Adjust game length to ensure segments fit within the game length\n",
    "        adjusted_game_length = df.loc[label_indices, 'length'] - segment_length\n",
    "\n",
    "        # Sum the lengths of all games with the current label to estimate the shift value\n",
    "        game_length_sum = adjusted_game_length.sum()\n",
    "        shift_estimate = game_length_sum / num_segments_per_label\n",
    "\n",
    "        # Calculate the floating-point number of segments for each game\n",
    "        df.loc[label_indices, 'float_num_segments'] = adjusted_game_length / shift_estimate\n",
    "\n",
    "        # Collect label information including the total count and shift estimate\n",
    "        label_info = [label, adjusted_game_length.count(), round(shift_estimate)]\n",
    "        label_info_list.append(label_info)\n",
    "\n",
    "    # Create a dataframe from the label information list\n",
    "    label_info_df = pd.DataFrame(label_info_list, columns=['Label', 'Count', 'Shift'])\n",
    "\n",
    "    # Sort the label_info DataFrame by 'Count' in descending order for better readability\n",
    "    label_info_df = label_info_df.sort_values(by='Count', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return_columns = ['player_inputs_np_save_path',  'length', 'labels','float_num_segments']\n",
    "\n",
    "    return df[return_columns], label_info_df\n",
    "\n",
    "segments_per_game_df, label_info_df = number_of_segments_per_game(processed_df, segment_length_power, num_segments_per_label)\n",
    "# print(segments_per_game_df.groupby('labels')['float_num_segments'].sum())\n",
    "print(label_info_df)\n",
    "segments_per_game_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_games(df, num_segments_per_label, test_ratio=0.15, val_ratio=0.15, val=True):\n",
    "    \"\"\"\n",
    "    Splits the games into training, testing, and optionally validation sets based on the approximate number of segments per game.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The output of number_of_segments_per_game containing game data with 'labels' and 'float_num_segments'.\n",
    "    num_segments_per_label (int): Total number of segments desired per label.\n",
    "    test_ratio (float): The proportion of data to be used for the test set.\n",
    "    val_ratio (float): The proportion of data to be used for the validation set.\n",
    "    val (bool): Whether to create a validation set.\n",
    "    \n",
    "    Returns:\n",
    "    test_df (DataFrame): Data for testing.\n",
    "    val_df (DataFrame): Data for validation (if val is True, otherwise an empty DataFrame).\n",
    "    train_df (DataFrame): Data for training.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the dataframe to avoid modifying the original data\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Initialize empty lists to store split dataframes\n",
    "    test_dfs, val_dfs, train_dfs = [], [], []\n",
    "\n",
    "    # Calculate the number of segments for each split based on the provided ratios\n",
    "    num_segments_test = round(num_segments_per_label * test_ratio)\n",
    "    num_segments_val = round(num_segments_per_label * val_ratio) * val\n",
    "    num_segments_train = num_segments_per_label - num_segments_test - num_segments_val\n",
    "    \n",
    "    # Process each label separately\n",
    "    for label in df['labels'].unique():\n",
    "        # Filter the dataframe for the current label and shuffle\n",
    "        label_df = df[df['labels'] == label].sample(frac=1).reset_index(drop=True)\n",
    "         # Ensure 'float_num_segments' is in label_df before proceeding\n",
    "        if 'float_num_segments' not in label_df.columns:\n",
    "            print(f\"'float_num_segments' column is missing in label_df for label {label}\")\n",
    "            continue  # Skip this label if the required column is missing\n",
    "        \n",
    "        # Calculate cumulative sum to find the cutoff points for splitting\n",
    "        num_segments_cumsum = label_df['float_num_segments'].cumsum()\n",
    "\n",
    "        # Determine the index to split test and train datasets\n",
    "        test_idx = num_segments_cumsum[num_segments_cumsum <= num_segments_test].last_valid_index() or 0\n",
    "        val_idx = num_segments_cumsum[num_segments_cumsum <= num_segments_test + num_segments_val].last_valid_index() or test_idx\n",
    "\n",
    "        # Split the data based on calculated indices\n",
    "        test_label_df = label_df.iloc[:test_idx + 1].copy()\n",
    "        val_label_df = label_df.iloc[test_idx + 1:val_idx + 1].copy() if val else pd.DataFrame(columns = label_df.columns)\n",
    "        train_label_df = label_df.iloc[val_idx + 1:].copy()\n",
    "        # print(test_label_df.head())\n",
    "\n",
    "        # Calculate the actual number of segments to extract for each set\n",
    "        # This process adjusts the 'num_segments' by distributing the rounding errors across the segments\n",
    "        # to ensure that the total number of segments remains as close as possible to the desired count\n",
    "        for split_df, num_segments_split in zip(\n",
    "            [test_label_df, val_label_df, train_label_df],\n",
    "            [num_segments_test, num_segments_val, num_segments_train]\n",
    "        ):\n",
    "            # Start with floor values of 'float_num_segments' and calculate the residual fractional part\n",
    "            split_df['num_segments'] = split_df['float_num_segments'].astype(int)\n",
    "            split_df['frac_part'] = split_df['float_num_segments'] - split_df['num_segments']\n",
    "            split_df.sort_values(by='frac_part', ascending=False, inplace=True)\n",
    "\n",
    "            # Distribute rounding residuals to match the total segment count precisely\n",
    "            residual_count = num_segments_split - split_df['num_segments'].sum()\n",
    "            split_df.iloc[:residual_count, split_df.columns.get_loc('num_segments')] += 1\n",
    "\n",
    "        # Append the processed dataframes to their respective lists\n",
    "        test_dfs.append(test_label_df)\n",
    "        val_dfs.append(val_label_df)\n",
    "        train_dfs.append(train_label_df)\n",
    "\n",
    "    # Concatenate all the dataframes in each list to create the final splits\n",
    "    return_columns = ['player_inputs_np_save_path',  'length', 'num_segments','labels']\n",
    "    test_df = pd.concat(test_dfs, ignore_index=True)[return_columns]\n",
    "    val_df = pd.concat(val_dfs, ignore_index=True)[return_columns] if val else pd.DataFrame(columns=return_columns)\n",
    "    train_df = pd.concat(train_dfs, ignore_index=True)[return_columns]\n",
    "    \n",
    "    # Encode the labels for training\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(df['labels'].unique())\n",
    "    test_df['encoded_labels'] = label_encoder.fit_transform(test_df['labels'])\n",
    "    val_df['encoded_labels'] = label_encoder.fit_transform(val_df['labels'])\n",
    "    train_df['encoded_labels'] = label_encoder.fit_transform(train_df['labels'])\n",
    "\n",
    "    return test_df, val_df, train_df\n",
    "\n",
    "# print(segments_per_game_df.head())\n",
    "test_df, val_df, train_df = divide_games(segments_per_game_df, num_segments_per_label, test_ratio=.15, val_ratio=.15, val=True)\n",
    "# Sum 'num_segments' for each 'label'\n",
    "print(test_df.groupby('labels')['num_segments'].sum())\n",
    "# Sum 'num_segments' for each 'label'\n",
    "if not val_df.empty:\n",
    "    print(val_df.groupby('labels')['num_segments'].sum())\n",
    "# Sum 'num_segments' for each 'label'\n",
    "print(train_df.groupby('labels')['num_segments'].sum())\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def create_training_dataframe(df, segment_length_power):\n",
    "    \"\"\"\n",
    "    Generate a DataFrame that lists the segments for training, where each row corresponds to a segment.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing the output from `divide_games`, which includes 'num_segments' and 'length'.\n",
    "    segment_length_power (int): The power of 2 used to determine the segment length.\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame: A new DataFrame where each row represents a segment, including the start index of each segment.\n",
    "    \"\"\"\n",
    "    # Calculate the segment length as a power of 2\n",
    "    segment_length = 2 ** segment_length_power\n",
    "    \n",
    "    # Retrieve the 'num_segments' column as an array to determine how many times to repeat each row\n",
    "    repeats = df['num_segments'].values\n",
    "\n",
    "    # Repeat each index in the DataFrame according to the number of segments it should be split into\n",
    "    index_repeated = np.repeat(df.index, repeats)\n",
    "    \n",
    "    # Duplicate rows in the DataFrame based on the repeat counts for each row\n",
    "    df_repeated = df.loc[index_repeated].reset_index(drop=True)\n",
    "    \n",
    "    # Generate a sequential 'segment_index' for each group of repeated rows\n",
    "    segment_indices = np.concatenate([np.arange(n, dtype=np.int16) for n in repeats])\n",
    "    \n",
    "    # Calculate the start index of each segment within the game\n",
    "    df_repeated['segment_start_index'] = ((df_repeated['length'] - segment_length) // df_repeated['num_segments']) * segment_indices\n",
    "    \n",
    "    # Drop columns that are no longer necessary after computing 'segment_start_index'\n",
    "    df_repeated = df_repeated.drop(columns=['length', 'num_segments'])\n",
    "\n",
    "    # Add 'segment_index' to the DataFrame to keep track of each segment within its group\n",
    "    df_repeated['segment_index'] = segment_indices\n",
    "    \n",
    "    return df_repeated\n",
    "\n",
    "\n",
    "train_segments_df = create_training_dataframe(train_df, 10)\n",
    "print(train_segments_df.value_counts('labels'))\n",
    "# print(train_segments_df.shape)\n",
    "   \n",
    "test_segments_df = create_training_dataframe(test_df, 10)\n",
    "print(test_segments_df.value_counts('labels'))\n",
    "# print(test_segments_df.shape)\n",
    "if not val_df.empty:\n",
    "    val_segments_df = create_training_dataframe(val_df, 10)\n",
    "    print(val_segments_df.value_counts('labels'))\n",
    "    # print(val_segments_df.shape)    \n",
    "    \n",
    "train_segments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_training_numpy(df, segment_length_power):\n",
    "    \"\"\"\n",
    "    Creates a NumPy array containing all the segments from the dataframe, with parallel processing for efficiency.\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame containing game data, must be one of the outputs from `divide_games`.\n",
    "    segment_length_power (int): The power of 2 that defines the length of each segment.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing two elements; the first is a NumPy array of input arrays, \n",
    "           and the second is a NumPy array of corresponding labels.\n",
    "    \"\"\"\n",
    "    \n",
    "    def process_game(path, label, length, num_segments, segment_length):\n",
    "        \"\"\"\n",
    "        Loads the game data from the specified path and extracts segments of the specified length.\n",
    "        \n",
    "        Parameters:\n",
    "        path (str): File path to the numpy array containing game data.\n",
    "        label (str): The label associated with the game data.\n",
    "        length (int): The total length of the game data.\n",
    "        num_segments (int): The number of segments to be extracted from the game data.\n",
    "        segment_length (int): The length of each segment.\n",
    "        \n",
    "        Appends the extracted segments and their labels to a shared list accessible by the parent process.\n",
    "        \"\"\"\n",
    "        # Return immediately if there are no segments to process\n",
    "        if num_segments == 0:\n",
    "            return\n",
    "        \n",
    "        # Load the game data from the specified path\n",
    "        with gzip.open(path, 'rb') as f:\n",
    "            inputs_array = np.load(f)\n",
    "        \n",
    "        # Initialize an array to hold the extracted segments\n",
    "        segments_array = np.empty((num_segments, 9, segment_length), dtype=np.single)\n",
    "        \n",
    "        # Calculate the shift between starting points of consecutive segments\n",
    "        segment_shift = (length - segment_length) // num_segments\n",
    "        \n",
    "        # Extract segments from the input array\n",
    "        for i in range(num_segments):\n",
    "            start_index = segment_shift * i\n",
    "            segments_array[i, :, :] = inputs_array[:, start_index : start_index + segment_length]\n",
    "        \n",
    "        # Append the extracted segments and their label to the shared list\n",
    "        shared_list.append((segments_array, [label] * num_segments))\n",
    "    \n",
    "    # Calculate the segment length using the power of 2\n",
    "    segment_length = 2 ** segment_length_power\n",
    "    \n",
    "    # Prepare tasks for parallel processing\n",
    "    tasks = [\n",
    "        (row['player_inputs_np_save_path'], row['labels'], row['length'], row['num_segments']) \n",
    "        for index, row in df.iterrows()\n",
    "    ]\n",
    "    \n",
    "    # Use Manager to create a shared list for collecting results from parallel processes\n",
    "    manager = Manager()\n",
    "    shared_list = manager.list()\n",
    "    \n",
    "    # Process each game in parallel to extract segments\n",
    "    Parallel(n_jobs=-1, verbose=0)(\n",
    "        delayed(process_game)(task[0], task[1], task[2], task[3], segment_length) \n",
    "        for task in tqdm.tqdm(tasks)\n",
    "    )\n",
    "    \n",
    "    # After parallel processing, extract the segments and labels from the shared list\n",
    "    input_arrays, label_lists = zip(*list(shared_list))\n",
    "    \n",
    "    # Combine all segment arrays into one array and all labels into one list\n",
    "    input_array = np.concatenate(input_arrays, axis=0)\n",
    "    labels = np.concatenate(label_lists)\n",
    "\n",
    "    return input_array, labels\n",
    "\n",
    "input_array, labels = create_training_numpy(train_df, 10)\n",
    "print(input_array.shape)\n",
    "print(labels.shape)\n",
    "input_array, labels = create_training_numpy(test_df, 10)\n",
    "print(input_array.shape)\n",
    "print(labels.shape)\n",
    "if not val_df.empty:\n",
    "    input_array, labels = create_training_numpy(val_df, 10)\n",
    "    print(input_array.shape)\n",
    "    print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
