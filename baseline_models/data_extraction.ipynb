{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Outline</h2>\n",
    "In this notebook we extract the input data from Fox vs Sheik games. We split each game into n second segments to get more training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import slippi as slp\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Initialize some variables</h2>\n",
    "We can change the number of seconds per segment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_per_segment = 15\n",
    "frames_per_segment = seconds_per_segment * 60\n",
    "game_data_columns = ['spl_file', 'game_segment', 'is_sheik', 'input_data']\n",
    "dataset_path = '../Slippi_Public_Dataset_v3/'\n",
    "slp_files = [file for file in os.listdir(dataset_path) if file.endswith('.slp') and 'Sheik' in file and 'Fox' in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preliminary Functions </h2>\n",
    "We use these functions to one-hot encode the button bitmask and get the frame input data for a given port number and frames object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(bitmask):\n",
    "    labels = ['DPAD_LEFT', 'DPAD_RIGHT', 'DPAD_DOWN', 'DPAD_UP', 'Z', 'R', 'L', 'A', 'B', 'X', 'Y', 'START']\n",
    "    encoded_values = [1, 2, 4, 8, 16, 32, 64, 256, 512, 1024, 2048, 4096]\n",
    "\n",
    "    # Create a dictionary mapping labels to their encoded values\n",
    "    label_to_value = dict(zip(labels, encoded_values))\n",
    "\n",
    "    # Initialize a list to store the one-hot encoded values\n",
    "    one_hot_encoded = [0] * len(labels)\n",
    "\n",
    "    # Iterate through labels and set the corresponding one-hot encoded value\n",
    "    for label, value in label_to_value.items():\n",
    "        if bitmask & value:\n",
    "            one_hot_encoded[labels.index(label)] = 1\n",
    "\n",
    "    return one_hot_encoded\n",
    "\n",
    "# Create a numpy list that is the correct size and fill it with a loop\n",
    "def get_frame_data(frames, port):\n",
    "    inputs = np.empty((frames_per_segment, 18))  # Initialize an empty Numpy array\n",
    "    for i, frame in enumerate(frames):  \n",
    "        buttons = one_hot_encode(frame.ports[port].leader.pre.buttons.physical.value)\n",
    "        j_x = frame.ports[port].leader.pre.joystick.x\n",
    "        j_y = frame.ports[port].leader.pre.joystick.y\n",
    "        c_x = frame.ports[port].leader.pre.cstick.x\n",
    "        c_y = frame.ports[port].leader.pre.cstick.y\n",
    "        t_l = frame.ports[port].leader.pre.triggers.physical.l\n",
    "        t_r = frame.ports[port].leader.pre.triggers.physical.r\n",
    "\n",
    "        frame_data = buttons + [j_x, j_y, c_x, c_y, t_l, t_r]\n",
    "        inputs[i] = frame_data\n",
    "\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Process SLP function</h2>\n",
    "The function that will be called for each SLP file we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_slp_file(slp_file, dataset_path, game_data):\n",
    "    try:\n",
    "        file_path = os.path.join(dataset_path, slp_file)\n",
    "        game = slp.Game(file_path)\n",
    "        frames = game.frames\n",
    "         \n",
    "        # Check game is long enough\n",
    "        game_length = game.metadata.duration\n",
    "        if game_length < 123 + frames_per_segment:\n",
    "            return\n",
    "        \n",
    "        # Find the ports the players are using\n",
    "        occupied_ports = [i for i, port in enumerate(game.start.players) if port is not None]\n",
    "        if len(occupied_ports) > 2:  # Ignore games that aren't singles\n",
    "            return\n",
    "        if game.start.players[occupied_ports[0]].character.name == 'SHEIK':\n",
    "            sheik_port = occupied_ports[0]\n",
    "            fox_port = occupied_ports[1]\n",
    "        else:\n",
    "            sheik_port = occupied_ports[1]\n",
    "            fox_port = occupied_ports[0]\n",
    "\n",
    "        # Is one of the players a CPU? If a player is a computer, ignor the game\n",
    "        # event.players[sheik_port].type.value returns 0 if human and 1 if cpu\n",
    "        if game.start.players[sheik_port].type.value or game.start.players[fox_port].type.value:\n",
    "            return\n",
    "\n",
    "        num_game_segments = game_length // frames_per_segment # To get more training data we take all 15s segments of the game\n",
    "        for i in range(num_game_segments):\n",
    "            # Get Sheik data for the ith game segment\n",
    "            sheik_input_data = get_frame_data(frames[123 + i * frames_per_segment: 123 + (i + 1) * frames_per_segment], sheik_port)\n",
    "            game_data.append([slp_file, i, 1, sheik_input_data])\n",
    "            \n",
    "            # Get Fox data for the ith game segment\n",
    "            fox_input_data =  get_frame_data(frames[123 + i * frames_per_segment: 123 + (i + 1) * frames_per_segment], fox_port)\n",
    "            game_data.append([slp_file, i, 0, fox_input_data])\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {slp_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Multiprocess data extraction </h2>\n",
    "We use joblib to speed the extraction of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_files = -1 # How many files we want to extract data from\n",
    "\n",
    "# Create shared lists to store results\n",
    "manager = Manager()\n",
    "game_data_list = manager.list()\n",
    "\n",
    "# Use joblib to parallelize processing of SLP files\n",
    "Parallel(n_jobs=-1, verbose=1)(delayed(process_slp_file)(slp_file, dataset_path, game_data_list) for slp_file in tqdm.tqdm(slp_files[:num_files]))\n",
    "\n",
    "# Make the data frame\n",
    "game_data_df = pd.DataFrame(list(game_data_list),columns = game_data_columns)\n",
    "print(game_data_df.shape) # Check the shape to make sure we actually did something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Save the extracted input data</h2>\n",
    "Save the data as a pickle file. Pickle is not the best format, but it seems to be the only one that works with numpy arrays in the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the file path to save the pickle file\n",
    "# pickle_file_path = '../data/Sheik_vs_Fox_15_second_segments.pkl'\n",
    "\n",
    "# # Save the game data as a pickle file\n",
    "# game_data_df.to_pickle(pickle_file_path)\n",
    "\n",
    "## Check to see if it is saved correctly\n",
    "# df = pd.read_pickle(pickle_file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
