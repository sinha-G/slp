{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOX               103069\n",
      "FALCO              90719\n",
      "MARTH              53728\n",
      "CAPTAIN_FALCON     38006\n",
      "SHEIK              27623\n",
      "PEACH              17438\n",
      "JIGGLYPUFF         16374\n",
      "SAMUS               9524\n",
      "ICE_CLIMBERS        6849\n",
      "GANONDORF           6655\n",
      "YOSHI               5725\n",
      "LUIGI               5230\n",
      "DR_MARIO            4202\n",
      "PIKACHU             4096\n",
      "LINK                2502\n",
      "NESS                2306\n",
      "DONKEY_KONG         2026\n",
      "GAME_AND_WATCH      1967\n",
      "MEWTWO              1775\n",
      "MARIO               1713\n",
      "YOUNG_LINK          1447\n",
      "ROY                 1272\n",
      "BOWSER               940\n",
      "KIRBY                556\n",
      "PICHU                230\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Label   Count  Shift\n",
      "0              FOX  103069  24187\n",
      "1            FALCO   90717  21015\n",
      "2            MARTH   53728  13321\n",
      "3   CAPTAIN_FALCON   38006   8766\n",
      "4            SHEIK   27623   7393\n",
      "5            PEACH   17438   4925\n",
      "6       JIGGLYPUFF   16374   4448\n",
      "7            SAMUS    9524   2879\n",
      "8     ICE_CLIMBERS    6849   1952\n",
      "9        GANONDORF    6655   1601\n",
      "10           YOSHI    5725   1528\n",
      "11           LUIGI    5230   1433\n",
      "12        DR_MARIO    4202   1133\n",
      "13         PIKACHU    4096   1124\n",
      "14            LINK    2502    700\n",
      "15            NESS    2306    727\n",
      "16     DONKEY_KONG    2026    542\n",
      "17  GAME_AND_WATCH    1967    462\n",
      "18          MEWTWO    1775    564\n",
      "19           MARIO    1713    478\n",
      "20      YOUNG_LINK    1447    410\n",
      "21             ROY    1272    336\n",
      "22          BOWSER     940    274\n",
      "23           KIRBY     556    155\n",
      "24           PICHU     230     61\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(60,40000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(60, proportion_of_segments=1, test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53712416, 6)\n",
      "(13425723, 6)\n",
      "0.1999716286446367\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>236</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           player_inputs_np_sub_path labels  encoded_labels  \\\n",
       "0  ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...  FALCO               4   \n",
       "1  ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...  FALCO               4   \n",
       "2  ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...  FALCO               4   \n",
       "3  ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...  FALCO               4   \n",
       "4  ranked\\FALCO\\4fd1d5a3-ace3-4d28-b529-3ea4a12ce...  FALCO               4   \n",
       "\n",
       "   segment_start_index  segment_index  segment_length  \n",
       "0                    0              0              60  \n",
       "1                   59              1              60  \n",
       "2                  118              2              60  \n",
       "3                  177              3              60  \n",
       "4                  236              4              60  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "        if self.transform:\n",
    "            segment = self.transform(segment)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(segment[:,segment_start:segment_end]).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, loaders, device, num_epochs=1):\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        total = 0\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            \n",
    "            # Resets the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Runs the forward pass with autocasting.\n",
    "            with autocast():\n",
    "                output_gpu = model(target_gpu)\n",
    "                loss = criterion(output_gpu, target_gpu)\n",
    "            \n",
    "            # Scales loss and calls backward() to create scaled gradients\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Clip gradients to avoid explosion\n",
    "            scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            # Before calling step(), check for inf or NaN values in the gradients\n",
    "            if any(torch.isinf(p.grad).any() or torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: inf or NaN values in gradients!\")\n",
    "                \n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "\n",
    "            # Update progress\n",
    "            train_loss += loss.item()\n",
    "            total += target_gpu.size(0)\n",
    "            train_loader_tqdm.set_postfix(loss=f'{train_loss / (total):.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu * 10, target_gpu * 10).item()\n",
    "            total += target_gpu.size(0)\n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.4f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / total:.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 60]             640\n",
      "       BatchNorm1d-2               [-1, 64, 60]             128\n",
      "              ReLU-3               [-1, 64, 60]               0\n",
      "            Conv1d-4               [-1, 64, 60]          12,352\n",
      "       BatchNorm1d-5               [-1, 64, 60]             128\n",
      "              ReLU-6               [-1, 64, 60]               0\n",
      "            Conv1d-7              [-1, 256, 60]          16,640\n",
      "       BatchNorm1d-8              [-1, 256, 60]             512\n",
      "            Conv1d-9              [-1, 256, 60]           2,560\n",
      "      BatchNorm1d-10              [-1, 256, 60]             512\n",
      "             ReLU-11              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-12              [-1, 256, 60]               0\n",
      "           Conv1d-13               [-1, 64, 60]          16,448\n",
      "      BatchNorm1d-14               [-1, 64, 60]             128\n",
      "             ReLU-15               [-1, 64, 60]               0\n",
      "           Conv1d-16               [-1, 64, 60]          12,352\n",
      "      BatchNorm1d-17               [-1, 64, 60]             128\n",
      "             ReLU-18               [-1, 64, 60]               0\n",
      "           Conv1d-19              [-1, 256, 60]          16,640\n",
      "      BatchNorm1d-20              [-1, 256, 60]             512\n",
      "             ReLU-21              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-22              [-1, 256, 60]               0\n",
      "           Conv1d-23               [-1, 64, 60]          16,448\n",
      "      BatchNorm1d-24               [-1, 64, 60]             128\n",
      "             ReLU-25               [-1, 64, 60]               0\n",
      "           Conv1d-26               [-1, 64, 60]          12,352\n",
      "      BatchNorm1d-27               [-1, 64, 60]             128\n",
      "             ReLU-28               [-1, 64, 60]               0\n",
      "           Conv1d-29              [-1, 256, 60]          16,640\n",
      "      BatchNorm1d-30              [-1, 256, 60]             512\n",
      "             ReLU-31              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-32              [-1, 256, 60]               0\n",
      "           Conv1d-33              [-1, 128, 60]          32,896\n",
      "      BatchNorm1d-34              [-1, 128, 60]             256\n",
      "             ReLU-35              [-1, 128, 60]               0\n",
      "           Conv1d-36              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-37              [-1, 128, 30]             256\n",
      "             ReLU-38              [-1, 128, 30]               0\n",
      "           Conv1d-39              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-40              [-1, 512, 30]           1,024\n",
      "           Conv1d-41              [-1, 512, 30]         131,584\n",
      "      BatchNorm1d-42              [-1, 512, 30]           1,024\n",
      "             ReLU-43              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-44              [-1, 512, 30]               0\n",
      "           Conv1d-45              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-46              [-1, 128, 30]             256\n",
      "             ReLU-47              [-1, 128, 30]               0\n",
      "           Conv1d-48              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-49              [-1, 128, 30]             256\n",
      "             ReLU-50              [-1, 128, 30]               0\n",
      "           Conv1d-51              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-52              [-1, 512, 30]           1,024\n",
      "             ReLU-53              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-54              [-1, 512, 30]               0\n",
      "           Conv1d-55              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-56              [-1, 128, 30]             256\n",
      "             ReLU-57              [-1, 128, 30]               0\n",
      "           Conv1d-58              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-59              [-1, 128, 30]             256\n",
      "             ReLU-60              [-1, 128, 30]               0\n",
      "           Conv1d-61              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-62              [-1, 512, 30]           1,024\n",
      "             ReLU-63              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-64              [-1, 512, 30]               0\n",
      "           Conv1d-65              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-66              [-1, 128, 30]             256\n",
      "             ReLU-67              [-1, 128, 30]               0\n",
      "           Conv1d-68              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-69              [-1, 128, 30]             256\n",
      "             ReLU-70              [-1, 128, 30]               0\n",
      "           Conv1d-71              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-72              [-1, 512, 30]           1,024\n",
      "             ReLU-73              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-74              [-1, 512, 30]               0\n",
      "           Conv1d-75              [-1, 256, 30]         131,328\n",
      "      BatchNorm1d-76              [-1, 256, 30]             512\n",
      "             ReLU-77              [-1, 256, 30]               0\n",
      "           Conv1d-78              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-79              [-1, 256, 15]             512\n",
      "             ReLU-80              [-1, 256, 15]               0\n",
      "           Conv1d-81             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-82             [-1, 1024, 15]           2,048\n",
      "           Conv1d-83             [-1, 1024, 15]         525,312\n",
      "      BatchNorm1d-84             [-1, 1024, 15]           2,048\n",
      "             ReLU-85             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-86             [-1, 1024, 15]               0\n",
      "           Conv1d-87              [-1, 256, 15]         262,400\n",
      "      BatchNorm1d-88              [-1, 256, 15]             512\n",
      "             ReLU-89              [-1, 256, 15]               0\n",
      "           Conv1d-90              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-91              [-1, 256, 15]             512\n",
      "             ReLU-92              [-1, 256, 15]               0\n",
      "           Conv1d-93             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-94             [-1, 1024, 15]           2,048\n",
      "             ReLU-95             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-96             [-1, 1024, 15]               0\n",
      "           Conv1d-97              [-1, 256, 15]         262,400\n",
      "      BatchNorm1d-98              [-1, 256, 15]             512\n",
      "             ReLU-99              [-1, 256, 15]               0\n",
      "          Conv1d-100              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-101              [-1, 256, 15]             512\n",
      "            ReLU-102              [-1, 256, 15]               0\n",
      "          Conv1d-103             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-104             [-1, 1024, 15]           2,048\n",
      "            ReLU-105             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-106             [-1, 1024, 15]               0\n",
      "          Conv1d-107              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-108              [-1, 256, 15]             512\n",
      "            ReLU-109              [-1, 256, 15]               0\n",
      "          Conv1d-110              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-111              [-1, 256, 15]             512\n",
      "            ReLU-112              [-1, 256, 15]               0\n",
      "          Conv1d-113             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-114             [-1, 1024, 15]           2,048\n",
      "            ReLU-115             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-116             [-1, 1024, 15]               0\n",
      "          Conv1d-117              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-118              [-1, 256, 15]             512\n",
      "            ReLU-119              [-1, 256, 15]               0\n",
      "          Conv1d-120              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-121              [-1, 256, 15]             512\n",
      "            ReLU-122              [-1, 256, 15]               0\n",
      "          Conv1d-123             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-124             [-1, 1024, 15]           2,048\n",
      "            ReLU-125             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-126             [-1, 1024, 15]               0\n",
      "          Conv1d-127              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-128              [-1, 256, 15]             512\n",
      "            ReLU-129              [-1, 256, 15]               0\n",
      "          Conv1d-130              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-131              [-1, 256, 15]             512\n",
      "            ReLU-132              [-1, 256, 15]               0\n",
      "          Conv1d-133             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-134             [-1, 1024, 15]           2,048\n",
      "            ReLU-135             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-136             [-1, 1024, 15]               0\n",
      "          Conv1d-137              [-1, 512, 15]         524,800\n",
      "     BatchNorm1d-138              [-1, 512, 15]           1,024\n",
      "            ReLU-139              [-1, 512, 15]               0\n",
      "          Conv1d-140               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-141               [-1, 512, 8]           1,024\n",
      "            ReLU-142               [-1, 512, 8]               0\n",
      "          Conv1d-143              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-144              [-1, 2048, 8]           4,096\n",
      "          Conv1d-145              [-1, 2048, 8]       2,099,200\n",
      "     BatchNorm1d-146              [-1, 2048, 8]           4,096\n",
      "            ReLU-147              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-148              [-1, 2048, 8]               0\n",
      "          Conv1d-149               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-150               [-1, 512, 8]           1,024\n",
      "            ReLU-151               [-1, 512, 8]               0\n",
      "          Conv1d-152               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-153               [-1, 512, 8]           1,024\n",
      "            ReLU-154               [-1, 512, 8]               0\n",
      "          Conv1d-155              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-156              [-1, 2048, 8]           4,096\n",
      "            ReLU-157              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-158              [-1, 2048, 8]               0\n",
      "          Conv1d-159               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-160               [-1, 512, 8]           1,024\n",
      "            ReLU-161               [-1, 512, 8]               0\n",
      "          Conv1d-162               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-163               [-1, 512, 8]           1,024\n",
      "            ReLU-164               [-1, 512, 8]               0\n",
      "          Conv1d-165              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-166              [-1, 2048, 8]           4,096\n",
      "            ReLU-167              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-168              [-1, 2048, 8]               0\n",
      "          Linear-169                   [-1, 64]       1,048,640\n",
      "            ReLU-170                   [-1, 64]               0\n",
      "          Linear-171                   [-1, 64]           4,160\n",
      "            ReLU-172                   [-1, 64]               0\n",
      "          Linear-173                   [-1, 64]           4,160\n",
      "            ReLU-174                   [-1, 64]               0\n",
      "          Linear-175                [-1, 16384]       1,064,960\n",
      "            ReLU-176                [-1, 16384]               0\n",
      " ConvTranspose1d-177               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-178               [-1, 512, 8]           1,024\n",
      "            ReLU-179               [-1, 512, 8]               0\n",
      " ConvTranspose1d-180               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-181               [-1, 512, 8]           1,024\n",
      "            ReLU-182               [-1, 512, 8]               0\n",
      " ConvTranspose1d-183              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-184              [-1, 2048, 8]           4,096\n",
      "            ReLU-185              [-1, 2048, 8]               0\n",
      "Decoder_Bottleneck-186              [-1, 2048, 8]               0\n",
      " ConvTranspose1d-187               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-188               [-1, 512, 8]           1,024\n",
      "            ReLU-189               [-1, 512, 8]               0\n",
      " ConvTranspose1d-190               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-191               [-1, 512, 8]           1,024\n",
      "            ReLU-192               [-1, 512, 8]               0\n",
      " ConvTranspose1d-193              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-194              [-1, 2048, 8]           4,096\n",
      "            ReLU-195              [-1, 2048, 8]               0\n",
      "Decoder_Bottleneck-196              [-1, 2048, 8]               0\n",
      " ConvTranspose1d-197               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-198               [-1, 512, 8]           1,024\n",
      "            ReLU-199               [-1, 512, 8]               0\n",
      " ConvTranspose1d-200              [-1, 512, 15]         786,944\n",
      "     BatchNorm1d-201              [-1, 512, 15]           1,024\n",
      "            ReLU-202              [-1, 512, 15]               0\n",
      " ConvTranspose1d-203             [-1, 1024, 15]         525,312\n",
      "     BatchNorm1d-204             [-1, 1024, 15]           2,048\n",
      " ConvTranspose1d-205             [-1, 1024, 15]       2,098,176\n",
      "     BatchNorm1d-206             [-1, 1024, 15]           2,048\n",
      "            ReLU-207             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-208             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-209              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-210              [-1, 256, 15]             512\n",
      "            ReLU-211              [-1, 256, 15]               0\n",
      " ConvTranspose1d-212              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-213              [-1, 256, 15]             512\n",
      "            ReLU-214              [-1, 256, 15]               0\n",
      " ConvTranspose1d-215             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-216             [-1, 1024, 15]           2,048\n",
      "            ReLU-217             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-218             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-219              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-220              [-1, 256, 15]             512\n",
      "            ReLU-221              [-1, 256, 15]               0\n",
      " ConvTranspose1d-222              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-223              [-1, 256, 15]             512\n",
      "            ReLU-224              [-1, 256, 15]               0\n",
      " ConvTranspose1d-225             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-226             [-1, 1024, 15]           2,048\n",
      "            ReLU-227             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-228             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-229              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-230              [-1, 256, 15]             512\n",
      "            ReLU-231              [-1, 256, 15]               0\n",
      " ConvTranspose1d-232              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-233              [-1, 256, 15]             512\n",
      "            ReLU-234              [-1, 256, 15]               0\n",
      " ConvTranspose1d-235             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-236             [-1, 1024, 15]           2,048\n",
      "            ReLU-237             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-238             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-239              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-240              [-1, 256, 15]             512\n",
      "            ReLU-241              [-1, 256, 15]               0\n",
      " ConvTranspose1d-242              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-243              [-1, 256, 15]             512\n",
      "            ReLU-244              [-1, 256, 15]               0\n",
      " ConvTranspose1d-245             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-246             [-1, 1024, 15]           2,048\n",
      "            ReLU-247             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-248             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-249              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-250              [-1, 256, 15]             512\n",
      "            ReLU-251              [-1, 256, 15]               0\n",
      " ConvTranspose1d-252              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-253              [-1, 256, 15]             512\n",
      "            ReLU-254              [-1, 256, 15]               0\n",
      " ConvTranspose1d-255             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-256             [-1, 1024, 15]           2,048\n",
      "            ReLU-257             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-258             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-259              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-260              [-1, 256, 15]             512\n",
      "            ReLU-261              [-1, 256, 15]               0\n",
      " ConvTranspose1d-262              [-1, 256, 30]         196,864\n",
      "     BatchNorm1d-263              [-1, 256, 30]             512\n",
      "            ReLU-264              [-1, 256, 30]               0\n",
      " ConvTranspose1d-265              [-1, 512, 30]         131,584\n",
      "     BatchNorm1d-266              [-1, 512, 30]           1,024\n",
      " ConvTranspose1d-267              [-1, 512, 30]         524,800\n",
      "     BatchNorm1d-268              [-1, 512, 30]           1,024\n",
      "            ReLU-269              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-270              [-1, 512, 30]               0\n",
      " ConvTranspose1d-271              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-272              [-1, 128, 30]             256\n",
      "            ReLU-273              [-1, 128, 30]               0\n",
      " ConvTranspose1d-274              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-275              [-1, 128, 30]             256\n",
      "            ReLU-276              [-1, 128, 30]               0\n",
      " ConvTranspose1d-277              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-278              [-1, 512, 30]           1,024\n",
      "            ReLU-279              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-280              [-1, 512, 30]               0\n",
      " ConvTranspose1d-281              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-282              [-1, 128, 30]             256\n",
      "            ReLU-283              [-1, 128, 30]               0\n",
      " ConvTranspose1d-284              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-285              [-1, 128, 30]             256\n",
      "            ReLU-286              [-1, 128, 30]               0\n",
      " ConvTranspose1d-287              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-288              [-1, 512, 30]           1,024\n",
      "            ReLU-289              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-290              [-1, 512, 30]               0\n",
      " ConvTranspose1d-291              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-292              [-1, 128, 30]             256\n",
      "            ReLU-293              [-1, 128, 30]               0\n",
      " ConvTranspose1d-294              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-295              [-1, 128, 30]             256\n",
      "            ReLU-296              [-1, 128, 30]               0\n",
      " ConvTranspose1d-297              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-298              [-1, 512, 30]           1,024\n",
      "            ReLU-299              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-300              [-1, 512, 30]               0\n",
      " ConvTranspose1d-301              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-302              [-1, 128, 30]             256\n",
      "            ReLU-303              [-1, 128, 30]               0\n",
      " ConvTranspose1d-304              [-1, 128, 60]          49,280\n",
      "     BatchNorm1d-305              [-1, 128, 60]             256\n",
      "            ReLU-306              [-1, 128, 60]               0\n",
      " ConvTranspose1d-307              [-1, 256, 60]          33,024\n",
      "     BatchNorm1d-308              [-1, 256, 60]             512\n",
      " ConvTranspose1d-309              [-1, 256, 60]         131,328\n",
      "     BatchNorm1d-310              [-1, 256, 60]             512\n",
      "            ReLU-311              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-312              [-1, 256, 60]               0\n",
      " ConvTranspose1d-313               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-314               [-1, 64, 60]             128\n",
      "            ReLU-315               [-1, 64, 60]               0\n",
      " ConvTranspose1d-316               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-317               [-1, 64, 60]             128\n",
      "            ReLU-318               [-1, 64, 60]               0\n",
      " ConvTranspose1d-319              [-1, 256, 60]          16,640\n",
      "     BatchNorm1d-320              [-1, 256, 60]             512\n",
      "            ReLU-321              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-322              [-1, 256, 60]               0\n",
      " ConvTranspose1d-323               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-324               [-1, 64, 60]             128\n",
      "            ReLU-325               [-1, 64, 60]               0\n",
      " ConvTranspose1d-326               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-327               [-1, 64, 60]             128\n",
      "            ReLU-328               [-1, 64, 60]               0\n",
      " ConvTranspose1d-329              [-1, 256, 60]          16,640\n",
      "     BatchNorm1d-330              [-1, 256, 60]             512\n",
      "            ReLU-331              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-332              [-1, 256, 60]               0\n",
      " ConvTranspose1d-333               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-334               [-1, 64, 60]             128\n",
      "            ReLU-335               [-1, 64, 60]               0\n",
      " ConvTranspose1d-336               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-337               [-1, 64, 60]             128\n",
      "            ReLU-338               [-1, 64, 60]               0\n",
      " ConvTranspose1d-339                [-1, 9, 60]             585\n",
      "================================================================\n",
      "Total params: 34,032,457\n",
      "Trainable params: 34,032,457\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 22.81\n",
      "Params size (MB): 129.82\n",
      "Estimated Total Size (MB): 152.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ResNet_Autoencoder_Model import ResNet_Autoencoder\n",
    "\n",
    "# Build model\n",
    "model = ResNet_Autoencoder().to('cuda')\n",
    "\n",
    "# With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(9, 60))\n",
    "\n",
    "# Check that the output shape and target shape match\n",
    "# training_example = torch.rand(9, 2 ** 12).to('cuda')\n",
    "# print('Target shape:', training_example.shape)\n",
    "# model.eval()\n",
    "# output = model(training_example)\n",
    "# print('Output shape:', output.shape)\n",
    "\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "model = torch.compile(model,mode = 'max-autotune')\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 1/20982 [00:32<188:47:46, 32.39s/batch, loss=623.1656]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 2/20982 [00:33<82:44:28, 14.20s/batch, loss=621.3223] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 3/20982 [00:34<45:37:22,  7.83s/batch, loss=621.9302]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 4/20982 [00:34<28:10:44,  4.84s/batch, loss=622.5852]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 5/20982 [00:34<18:32:12,  3.18s/batch, loss=623.0424]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 6/20982 [00:34<12:43:21,  2.18s/batch, loss=623.1840]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 7/20982 [00:35<9:02:25,  1.55s/batch, loss=623.3801] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 8/20982 [00:35<6:37:08,  1.14s/batch, loss=623.2238]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 9/20982 [00:35<5:00:04,  1.16batch/s, loss=623.0957]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 10/20982 [00:35<3:54:27,  1.49batch/s, loss=622.8861]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 11/20982 [00:36<3:09:46,  1.84batch/s, loss=623.2883]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 12/20982 [00:36<2:38:24,  2.21batch/s, loss=623.3662]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 13/20982 [00:36<2:17:11,  2.55batch/s, loss=623.4457]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 14/20982 [00:36<2:01:36,  2.87batch/s, loss=623.2290]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 15/20982 [00:37<1:51:45,  3.13batch/s, loss=623.3580]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 16/20982 [00:37<1:44:15,  3.35batch/s, loss=623.5219]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 17/20982 [00:37<1:39:14,  3.52batch/s, loss=623.6534]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 18/20982 [00:37<1:35:12,  3.67batch/s, loss=623.5248]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 19/20982 [00:38<1:33:09,  3.75batch/s, loss=623.7845]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 20/20982 [00:38<1:31:02,  3.84batch/s, loss=623.6399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 21/20982 [00:38<1:30:20,  3.87batch/s, loss=623.4208]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 22/20982 [00:38<1:29:10,  3.92batch/s, loss=623.4106]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 23/20982 [00:39<1:28:51,  3.93batch/s, loss=623.6198]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 24/20982 [00:39<1:27:56,  3.97batch/s, loss=623.7004]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: inf or NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   0%|          | 42/20982 [00:44<6:10:06,  1.06s/batch, loss=415.4047]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# # # This seems to sometimes help\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# start_time = time.time()\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Again, this sometimes seems to help\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Evaluate the trained model\u001b[39;00m\n\u001b[1;32m     27\u001b[0m evaluate_model(model, criterion, loaders, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, loaders, device, num_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Before calling step(), check for inf or NaN values in the gradients\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: inf or NaN values in gradients!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# scaler.step() first unscales the gradients of the optimizer's assigned params.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# If these gradients do not contain infs or NaNs, optimizer.step() is then called,\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# otherwise, optimizer.step() is skipped.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Before calling step(), check for inf or NaN values in the gradients\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(torch\u001b[38;5;241m.\u001b[39misinf(p\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39many() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: inf or NaN values in gradients!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# scaler.step() first unscales the gradients of the optimizer's assigned params.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# If these gradients do not contain infs or NaNs, optimizer.step() is then called,\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# otherwise, optimizer.step() is skipped.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "\n",
    "# Pepare data loaders\n",
    "batch_size =  32 * 16 * 5\n",
    "num_workers = 22\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "\n",
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1\n",
    "\n",
    "# # # This seems to sometimes help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "# start_time = time.time()\n",
    "train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# Again, this sometimes seems to help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Evaluate the trained model\n",
    "evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5245 [00:00<?, ?batch/s]AUTOTUNE mm(2560x16384, 16384x64)\n",
      "  triton_mm_145 0.2424 ms 100.0%\n",
      "  triton_mm_146 0.2437 ms 99.5%\n",
      "  triton_mm_149 0.2444 ms 99.2%\n",
      "  triton_mm_148 0.2469 ms 98.2%\n",
      "  mm 0.2509 ms 96.6%\n",
      "  triton_mm_143 0.2642 ms 91.8%\n",
      "  triton_mm_141 0.3215 ms 75.4%\n",
      "  triton_mm_144 0.3850 ms 63.0%\n",
      "  triton_mm_142 0.4004 ms 60.5%\n",
      "  triton_mm_150 0.4701 ms 51.6%\n",
      "SingleProcess AUTOTUNE takes 3.2618 seconds\n",
      "AUTOTUNE mm(2560x64, 64x64)\n",
      "  triton_mm_158 0.0054 ms 100.0%\n",
      "  triton_mm_157 0.0059 ms 90.8%\n",
      "  mm 0.0061 ms 87.5%\n",
      "  triton_mm_153 0.0061 ms 87.5%\n",
      "  triton_mm_155 0.0061 ms 87.5%\n",
      "  triton_mm_160 0.0061 ms 87.5%\n",
      "  triton_mm_161 0.0061 ms 87.5%\n",
      "  triton_mm_152 0.0069 ms 78.1%\n",
      "  triton_mm_162 0.0071 ms 75.7%\n",
      "  triton_mm_154 0.0072 ms 75.0%\n",
      "SingleProcess AUTOTUNE takes 3.0065 seconds\n",
      "AUTOTUNE mm(2560x64, 64x16384)\n",
      "  triton_mm_182 0.2099 ms 100.0%\n",
      "  triton_mm_179 0.2109 ms 99.5%\n",
      "  triton_mm_184 0.2112 ms 99.4%\n",
      "  triton_mm_185 0.2112 ms 99.4%\n",
      "  triton_mm_177 0.2120 ms 99.0%\n",
      "  triton_mm_176 0.2140 ms 98.1%\n",
      "  triton_mm_181 0.2140 ms 98.1%\n",
      "  triton_mm_186 0.2147 ms 97.8%\n",
      "  triton_mm_187 0.2162 ms 97.1%\n",
      "  mm 0.2181 ms 96.2%\n",
      "SingleProcess AUTOTUNE takes 3.2485 seconds\n",
      "  7%|▋         | 374/5245 [01:18<16:59,  4.78batch/s, loss=nan] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train_model(model, criterion, optimizer, loaders, 'cuda', 3)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# # print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# # Evaluate the trained model\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 53\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, criterion, loaders, loader, device)\u001b[0m\n\u001b[1;32m     50\u001b[0m target_gpu \u001b[38;5;241m=\u001b[39m target_cpu\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     51\u001b[0m output_gpu \u001b[38;5;241m=\u001b[39m model(target_gpu)\n\u001b[0;32m---> 53\u001b[0m eval_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_gpu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m target_gpu\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     55\u001b[0m eval_loader_tqdm\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meval_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m(total)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_model(model, criterion, optimizer, loaders, 'cuda', 3)\n",
    "# # print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# # Again, this sometimes seems to help\n",
    "# # gc.collect()\n",
    "# # torch.cuda.empty_cache()\n",
    "\n",
    "# # Evaluate the trained model\n",
    "evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    # eval_loss = 0\n",
    "    # total = 0\n",
    "    predictions_gpu = []\n",
    "    targets_cpu = []\n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            targets_cpu.append(target_cpu)\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            # output_gpu\n",
    "            predictions_gpu.append(model(target_gpu).to('cpu'))\n",
    "            \n",
    "            # eval_loss += criterion(output_gpu, target_gpu).item()\n",
    "            # total += target_gpu.size(0)\n",
    "            # eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.4f}') \n",
    "            \n",
    "    # print(f'Evaluated Loss: {eval_loss / total:.6f}')\n",
    "    \n",
    "    return predictions_gpu, targets_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 5244/5245 [14:12<00:00,  7.55batch/s]AUTOTUNE mm(1083x16384, 16384x64)\n",
      "  mm 0.1147 ms 100.0%\n",
      "  triton_mm_194 0.1475 ms 77.8%\n",
      "  triton_mm_193 0.1636 ms 70.1%\n",
      "  triton_mm_197 0.1665 ms 68.9%\n",
      "  triton_mm_196 0.2097 ms 54.7%\n",
      "  triton_mm_191 0.2212 ms 51.9%\n",
      "  triton_mm_189 0.2335 ms 49.1%\n",
      "  triton_mm_188 0.3799 ms 30.2%\n",
      "  triton_mm_192 0.3840 ms 29.9%\n",
      "  triton_mm_190 0.4076 ms 28.1%\n",
      "SingleProcess AUTOTUNE takes 3.2280 seconds\n",
      "AUTOTUNE mm(1083x64, 64x64)\n",
      "  triton_mm_201 0.0051 ms 100.0%\n",
      "  triton_mm_205 0.0051 ms 100.0%\n",
      "  triton_mm_206 0.0051 ms 100.0%\n",
      "  triton_mm_209 0.0051 ms 100.0%\n",
      "  triton_mm_208 0.0054 ms 95.2%\n",
      "  triton_mm_203 0.0055 ms 92.5%\n",
      "  triton_mm_200 0.0060 ms 86.0%\n",
      "  mm 0.0061 ms 83.3%\n",
      "  triton_mm_202 0.0061 ms 83.3%\n",
      "  triton_mm_204 0.0061 ms 83.3%\n",
      "SingleProcess AUTOTUNE takes 3.0356 seconds\n",
      "AUTOTUNE mm(1083x64, 64x16384)\n",
      "  mm 0.0973 ms 100.0%\n",
      "  triton_mm_225 0.1004 ms 96.9%\n",
      "  triton_mm_230 0.1004 ms 96.9%\n",
      "  triton_mm_224 0.1005 ms 96.8%\n",
      "  triton_mm_232 0.1014 ms 96.0%\n",
      "  triton_mm_233 0.1014 ms 96.0%\n",
      "  triton_mm_227 0.1024 ms 95.0%\n",
      "  triton_mm_234 0.1024 ms 95.0%\n",
      "  triton_mm_229 0.1034 ms 94.1%\n",
      "  triton_mm_235 0.1034 ms 94.1%\n",
      "SingleProcess AUTOTUNE takes 3.3658 seconds\n",
      "100%|██████████| 5245/5245 [14:31<00:00,  6.02batch/s]\n"
     ]
    }
   ],
   "source": [
    "pred, target = predict(model, criterion, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5245,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error \n\u001b[0;32m----> 2\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(\n\u001b[1;32m    383\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    384\u001b[0m ):\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    446\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 101\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    881\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (5245,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "m = mean_squared_error(target, pred)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "pred_example = pred[n][0].numpy()\n",
    "target_example = target[n][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 60)\n",
      "(9, 60)\n"
     ]
    }
   ],
   "source": [
    "print(pred_example.shape)\n",
    "print(target_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]]\n",
      "[[ 0.775   0.7625  0.7     0.65    0.625 ]\n",
      " [ 0.6125  0.625   0.7     0.75    0.775 ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.     -0.9875]\n",
      " [ 1.      1.      1.      1.      1.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "print(pred_example[:,n:5+n])\n",
    "print(target_example[:,n:5+n])\n",
    "# for i in range(12):\n",
    "#     print(i)\n",
    "#     print(target_example[5:9,i*5:5+i*5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(target_example[5:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
