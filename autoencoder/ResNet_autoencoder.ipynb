{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(60,5000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = dataset.all_segments_train_test_split_dataframes(60, proportion_of_segments=.01, test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,segment_start:segment_end]\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = np.zeros((13,60))\n",
    "            transformed[0,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] > 0)\n",
    "            transformed[1,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] < 0)\n",
    "            transformed[2,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] > 0)\n",
    "            transformed[3,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] < 0)\n",
    "            transformed[4,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] > 0)\n",
    "            transformed[5,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] < 0)\n",
    "            transformed[6,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] > 0)\n",
    "            transformed[7,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] < 0)\n",
    "            transformed[8:,:] = segment[4:]\n",
    "            segment = transformed\n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(segment).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df,True)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df,True)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, loaders, device, num_epochs=1):\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        total = 0\n",
    "        i = 3\n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            \n",
    "            # Resets the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Runs the forward pass with autocasting.\n",
    "            with autocast():\n",
    "                output_gpu = model(target_gpu)\n",
    "                loss = criterion(output_gpu , target_gpu )\n",
    "                # print(loss)\n",
    "            \n",
    "            # Scales loss and calls backward() to create scaled gradients\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Clip gradients to avoid explosion\n",
    "            scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            # Before calling step(), check for inf or NaN values in the gradients\n",
    "            if any(torch.isinf(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: inf values in gradients!\")\n",
    "            elif any( torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: NaN values in gradients!\")\n",
    "                \n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "\n",
    "            # Update progress\n",
    "            train_loss += loss.item()\n",
    "            total += target_gpu.size(0)\n",
    "            train_loader_tqdm.set_postfix(loss=f'{train_loss / (total):.4f}')\n",
    "            # i += 1\n",
    "            # if i > 10:\n",
    "            #     break\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu, target_gpu).item()\n",
    "            total += target_gpu.size(0)\n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.4f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / total:.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet_Autoencoder_Model import ResNet_Autoencoder\n",
    "\n",
    "# Build model\n",
    "model = ResNet_Autoencoder(13).to('cuda')\n",
    "\n",
    "# With the size of an input we can get a model summary.\n",
    "# summary(model, input_size=(9, 60))\n",
    "\n",
    "# Check that the output shape and target shape match\n",
    "# training_example = torch.rand(9, 2 ** 12).to('cuda')\n",
    "# print('Target shape:', training_example.shape)\n",
    "# model.eval()\n",
    "# output = model(training_example)\n",
    "# print('Output shape:', output.shape)\n",
    "\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "# Pepare data loaders\n",
    "batch_size =  32 * 16 * 5 \n",
    "batch_size =  32 \n",
    "num_workers = 22\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "\n",
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "\n",
    "class LInfinityLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LInfinityLoss, self).__init__()\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Compute the infinity norm of the difference\n",
    "        return torch.max(torch.abs(predictions - targets))\n",
    "\n",
    "class LPNormLoss(nn.Module):\n",
    "    def __init__(self, p=2):\n",
    "        super(LPNormLoss, self).__init__()\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        # Compute the lp norm of the difference\n",
    "        return torch.norm(predictions - targets, p=self.p)\n",
    "\n",
    "# Example usage:\n",
    "# criterion = LPNormLoss(p=6) \n",
    "# criterion = LInfinityLoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1\n",
    "\n",
    "# # # This seems to sometimes help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "# start_time = time.time()\n",
    "train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# Again, this sometimes seems to help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Evaluate the trained model\n",
    "# evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loaders, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit='batch')\n",
    "        \n",
    "        for _, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            predictions.append(output_gpu.cpu().numpy())\n",
    "            targets.append(target_cpu.numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    \n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, target = predict(model, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pred))\n",
    "print(pred.shape)\n",
    "print(type(target))\n",
    "print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stick_histograms(predictions, targets, jstick_n_bins, c_stick_n_bins):\n",
    "    \n",
    "    \n",
    "    # # get the max and min of JSTICK_X, JSTICK_Y, CSTICK_X, and CSTICK_Y\n",
    "    jstick_x_max, jstick_x_min = np.max(predictions[:, 0, :]), np.min(predictions[:, 0, :])\n",
    "    jstick_y_max, jstick_y_min = np.max(predictions[:, 1, :]), np.min(predictions[:, 1, :])\n",
    "    cstick_x_max, cstick_x_min = np.max(predictions[:, 2, :]), np.min(predictions[:, 2, :])\n",
    "    cstick_y_max, cstick_y_min = np.max(predictions[:, 3, :]), np.min(predictions[:, 3, :])\n",
    "    \n",
    "    print(f'Predictions JSTICK_X max: {jstick_x_max}, min: {jstick_x_min}')\n",
    "    print(f'Predictions JSTICK_Y max: {jstick_y_max}, min: {jstick_y_min}')\n",
    "    print(f'Predictions CSTICK_X max: {cstick_x_max}, min: {cstick_x_min}')\n",
    "    print(f'Predictions CSTICK_Y max: {cstick_y_max}, min: {cstick_y_min}')\n",
    "    \n",
    "    predictions = np.clip(predictions,-1,1)\n",
    "    # Histograms\n",
    "    pred_hist_jstick_x, edges_jstick_x = np.histogram(predictions[:, 0, :], bins=jstick_n_bins, range=(-1, 1))\n",
    "    target_hist_jstick_x, _ = np.histogram(targets[:, 0, :], bins=jstick_n_bins, range=(-1, 1))\n",
    "    \n",
    "    pred_hist_jstick_y, edges_jstick_y = np.histogram(predictions[:, 1, :], bins=jstick_n_bins, range=(-1, 1))\n",
    "    target_hist_jstick_y, _ = np.histogram(targets[:, 1, :], bins=jstick_n_bins, range=(-1, 1))\n",
    "    \n",
    "    pred_hist_cstick_x, edges_cstick_x = np.histogram(predictions[:, 2, :], bins=c_stick_n_bins, range=(-1, 1))\n",
    "    target_hist_cstick_x, _ = np.histogram(targets[:, 2, :], bins=c_stick_n_bins, range=(-1, 1))\n",
    "    \n",
    "    pred_hist_cstick_y, edges_cstick_y = np.histogram(predictions[:, 3, :], bins=c_stick_n_bins, range=(-1, 1))\n",
    "    target_hist_cstick_y, _ = np.histogram(targets[:, 3, :], bins=c_stick_n_bins, range=(-1, 1))\n",
    "    \n",
    "    # Plotting histograms\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    \n",
    "    # JSTICK_X histogram\n",
    "    axs[0, 0].bar(edges_jstick_x[:-1], pred_hist_jstick_x, width=np.diff(edges_jstick_x), edgecolor=\"black\", align=\"edge\", label='Predictions')\n",
    "    axs[0, 0].bar(edges_jstick_x[:-1], target_hist_jstick_x, width=np.diff(edges_jstick_x), edgecolor=\"red\", align=\"edge\", label='Targets', alpha=0.5)\n",
    "    axs[0, 0].legend()\n",
    "    axs[0, 0].set_title('Histogram of JSTICK_X')\n",
    "    axs[0, 0].set_xlabel('JSTICK_X values')\n",
    "    axs[0, 0].set_ylabel('Frequency')\n",
    "    axs[0, 0].set_yscale('log')\n",
    "    \n",
    "    # JSTICK_Y histogram\n",
    "    axs[0, 1].bar(edges_jstick_y[:-1], pred_hist_jstick_y, width=np.diff(edges_jstick_y), edgecolor=\"black\", align=\"edge\", label='Predictions')\n",
    "    axs[0, 1].bar(edges_jstick_y[:-1], target_hist_jstick_y, width=np.diff(edges_jstick_y), edgecolor=\"red\", align=\"edge\", label='Targets', alpha=0.5)\n",
    "    axs[0, 1].legend()\n",
    "    axs[0, 1].set_title('Histogram of JSTICK_Y')\n",
    "    axs[0, 1].set_xlabel('JSTICK_Y values')\n",
    "    axs[0, 1].set_ylabel('Frequency')\n",
    "    axs[0, 1].set_yscale('log')\n",
    "    \n",
    "    # CSTICK_X histogram\n",
    "    axs[1, 0].bar(edges_cstick_x[:-1], pred_hist_cstick_x, width=np.diff(edges_cstick_x), edgecolor=\"black\", align=\"edge\", label='Predictions')\n",
    "    axs[1, 0].bar(edges_cstick_x[:-1], target_hist_cstick_x, width=np.diff(edges_cstick_x), edgecolor=\"red\", align=\"edge\", label='Targets', alpha=0.5)\n",
    "    axs[1, 0].legend()\n",
    "    axs[1, 0].set_title('Histogram of CSTICK_X')\n",
    "    axs[1, 0].set_xlabel('CSTICK_X values')\n",
    "    axs[1, 0].set_ylabel('Frequency')\n",
    "    axs[1, 0].set_yscale('log')\n",
    "    \n",
    "    # CSTICK_Y histogram\n",
    "    axs[1, 1].bar(edges_cstick_y[:-1], pred_hist_cstick_y, width=np.diff(edges_cstick_y), edgecolor=\"black\", align=\"edge\", label='Predictions')\n",
    "    axs[1, 1].bar(edges_cstick_y[:-1], target_hist_cstick_y, width=np.diff(edges_cstick_y), edgecolor=\"red\", align=\"edge\", label='Targets', alpha=0.5)\n",
    "    axs[1, 1].legend()\n",
    "    axs[1, 1].set_title('Histogram of CSTICK_Y')\n",
    "    axs[1, 1].set_xlabel('CSTICK_Y values')\n",
    "    axs[1, 1].set_ylabel('Frequency')\n",
    "    axs[1, 1].set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# pred: predictions numpy array of shape (batch_size, 9, 60)\n",
    "# target: targets numpy array of shape (batch_size, 9, 60)\n",
    "# Adjust bins as needed\n",
    "stick_histograms(pred, target, 101, 101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_heatmap_none(predictions, targets, bins, label):\n",
    "    # Clip and flatten the predictions and targets\n",
    "    predictions = np.clip(predictions, -1, 1).flatten()\n",
    "    targets = np.clip(targets, -1, 1).flatten()\n",
    "\n",
    "    # Create a 2D histogram of the data\n",
    "    heatmap, xedges, yedges = np.histogram2d(predictions, targets, bins=bins, range=[[-1, 1], [-1, 1]])\n",
    "    \n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 8))  # Increase figure size\n",
    "    plt.imshow(heatmap, origin='lower', extent=[-1, 1, -1, 1], aspect='auto', cmap='viridis')\n",
    "    \n",
    "    # Adding color bar to understand the scale of counts\n",
    "    plt.colorbar(label='Count')\n",
    "    \n",
    "    # Labels for axes\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Targets')\n",
    "    \n",
    "    # Set x and y ticks to represent the edges of bins\n",
    "    # plt.xticks((xedges[:-1] + xedges[1:])/2, labels=[f\"{edge:.2f}\" for edge in xedges[:-1]])\n",
    "    # plt.yticks((yedges[:-1] + yedges[1:])/2, labels=[f\"{edge:.2f}\" for edge in yedges[:-1]])\n",
    "    \n",
    "    plt.title(f'Heatmap of {label} Predictions vs Targets')\n",
    "    plt.show()\n",
    "\n",
    "def confusion_heatmap_normalize_pred(predictions, targets, bins, label):\n",
    "    predictions = np.clip(predictions   , -1, 1).flatten()\n",
    "    targets = np.clip(targets   , -1, 1).flatten()\n",
    "\n",
    "    # Calculate weights for normalization by predicted values\n",
    "    # Count the occurrences of each predicted bin\n",
    "    predicted_bins = np.digitize(predictions, bins=np.linspace(-1, 1, bins+1)) - 1\n",
    "    predicted_bin_counts = np.bincount(predicted_bins, minlength=bins)\n",
    "    weights_pred = 1 / predicted_bin_counts[predicted_bins]  # Weights are reciprocal of the counts\n",
    "\n",
    "    # Create a 2D histogram of the data with weights\n",
    "    heatmap, xedges, yedges = np.histogram2d(predictions, targets, bins=bins, range=[[-1, 1], [-1, 1]], weights=weights_pred)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(heatmap, origin='lower', extent=[-1, 1, -1, 1], aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Proportion')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Targets')\n",
    "    plt.title(f'Heatmap {label} Normalized by Predicted')\n",
    "    plt.show()\n",
    "\n",
    "def confusion_heatmap_normalize_true(predictions, targets, bins, label):\n",
    "    predictions = np.clip(predictions, -1, 1).flatten()\n",
    "    targets = np.clip(targets, -1, 1).flatten()\n",
    "\n",
    "    # Calculate weights for normalization by true values\n",
    "    # Count the occurrences of each true bin\n",
    "    true_bins = np.digitize(targets, bins=np.linspace(-1, 1, bins+1)) - 1\n",
    "    true_bin_counts = np.bincount(true_bins, minlength=bins)\n",
    "    weights_true = 1 / true_bin_counts[true_bins]  # Weights are reciprocal of the counts\n",
    "\n",
    "    # Create a 2D histogram of the data with weights\n",
    "    heatmap, xedges, yedges = np.histogram2d(predictions, targets, bins=bins, range=[[-1, 1], [-1, 1]], weights=weights_true)\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(heatmap, origin='lower', extent=[-1, 1, -1, 1], aspect='auto', cmap='viridis')\n",
    "    plt.colorbar(label='Proportion')\n",
    "    plt.xlabel('Predictions')\n",
    "    plt.ylabel('Targets')\n",
    "    plt.title(f'Heatmap {label} Normalized by True')\n",
    "    plt.show()\n",
    "\n",
    "def confusion_heatmaps(predictions, targets, bins, label):\n",
    "    confusion_heatmap_none(pred[:, 0, :], target[:, 0, :], bins, label)\n",
    "    confusion_heatmap_normalize_pred(pred[:, 0, :], target[:, 0, :],  bins, label)\n",
    "    confusion_heatmap_normalize_true(pred[:, 0, :], target[:, 0, :],  bins, label)\n",
    "\n",
    "bins = 30\n",
    "# confusion_heatmaps(pred[:, 0, :], target[:, 0, :],  bins, 'JSTICK_X')\n",
    "# confusion_heatmaps(pred[:, 1, :], target[:, 1, :],  bins, 'JSTICK_Y')\n",
    "\n",
    "# confusion_heatmaps(np.arctan2(pred[:, 1, :], pred[:, 0, :]), np.arctan2(target[:, 1, :], target[:, 0, :]),  bins, 'J-Stick Angle')\n",
    "# confusion_heatmaps(pred[:, 1, :]**2 + pred[:, 0, :]**2, target[:, 1, :]**2 + target[:, 0, :]**2,  bins, 'J-Stick Radius')\n",
    "\n",
    "# confusion_heatmaps(pred[:, 2, :], target[:, 2, :],  bins, 'CSTICK_X')\n",
    "# confusion_heatmaps(pred[:, 3, :], target[:, 3, :],  bins, 'CSTICK_Y')\n",
    "\n",
    "# confusion_heatmaps(np.arctan2(pred[:, 3, :],  pred[:, 2, :]), np.arctan2(target[:, 3, :] , target[:, 2, :]),  bins, 'J-Stick Angle')\n",
    "# confusion_heatmaps(pred[:, 2, :]**2 + pred[:, 3, :]**2, target[:, 2, :]**2 + target[:, 3, :]**2,  bins, 'J-Stick Radius')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a sense of how often the model predicts zeros. We look at the distribution of the number of frames a button is held over all games for the predictions and the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target and predicted to binary numpy\n",
    "predicted_buttons = pred[:,-5:,:] >= .5\n",
    "target_buttons = target[:,-5:,:] == 1\n",
    "predicted_and_target_one = np.multiply(predicted_buttons ,target_buttons)\n",
    "\n",
    "# sum over the buttons to get the number of frames the button is held\n",
    "target_button_sum = np.sum(target_buttons, axis = 2)\n",
    "pred_button_sum = np.sum(predicted_buttons, axis = 2)\n",
    "\n",
    "prediction_and_target_one_sum = np.sum(predicted_and_target_one, axis = 2)\n",
    "# take the difference between the number of frames the button is held in the prediction and the target\n",
    "difference = target_button_sum - pred_button_sum\n",
    "\n",
    "order = ['Trigger', 'Z', 'A', 'B', 'X_or_Y']\n",
    "for i, label in enumerate(order):\n",
    "    pred_unique, pred_counts = np.unique(pred_button_sum[:,i], return_counts=True)\n",
    "    target_unique, target_counts = np.unique(target_button_sum[:,i], return_counts=True)\n",
    "    diff_unique, diff_counts = np.unique(difference[:,i], return_counts=True)\n",
    "    both_one_unique, both_one_counts = np.unique(prediction_and_target_one_sum[:,i], return_counts=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title(f'Number of ones in target {label}')\n",
    "    plt.bar(target_unique[1:],target_counts[1:])\n",
    "    # plt.bar(target_unique,target_counts)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title(f'Number of ones predicted {label}')\n",
    "    plt.bar(pred_unique[1:],pred_counts[1:])\n",
    "    # plt.bar(pred_unique,pred_counts)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.title(f'Difference in number of ones in target and predicted {label}')\n",
    "    plt.bar(diff_unique,diff_counts)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the target and predicted to binary numpy\n",
    "predicted_buttons = pred[:,-5:,:] >= .5\n",
    "target_buttons = target[:,-5:,:] == 1\n",
    "predicted_and_target_one = np.multiply(predicted_buttons ,target_buttons)\n",
    "\n",
    "# sum over the buttons to get the number of frames the button is held\n",
    "target_button_sum = np.sum(target_buttons, axis = 2)\n",
    "pred_button_sum = np.sum(predicted_buttons, axis = 2)\n",
    "\n",
    "prediction_and_target_one_sum = np.sum(predicted_and_target_one, axis = 2)\n",
    "# take the difference between the number of frames the button is held in the prediction and the target\n",
    "difference = target_button_sum - pred_button_sum\n",
    "\n",
    "order = ['Trigger', 'Z', 'A', 'B', 'X_or_Y']\n",
    "for i, label in enumerate(order):\n",
    "    target_non_zero = target_button_sum[:,i] > 0\n",
    "    # print(target_non_zero.shape)\n",
    "    pred_unique, pred_counts = np.unique(pred_button_sum[target_non_zero,i], return_counts=True)\n",
    "    target_unique, target_counts = np.unique(target_button_sum[target_non_zero,i], return_counts=True)\n",
    "    diff_unique, diff_counts = np.unique(difference[target_non_zero,i], return_counts=True)\n",
    "    both_one_unique, both_one_counts = np.unique(prediction_and_target_one_sum[target_non_zero,i], return_counts=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f'Number of ones in target {label} given target had a one')\n",
    "    plt.bar(target_unique[1:],target_counts[1:])\n",
    "    # plt.bar(target_unique,target_counts)\n",
    "    # plt.show()\n",
    "    \n",
    "    # plt.figure(figsize=(10, 4))\n",
    "    plt.title(f'Number of ones predicted {label} given target had a one')\n",
    "    plt.bar(pred_unique[1:],pred_counts[1:])\n",
    "    # plt.bar(pred_unique,pred_counts)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f'Difference in number of ones in target and predicted {label} given target had a one')\n",
    "    plt.bar(diff_unique,diff_counts)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we get the distributions of the ones better (using a better loss function) and deal with the gradient problem we can focus in on the details of button presses. A confusion matrix where we look at the number of distinct times the button is pressed during a segment (it is pressed once but the prediction is two distinct presses). Given a button is pressed once and the prediction is that the button was pressed once, does the autoencoder predict the button was pressed at the same time? How many frames before the actual button was press does the autoencoder predict it was first pressed. How many frames is the end of the predicted button press off from the actual end of the button press.\n",
    "\n",
    "Given any button was pressed, what is the probability that it predicted a button was pressed (not necessarily the one that was actually pressed). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
