{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOX               103069\n",
      "FALCO              90719\n",
      "MARTH              53728\n",
      "CAPTAIN_FALCON     38006\n",
      "SHEIK              27623\n",
      "PEACH              17438\n",
      "JIGGLYPUFF         16374\n",
      "SAMUS               9524\n",
      "ICE_CLIMBERS        6849\n",
      "GANONDORF           6655\n",
      "YOSHI               5725\n",
      "LUIGI               5230\n",
      "DR_MARIO            4202\n",
      "PIKACHU             4096\n",
      "LINK                2502\n",
      "NESS                2306\n",
      "DONKEY_KONG         2026\n",
      "GAME_AND_WATCH      1967\n",
      "MEWTWO              1775\n",
      "MARIO               1713\n",
      "YOUNG_LINK          1447\n",
      "ROY                 1272\n",
      "BOWSER               940\n",
      "KIRBY                556\n",
      "PICHU                230\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Label   Count   Shift\n",
      "0              FOX  103069  967486\n",
      "1            FALCO   90717  840584\n",
      "2            MARTH   53728  532846\n",
      "3   CAPTAIN_FALCON   38006  350625\n",
      "4            SHEIK   27623  295724\n",
      "5            PEACH   17438  196988\n",
      "6       JIGGLYPUFF   16374  177903\n",
      "7            SAMUS    9524  115154\n",
      "8     ICE_CLIMBERS    6849   78098\n",
      "9        GANONDORF    6655   64025\n",
      "10           YOSHI    5725   61132\n",
      "11           LUIGI    5230   57319\n",
      "12        DR_MARIO    4202   45308\n",
      "13         PIKACHU    4096   44953\n",
      "14            LINK    2502   27988\n",
      "15            NESS    2306   29062\n",
      "16     DONKEY_KONG    2026   21667\n",
      "17  GAME_AND_WATCH    1967   18467\n",
      "18          MEWTWO    1775   22553\n",
      "19           MARIO    1713   19122\n",
      "20      YOUNG_LINK    1447   16390\n",
      "21             ROY    1272   13426\n",
      "22          BOWSER     940   10979\n",
      "23           KIRBY     556    6186\n",
      "24           PICHU     230    2457\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(60,1000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           player_inputs_np_sub_path  length  num_segments  \\\n",
      "0  public\\FALCO\\bee06d45-fca6-437f-969a-901efa166...   28801             1   \n",
      "1  mango\\FALCO\\44e0962b-fdf7-4a16-acbe-61b5e5d609...   27200             1   \n",
      "2  ranked\\FALCO\\2f51bb81-4304-4c6d-ac53-960aba87c...   26024             1   \n",
      "3  ranked\\FALCO\\69cf9bb4-5f80-4e67-850d-ce0d7da1d...   25128             1   \n",
      "4  ranked\\FALCO\\04257d15-f02f-4001-a191-37b97d2ed...   24323             1   \n",
      "\n",
      "  labels  encoded_labels  \n",
      "0  FALCO               4  \n",
      "1  FALCO               4  \n",
      "2  FALCO               4  \n",
      "3  FALCO               4  \n",
      "4  FALCO               4  \n"
     ]
    }
   ],
   "source": [
    "train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = dataset.all_segments_train_test_split_dataframes(60, proportion_of_segments=.01, test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 6)\n",
      "(5000, 6)\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango\\FALCO\\b3c63d9d-efb7-4544-bdd6-9da7e221f1...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mango\\FALCO\\a24ef3f0-ab56-47e6-af18-5905aa43af...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mango\\FALCO\\24b523a3-18da-4ba2-a986-d0c99b6228...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mango\\FALCO\\60e0d81b-e0bd-420c-8fce-fe2b11645c...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public\\FALCO\\b0925bbb-c009-49db-80e6-6985d4756...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           player_inputs_np_sub_path labels  encoded_labels  \\\n",
       "0  mango\\FALCO\\b3c63d9d-efb7-4544-bdd6-9da7e221f1...  FALCO               4   \n",
       "1  mango\\FALCO\\a24ef3f0-ab56-47e6-af18-5905aa43af...  FALCO               4   \n",
       "2  mango\\FALCO\\24b523a3-18da-4ba2-a986-d0c99b6228...  FALCO               4   \n",
       "3  mango\\FALCO\\60e0d81b-e0bd-420c-8fce-fe2b11645c...  FALCO               4   \n",
       "4  public\\FALCO\\b0925bbb-c009-49db-80e6-6985d4756...  FALCO               4   \n",
       "\n",
       "   segment_start_index  segment_index  segment_length  \n",
       "0                    0              0              60  \n",
       "1                    0              0              60  \n",
       "2                    0              0              60  \n",
       "3                    0              0              60  \n",
       "4                    0              0              60  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "        if self.transform:\n",
    "            segment = self.transform(segment)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(segment[:,segment_start:segment_end]).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, loaders, device, num_epochs=1):\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        total = 0\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            \n",
    "            # Resets the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Runs the forward pass with autocasting.\n",
    "            with autocast():\n",
    "                output_gpu = model(target_gpu)\n",
    "                loss = criterion(output_gpu, target_gpu)\n",
    "            \n",
    "            # Scales loss and calls backward() to create scaled gradients\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Clip gradients to avoid explosion\n",
    "            scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            # Before calling step(), check for inf or NaN values in the gradients\n",
    "            if any(torch.isinf(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: inf values in gradients!\")\n",
    "            elif any( torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: NaN values in gradients!\")\n",
    "                \n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "\n",
    "            # Update progress\n",
    "            train_loss += loss.item()\n",
    "            total += target_gpu.size(0)\n",
    "            train_loader_tqdm.set_postfix(loss=f'{train_loss / (total):.4f}')\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu, target_gpu).item()\n",
    "            total += target_gpu.size(0)\n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.4f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / total:.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 60]             640\n",
      "       BatchNorm1d-2               [-1, 64, 60]             128\n",
      "              ReLU-3               [-1, 64, 60]               0\n",
      "            Conv1d-4               [-1, 64, 60]          12,352\n",
      "       BatchNorm1d-5               [-1, 64, 60]             128\n",
      "              ReLU-6               [-1, 64, 60]               0\n",
      "            Conv1d-7              [-1, 256, 60]          16,640\n",
      "       BatchNorm1d-8              [-1, 256, 60]             512\n",
      "            Conv1d-9              [-1, 256, 60]           2,560\n",
      "      BatchNorm1d-10              [-1, 256, 60]             512\n",
      "             ReLU-11              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-12              [-1, 256, 60]               0\n",
      "           Conv1d-13               [-1, 64, 60]          16,448\n",
      "      BatchNorm1d-14               [-1, 64, 60]             128\n",
      "             ReLU-15               [-1, 64, 60]               0\n",
      "           Conv1d-16               [-1, 64, 60]          12,352\n",
      "      BatchNorm1d-17               [-1, 64, 60]             128\n",
      "             ReLU-18               [-1, 64, 60]               0\n",
      "           Conv1d-19              [-1, 256, 60]          16,640\n",
      "      BatchNorm1d-20              [-1, 256, 60]             512\n",
      "             ReLU-21              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-22              [-1, 256, 60]               0\n",
      "           Conv1d-23               [-1, 64, 60]          16,448\n",
      "      BatchNorm1d-24               [-1, 64, 60]             128\n",
      "             ReLU-25               [-1, 64, 60]               0\n",
      "           Conv1d-26               [-1, 64, 60]          12,352\n",
      "      BatchNorm1d-27               [-1, 64, 60]             128\n",
      "             ReLU-28               [-1, 64, 60]               0\n",
      "           Conv1d-29              [-1, 256, 60]          16,640\n",
      "      BatchNorm1d-30              [-1, 256, 60]             512\n",
      "             ReLU-31              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-32              [-1, 256, 60]               0\n",
      "           Conv1d-33              [-1, 128, 60]          32,896\n",
      "      BatchNorm1d-34              [-1, 128, 60]             256\n",
      "             ReLU-35              [-1, 128, 60]               0\n",
      "           Conv1d-36              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-37              [-1, 128, 30]             256\n",
      "             ReLU-38              [-1, 128, 30]               0\n",
      "           Conv1d-39              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-40              [-1, 512, 30]           1,024\n",
      "           Conv1d-41              [-1, 512, 30]         131,584\n",
      "      BatchNorm1d-42              [-1, 512, 30]           1,024\n",
      "             ReLU-43              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-44              [-1, 512, 30]               0\n",
      "           Conv1d-45              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-46              [-1, 128, 30]             256\n",
      "             ReLU-47              [-1, 128, 30]               0\n",
      "           Conv1d-48              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-49              [-1, 128, 30]             256\n",
      "             ReLU-50              [-1, 128, 30]               0\n",
      "           Conv1d-51              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-52              [-1, 512, 30]           1,024\n",
      "             ReLU-53              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-54              [-1, 512, 30]               0\n",
      "           Conv1d-55              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-56              [-1, 128, 30]             256\n",
      "             ReLU-57              [-1, 128, 30]               0\n",
      "           Conv1d-58              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-59              [-1, 128, 30]             256\n",
      "             ReLU-60              [-1, 128, 30]               0\n",
      "           Conv1d-61              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-62              [-1, 512, 30]           1,024\n",
      "             ReLU-63              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-64              [-1, 512, 30]               0\n",
      "           Conv1d-65              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-66              [-1, 128, 30]             256\n",
      "             ReLU-67              [-1, 128, 30]               0\n",
      "           Conv1d-68              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-69              [-1, 128, 30]             256\n",
      "             ReLU-70              [-1, 128, 30]               0\n",
      "           Conv1d-71              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-72              [-1, 512, 30]           1,024\n",
      "             ReLU-73              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-74              [-1, 512, 30]               0\n",
      "           Conv1d-75              [-1, 256, 30]         131,328\n",
      "      BatchNorm1d-76              [-1, 256, 30]             512\n",
      "             ReLU-77              [-1, 256, 30]               0\n",
      "           Conv1d-78              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-79              [-1, 256, 15]             512\n",
      "             ReLU-80              [-1, 256, 15]               0\n",
      "           Conv1d-81             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-82             [-1, 1024, 15]           2,048\n",
      "           Conv1d-83             [-1, 1024, 15]         525,312\n",
      "      BatchNorm1d-84             [-1, 1024, 15]           2,048\n",
      "             ReLU-85             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-86             [-1, 1024, 15]               0\n",
      "           Conv1d-87              [-1, 256, 15]         262,400\n",
      "      BatchNorm1d-88              [-1, 256, 15]             512\n",
      "             ReLU-89              [-1, 256, 15]               0\n",
      "           Conv1d-90              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-91              [-1, 256, 15]             512\n",
      "             ReLU-92              [-1, 256, 15]               0\n",
      "           Conv1d-93             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-94             [-1, 1024, 15]           2,048\n",
      "             ReLU-95             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-96             [-1, 1024, 15]               0\n",
      "           Conv1d-97              [-1, 256, 15]         262,400\n",
      "      BatchNorm1d-98              [-1, 256, 15]             512\n",
      "             ReLU-99              [-1, 256, 15]               0\n",
      "          Conv1d-100              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-101              [-1, 256, 15]             512\n",
      "            ReLU-102              [-1, 256, 15]               0\n",
      "          Conv1d-103             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-104             [-1, 1024, 15]           2,048\n",
      "            ReLU-105             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-106             [-1, 1024, 15]               0\n",
      "          Conv1d-107              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-108              [-1, 256, 15]             512\n",
      "            ReLU-109              [-1, 256, 15]               0\n",
      "          Conv1d-110              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-111              [-1, 256, 15]             512\n",
      "            ReLU-112              [-1, 256, 15]               0\n",
      "          Conv1d-113             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-114             [-1, 1024, 15]           2,048\n",
      "            ReLU-115             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-116             [-1, 1024, 15]               0\n",
      "          Conv1d-117              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-118              [-1, 256, 15]             512\n",
      "            ReLU-119              [-1, 256, 15]               0\n",
      "          Conv1d-120              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-121              [-1, 256, 15]             512\n",
      "            ReLU-122              [-1, 256, 15]               0\n",
      "          Conv1d-123             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-124             [-1, 1024, 15]           2,048\n",
      "            ReLU-125             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-126             [-1, 1024, 15]               0\n",
      "          Conv1d-127              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-128              [-1, 256, 15]             512\n",
      "            ReLU-129              [-1, 256, 15]               0\n",
      "          Conv1d-130              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-131              [-1, 256, 15]             512\n",
      "            ReLU-132              [-1, 256, 15]               0\n",
      "          Conv1d-133             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-134             [-1, 1024, 15]           2,048\n",
      "            ReLU-135             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-136             [-1, 1024, 15]               0\n",
      "          Conv1d-137              [-1, 512, 15]         524,800\n",
      "     BatchNorm1d-138              [-1, 512, 15]           1,024\n",
      "            ReLU-139              [-1, 512, 15]               0\n",
      "          Conv1d-140               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-141               [-1, 512, 8]           1,024\n",
      "            ReLU-142               [-1, 512, 8]               0\n",
      "          Conv1d-143              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-144              [-1, 2048, 8]           4,096\n",
      "          Conv1d-145              [-1, 2048, 8]       2,099,200\n",
      "     BatchNorm1d-146              [-1, 2048, 8]           4,096\n",
      "            ReLU-147              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-148              [-1, 2048, 8]               0\n",
      "          Conv1d-149               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-150               [-1, 512, 8]           1,024\n",
      "            ReLU-151               [-1, 512, 8]               0\n",
      "          Conv1d-152               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-153               [-1, 512, 8]           1,024\n",
      "            ReLU-154               [-1, 512, 8]               0\n",
      "          Conv1d-155              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-156              [-1, 2048, 8]           4,096\n",
      "            ReLU-157              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-158              [-1, 2048, 8]               0\n",
      "          Conv1d-159               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-160               [-1, 512, 8]           1,024\n",
      "            ReLU-161               [-1, 512, 8]               0\n",
      "          Conv1d-162               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-163               [-1, 512, 8]           1,024\n",
      "            ReLU-164               [-1, 512, 8]               0\n",
      "          Conv1d-165              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-166              [-1, 2048, 8]           4,096\n",
      "            ReLU-167              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-168              [-1, 2048, 8]               0\n",
      "          Linear-169                   [-1, 64]       1,048,640\n",
      "            ReLU-170                   [-1, 64]               0\n",
      "          Linear-171                   [-1, 64]           4,160\n",
      "            ReLU-172                   [-1, 64]               0\n",
      "          Linear-173                   [-1, 64]           4,160\n",
      "            ReLU-174                   [-1, 64]               0\n",
      "          Linear-175                [-1, 16384]       1,064,960\n",
      "            ReLU-176                [-1, 16384]               0\n",
      " ConvTranspose1d-177               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-178               [-1, 512, 8]           1,024\n",
      "            ReLU-179               [-1, 512, 8]               0\n",
      " ConvTranspose1d-180               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-181               [-1, 512, 8]           1,024\n",
      "            ReLU-182               [-1, 512, 8]               0\n",
      " ConvTranspose1d-183              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-184              [-1, 2048, 8]           4,096\n",
      "            ReLU-185              [-1, 2048, 8]               0\n",
      "Decoder_Bottleneck-186              [-1, 2048, 8]               0\n",
      " ConvTranspose1d-187               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-188               [-1, 512, 8]           1,024\n",
      "            ReLU-189               [-1, 512, 8]               0\n",
      " ConvTranspose1d-190               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-191               [-1, 512, 8]           1,024\n",
      "            ReLU-192               [-1, 512, 8]               0\n",
      " ConvTranspose1d-193              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-194              [-1, 2048, 8]           4,096\n",
      "            ReLU-195              [-1, 2048, 8]               0\n",
      "Decoder_Bottleneck-196              [-1, 2048, 8]               0\n",
      " ConvTranspose1d-197               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-198               [-1, 512, 8]           1,024\n",
      "            ReLU-199               [-1, 512, 8]               0\n",
      " ConvTranspose1d-200              [-1, 512, 15]         786,944\n",
      "     BatchNorm1d-201              [-1, 512, 15]           1,024\n",
      "            ReLU-202              [-1, 512, 15]               0\n",
      " ConvTranspose1d-203             [-1, 1024, 15]         525,312\n",
      "     BatchNorm1d-204             [-1, 1024, 15]           2,048\n",
      " ConvTranspose1d-205             [-1, 1024, 15]       2,098,176\n",
      "     BatchNorm1d-206             [-1, 1024, 15]           2,048\n",
      "            ReLU-207             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-208             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-209              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-210              [-1, 256, 15]             512\n",
      "            ReLU-211              [-1, 256, 15]               0\n",
      " ConvTranspose1d-212              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-213              [-1, 256, 15]             512\n",
      "            ReLU-214              [-1, 256, 15]               0\n",
      " ConvTranspose1d-215             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-216             [-1, 1024, 15]           2,048\n",
      "            ReLU-217             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-218             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-219              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-220              [-1, 256, 15]             512\n",
      "            ReLU-221              [-1, 256, 15]               0\n",
      " ConvTranspose1d-222              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-223              [-1, 256, 15]             512\n",
      "            ReLU-224              [-1, 256, 15]               0\n",
      " ConvTranspose1d-225             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-226             [-1, 1024, 15]           2,048\n",
      "            ReLU-227             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-228             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-229              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-230              [-1, 256, 15]             512\n",
      "            ReLU-231              [-1, 256, 15]               0\n",
      " ConvTranspose1d-232              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-233              [-1, 256, 15]             512\n",
      "            ReLU-234              [-1, 256, 15]               0\n",
      " ConvTranspose1d-235             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-236             [-1, 1024, 15]           2,048\n",
      "            ReLU-237             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-238             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-239              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-240              [-1, 256, 15]             512\n",
      "            ReLU-241              [-1, 256, 15]               0\n",
      " ConvTranspose1d-242              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-243              [-1, 256, 15]             512\n",
      "            ReLU-244              [-1, 256, 15]               0\n",
      " ConvTranspose1d-245             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-246             [-1, 1024, 15]           2,048\n",
      "            ReLU-247             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-248             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-249              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-250              [-1, 256, 15]             512\n",
      "            ReLU-251              [-1, 256, 15]               0\n",
      " ConvTranspose1d-252              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-253              [-1, 256, 15]             512\n",
      "            ReLU-254              [-1, 256, 15]               0\n",
      " ConvTranspose1d-255             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-256             [-1, 1024, 15]           2,048\n",
      "            ReLU-257             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-258             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-259              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-260              [-1, 256, 15]             512\n",
      "            ReLU-261              [-1, 256, 15]               0\n",
      " ConvTranspose1d-262              [-1, 256, 30]         196,864\n",
      "     BatchNorm1d-263              [-1, 256, 30]             512\n",
      "            ReLU-264              [-1, 256, 30]               0\n",
      " ConvTranspose1d-265              [-1, 512, 30]         131,584\n",
      "     BatchNorm1d-266              [-1, 512, 30]           1,024\n",
      " ConvTranspose1d-267              [-1, 512, 30]         524,800\n",
      "     BatchNorm1d-268              [-1, 512, 30]           1,024\n",
      "            ReLU-269              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-270              [-1, 512, 30]               0\n",
      " ConvTranspose1d-271              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-272              [-1, 128, 30]             256\n",
      "            ReLU-273              [-1, 128, 30]               0\n",
      " ConvTranspose1d-274              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-275              [-1, 128, 30]             256\n",
      "            ReLU-276              [-1, 128, 30]               0\n",
      " ConvTranspose1d-277              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-278              [-1, 512, 30]           1,024\n",
      "            ReLU-279              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-280              [-1, 512, 30]               0\n",
      " ConvTranspose1d-281              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-282              [-1, 128, 30]             256\n",
      "            ReLU-283              [-1, 128, 30]               0\n",
      " ConvTranspose1d-284              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-285              [-1, 128, 30]             256\n",
      "            ReLU-286              [-1, 128, 30]               0\n",
      " ConvTranspose1d-287              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-288              [-1, 512, 30]           1,024\n",
      "            ReLU-289              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-290              [-1, 512, 30]               0\n",
      " ConvTranspose1d-291              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-292              [-1, 128, 30]             256\n",
      "            ReLU-293              [-1, 128, 30]               0\n",
      " ConvTranspose1d-294              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-295              [-1, 128, 30]             256\n",
      "            ReLU-296              [-1, 128, 30]               0\n",
      " ConvTranspose1d-297              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-298              [-1, 512, 30]           1,024\n",
      "            ReLU-299              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-300              [-1, 512, 30]               0\n",
      " ConvTranspose1d-301              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-302              [-1, 128, 30]             256\n",
      "            ReLU-303              [-1, 128, 30]               0\n",
      " ConvTranspose1d-304              [-1, 128, 60]          49,280\n",
      "     BatchNorm1d-305              [-1, 128, 60]             256\n",
      "            ReLU-306              [-1, 128, 60]               0\n",
      " ConvTranspose1d-307              [-1, 256, 60]          33,024\n",
      "     BatchNorm1d-308              [-1, 256, 60]             512\n",
      " ConvTranspose1d-309              [-1, 256, 60]         131,328\n",
      "     BatchNorm1d-310              [-1, 256, 60]             512\n",
      "            ReLU-311              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-312              [-1, 256, 60]               0\n",
      " ConvTranspose1d-313               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-314               [-1, 64, 60]             128\n",
      "            ReLU-315               [-1, 64, 60]               0\n",
      " ConvTranspose1d-316               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-317               [-1, 64, 60]             128\n",
      "            ReLU-318               [-1, 64, 60]               0\n",
      " ConvTranspose1d-319              [-1, 256, 60]          16,640\n",
      "     BatchNorm1d-320              [-1, 256, 60]             512\n",
      "            ReLU-321              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-322              [-1, 256, 60]               0\n",
      " ConvTranspose1d-323               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-324               [-1, 64, 60]             128\n",
      "            ReLU-325               [-1, 64, 60]               0\n",
      " ConvTranspose1d-326               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-327               [-1, 64, 60]             128\n",
      "            ReLU-328               [-1, 64, 60]               0\n",
      " ConvTranspose1d-329              [-1, 256, 60]          16,640\n",
      "     BatchNorm1d-330              [-1, 256, 60]             512\n",
      "            ReLU-331              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-332              [-1, 256, 60]               0\n",
      " ConvTranspose1d-333               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-334               [-1, 64, 60]             128\n",
      "            ReLU-335               [-1, 64, 60]               0\n",
      " ConvTranspose1d-336               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-337               [-1, 64, 60]             128\n",
      "            ReLU-338               [-1, 64, 60]               0\n",
      " ConvTranspose1d-339                [-1, 9, 60]             585\n",
      "================================================================\n",
      "Total params: 34,032,457\n",
      "Trainable params: 34,032,457\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 22.81\n",
      "Params size (MB): 129.82\n",
      "Estimated Total Size (MB): 152.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ResNet_Autoencoder_Model import ResNet_Autoencoder\n",
    "\n",
    "# Build model\n",
    "model = ResNet_Autoencoder().to('cuda')\n",
    "\n",
    "# With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(9, 60))\n",
    "\n",
    "# Check that the output shape and target shape match\n",
    "# training_example = torch.rand(9, 2 ** 12).to('cuda')\n",
    "# print('Target shape:', training_example.shape)\n",
    "# model.eval()\n",
    "# output = model(training_example)\n",
    "# print('Output shape:', output.shape)\n",
    "\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  12%|        | 1/8 [00:03<00:24,  3.44s/batch, loss=620.7396]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  25%|       | 2/8 [00:03<00:09,  1.57s/batch, loss=620.9941]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  38%|      | 3/8 [00:03<00:04,  1.02batch/s, loss=621.0269]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  50%|     | 4/8 [00:04<00:02,  1.44batch/s, loss=622.1520]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  62%|   | 5/8 [00:04<00:01,  1.85batch/s, loss=621.7027]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  75%|  | 6/8 [00:04<00:00,  2.23batch/s, loss=622.4602]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:  88%| | 7/8 [00:05<00:00,  2.57batch/s, loss=622.9407]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|| 8/8 [00:05<00:00,  1.52batch/s, loss=622.9864]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values in gradients!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:03<00:00,  1.76s/batch, loss=131.2466]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Loss: 131.246612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "\n",
    "# Pepare data loaders\n",
    "batch_size =  32 * 16 * 5\n",
    "num_workers = 22\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "\n",
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "num_epochs = 1\n",
    "\n",
    "# # # This seems to sometimes help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "# start_time = time.time()\n",
    "train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# Again, this sometimes seems to help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Evaluate the trained model\n",
    "evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:03<00:00,  1.52s/batch, loss=131.2466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Loss: 131.246612\n"
     ]
    }
   ],
   "source": [
    "# train_model(model, criterion, optimizer, loaders, 'cuda', 3)\n",
    "# # print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# # Again, this sometimes seems to help\n",
    "# # gc.collect()\n",
    "# # torch.cuda.empty_cache()\n",
    "\n",
    "# # Evaluate the trained model\n",
    "evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    # eval_loss = 0\n",
    "    # total = 0\n",
    "    predictions_gpu = []\n",
    "    targets_cpu = []\n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            targets_cpu.append(target_cpu)\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            # output_gpu\n",
    "            predictions_gpu.append(model(target_gpu).to('cpu'))\n",
    "            \n",
    "            # eval_loss += criterion(output_gpu, target_gpu).item()\n",
    "            # total += target_gpu.size(0)\n",
    "            # eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.4f}') \n",
    "            \n",
    "    # print(f'Evaluated Loss: {eval_loss / total:.6f}')\n",
    "    \n",
    "    return predictions_gpu, targets_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2/2 [00:03<00:00,  1.53s/batch]\n"
     ]
    }
   ],
   "source": [
    "pred, target = predict(model, criterion, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  array = numpy.asarray(array, order=order, dtype=dtype)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error \n\u001b[0;32m----> 2\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean_squared_error\u001b[39m(\n\u001b[1;32m    383\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m\"\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    384\u001b[0m ):\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    446\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    100\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m--> 101\u001b[0m y_true \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    881\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy.array_api\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "m = mean_squared_error(target, pred)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "pred_example = pred[n][0].numpy()\n",
    "target_example = target[n][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 60)\n",
      "(9, 60)\n"
     ]
    }
   ],
   "source": [
    "print(pred_example.shape)\n",
    "print(target_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]\n",
      " [nan nan nan nan nan]]\n",
      "[[ 0.775   0.7625  0.7     0.65    0.625 ]\n",
      " [ 0.6125  0.625   0.7     0.75    0.775 ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.     -0.9875]\n",
      " [ 1.      1.      1.      1.      1.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]\n",
      " [ 0.      0.      0.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "print(pred_example[:,n:5+n])\n",
    "print(target_example[:,n:5+n])\n",
    "# for i in range(12):\n",
    "#     print(i)\n",
    "#     print(target_example[5:9,i*5:5+i*5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(target_example[5:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
