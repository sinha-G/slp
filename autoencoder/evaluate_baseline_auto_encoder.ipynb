{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOX               103069\n",
      "FALCO              90719\n",
      "MARTH              53728\n",
      "CAPTAIN_FALCON     38006\n",
      "SHEIK              27623\n",
      "PEACH              17438\n",
      "JIGGLYPUFF         16374\n",
      "SAMUS               9524\n",
      "ICE_CLIMBERS        6849\n",
      "GANONDORF           6655\n",
      "YOSHI               5725\n",
      "LUIGI               5230\n",
      "DR_MARIO            4202\n",
      "PIKACHU             4096\n",
      "LINK                2502\n",
      "NESS                2306\n",
      "DONKEY_KONG         2026\n",
      "GAME_AND_WATCH      1967\n",
      "MEWTWO              1775\n",
      "MARIO               1713\n",
      "YOUNG_LINK          1447\n",
      "ROY                 1272\n",
      "BOWSER               940\n",
      "KIRBY                556\n",
      "PICHU                230\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())\n",
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Label   Count   Shift\n",
      "0              FOX  103069  193497\n",
      "1            FALCO   90717  168117\n",
      "2            MARTH   53728  106569\n",
      "3   CAPTAIN_FALCON   38006   70125\n",
      "4            SHEIK   27623   59145\n",
      "5            PEACH   17438   39398\n",
      "6       JIGGLYPUFF   16374   35581\n",
      "7            SAMUS    9524   23031\n",
      "8     ICE_CLIMBERS    6849   15620\n",
      "9        GANONDORF    6655   12805\n",
      "10           YOSHI    5725   12226\n",
      "11           LUIGI    5230   11464\n",
      "12        DR_MARIO    4202    9062\n",
      "13         PIKACHU    4096    8991\n",
      "14            LINK    2502    5598\n",
      "15            NESS    2306    5812\n",
      "16     DONKEY_KONG    2026    4333\n",
      "17  GAME_AND_WATCH    1967    3693\n",
      "18          MEWTWO    1775    4511\n",
      "19           MARIO    1713    3824\n",
      "20      YOUNG_LINK    1447    3278\n",
      "21             ROY    1272    2685\n",
      "22          BOWSER     940    2196\n",
      "23           KIRBY     556    1237\n",
      "24           PICHU     230     491\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(60,5000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(60, proportion_of_segments=1, test_ratio = .005, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66805138, 6)\n",
      "(333001, 6)\n",
      "0.004959937897593497\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>177</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>236</td>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           player_inputs_np_sub_path labels  encoded_labels  \\\n",
       "0  ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...  FALCO               4   \n",
       "1  ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...  FALCO               4   \n",
       "2  ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...  FALCO               4   \n",
       "3  ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...  FALCO               4   \n",
       "4  ranked\\FALCO\\94f019ac-d174-4eb0-9af7-c514c1796...  FALCO               4   \n",
       "\n",
       "   segment_start_index  segment_index  segment_length  \n",
       "0                    0              0              60  \n",
       "1                   59              1              60  \n",
       "2                  118              2              60  \n",
       "3                  177              3              60  \n",
       "4                  236              4              60  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,int(segment_start):int(segment_end)]\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     transformed = np.zeros((13,60))\n",
    "        #     transformed[0,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] > 0)\n",
    "        #     transformed[1,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] < 0)\n",
    "        #     transformed[2,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] > 0)\n",
    "        #     transformed[3,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] < 0)\n",
    "        #     transformed[4,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] > 0)\n",
    "        #     transformed[5,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] < 0)\n",
    "        #     transformed[6,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] > 0)\n",
    "        #     transformed[7,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] < 0)\n",
    "        #     transformed[8:,:] = segment[4:]\n",
    "        #     segment = transformed\n",
    "        \n",
    "        if self.transform:\n",
    "            # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "            segment[0:4, :] -= .2875 * (segment[0:4, :] > 0)\n",
    "            segment[0:4, :] += .2875 * (segment[0:4, :] < 0)\n",
    "\n",
    "            # Scale inputs to be between -.5 and .5\n",
    "            segment[0:4, :] *= 1.40350877193 / 2\n",
    "            segment[0:4, :] += .5\n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(segment).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df,True)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df,True)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, loaders, device, num_epochs=1,rolling_loss_number = 100):\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        total = 0\n",
    "        rolling_loss = deque(maxlen=rolling_loss_number)\n",
    "        rolling_total = deque(maxlen=rolling_loss_number)\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            \n",
    "            # Resets the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Runs the forward pass with autocasting.\n",
    "            with autocast():\n",
    "                output_gpu = model(target_gpu)\n",
    "                loss = criterion(output_gpu , target_gpu) / (9 * 60 * target_cpu.size(0))\n",
    "\n",
    "                # print(loss)\n",
    "            \n",
    "            # Scales loss and calls backward() to create scaled gradients\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Clip gradients to avoid explosion\n",
    "            scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            # Before calling step(), check for inf or NaN values in the gradients\n",
    "            if any(torch.isinf(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: inf values in gradients!\")\n",
    "            elif any( torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: NaN values in gradients!\")\n",
    "                \n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "\n",
    "            # Update progress\n",
    "            # train_loss += loss.item()\n",
    "            # total += target_gpu.size(0) / (9 * 60 * target_cpu.size[0])\n",
    "            batch_total = target_gpu.size(0)\n",
    "            rolling_total.append(batch_total)\n",
    "            current_batch_loss = loss.item() \n",
    "            rolling_loss.append(current_batch_loss * target_cpu.size(0))\n",
    "            \n",
    "            train_loader_tqdm.set_postfix(loss=f'{sum(rolling_loss) / sum(rolling_total):.10f}')\n",
    "            \n",
    "\n",
    "            \n",
    "            # i += 1\n",
    "            # if i > 10:\n",
    "            # break\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu, target_gpu) / ((32 * 16 * 4) * 9 * 60)\n",
    "            \n",
    "            \n",
    "            total += target_gpu.shape[0] / (32 * 16 * 4)\n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.10f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / total:.10f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 60]             640\n",
      "       BatchNorm1d-2               [-1, 64, 60]             128\n",
      "              ReLU-3               [-1, 64, 60]               0\n",
      "            Conv1d-4               [-1, 64, 60]          12,352\n",
      "       BatchNorm1d-5               [-1, 64, 60]             128\n",
      "              ReLU-6               [-1, 64, 60]               0\n",
      "            Conv1d-7              [-1, 256, 60]          16,640\n",
      "       BatchNorm1d-8              [-1, 256, 60]             512\n",
      "            Conv1d-9              [-1, 256, 60]           2,560\n",
      "      BatchNorm1d-10              [-1, 256, 60]             512\n",
      "             ReLU-11              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-12              [-1, 256, 60]               0\n",
      "           Conv1d-13               [-1, 64, 60]          16,448\n",
      "      BatchNorm1d-14               [-1, 64, 60]             128\n",
      "             ReLU-15               [-1, 64, 60]               0\n",
      "           Conv1d-16               [-1, 64, 60]          12,352\n",
      "      BatchNorm1d-17               [-1, 64, 60]             128\n",
      "             ReLU-18               [-1, 64, 60]               0\n",
      "           Conv1d-19              [-1, 256, 60]          16,640\n",
      "      BatchNorm1d-20              [-1, 256, 60]             512\n",
      "             ReLU-21              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-22              [-1, 256, 60]               0\n",
      "           Conv1d-23              [-1, 128, 60]          32,896\n",
      "      BatchNorm1d-24              [-1, 128, 60]             256\n",
      "             ReLU-25              [-1, 128, 60]               0\n",
      "           Conv1d-26              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-27              [-1, 128, 30]             256\n",
      "             ReLU-28              [-1, 128, 30]               0\n",
      "           Conv1d-29              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-30              [-1, 512, 30]           1,024\n",
      "           Conv1d-31              [-1, 512, 30]         131,584\n",
      "      BatchNorm1d-32              [-1, 512, 30]           1,024\n",
      "             ReLU-33              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-34              [-1, 512, 30]               0\n",
      "           Conv1d-35              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-36              [-1, 128, 30]             256\n",
      "             ReLU-37              [-1, 128, 30]               0\n",
      "           Conv1d-38              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-39              [-1, 128, 30]             256\n",
      "             ReLU-40              [-1, 128, 30]               0\n",
      "           Conv1d-41              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-42              [-1, 512, 30]           1,024\n",
      "             ReLU-43              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-44              [-1, 512, 30]               0\n",
      "           Conv1d-45              [-1, 256, 30]         131,328\n",
      "      BatchNorm1d-46              [-1, 256, 30]             512\n",
      "             ReLU-47              [-1, 256, 30]               0\n",
      "           Conv1d-48              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-49              [-1, 256, 15]             512\n",
      "             ReLU-50              [-1, 256, 15]               0\n",
      "           Conv1d-51             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-52             [-1, 1024, 15]           2,048\n",
      "           Conv1d-53             [-1, 1024, 15]         525,312\n",
      "      BatchNorm1d-54             [-1, 1024, 15]           2,048\n",
      "             ReLU-55             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-56             [-1, 1024, 15]               0\n",
      "           Conv1d-57              [-1, 256, 15]         262,400\n",
      "      BatchNorm1d-58              [-1, 256, 15]             512\n",
      "             ReLU-59              [-1, 256, 15]               0\n",
      "           Conv1d-60              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-61              [-1, 256, 15]             512\n",
      "             ReLU-62              [-1, 256, 15]               0\n",
      "           Conv1d-63             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-64             [-1, 1024, 15]           2,048\n",
      "             ReLU-65             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-66             [-1, 1024, 15]               0\n",
      "           Conv1d-67              [-1, 512, 15]         524,800\n",
      "      BatchNorm1d-68              [-1, 512, 15]           1,024\n",
      "             ReLU-69              [-1, 512, 15]               0\n",
      "           Conv1d-70               [-1, 512, 8]         786,944\n",
      "      BatchNorm1d-71               [-1, 512, 8]           1,024\n",
      "             ReLU-72               [-1, 512, 8]               0\n",
      "           Conv1d-73              [-1, 2048, 8]       1,050,624\n",
      "      BatchNorm1d-74              [-1, 2048, 8]           4,096\n",
      "           Conv1d-75              [-1, 2048, 8]       2,099,200\n",
      "      BatchNorm1d-76              [-1, 2048, 8]           4,096\n",
      "             ReLU-77              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-78              [-1, 2048, 8]               0\n",
      "           Conv1d-79               [-1, 512, 8]       1,049,088\n",
      "      BatchNorm1d-80               [-1, 512, 8]           1,024\n",
      "             ReLU-81               [-1, 512, 8]               0\n",
      "           Conv1d-82               [-1, 512, 8]         786,944\n",
      "      BatchNorm1d-83               [-1, 512, 8]           1,024\n",
      "             ReLU-84               [-1, 512, 8]               0\n",
      "           Conv1d-85              [-1, 2048, 8]       1,050,624\n",
      "      BatchNorm1d-86              [-1, 2048, 8]           4,096\n",
      "             ReLU-87              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-88              [-1, 2048, 8]               0\n",
      "           Linear-89                   [-1, 64]       1,048,640\n",
      "             ReLU-90                   [-1, 64]               0\n",
      "           Linear-91                   [-1, 64]           4,160\n",
      "           Linear-92                   [-1, 64]           4,160\n",
      "             ReLU-93                   [-1, 64]               0\n",
      "           Linear-94                [-1, 16384]       1,064,960\n",
      "             ReLU-95                [-1, 16384]               0\n",
      "  ConvTranspose1d-96               [-1, 512, 8]       1,049,088\n",
      "      BatchNorm1d-97               [-1, 512, 8]           1,024\n",
      "             ReLU-98               [-1, 512, 8]               0\n",
      "  ConvTranspose1d-99               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-100               [-1, 512, 8]           1,024\n",
      "            ReLU-101               [-1, 512, 8]               0\n",
      " ConvTranspose1d-102              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-103              [-1, 2048, 8]           4,096\n",
      "            ReLU-104              [-1, 2048, 8]               0\n",
      "Decoder_Bottleneck-105              [-1, 2048, 8]               0\n",
      " ConvTranspose1d-106               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-107               [-1, 512, 8]           1,024\n",
      "            ReLU-108               [-1, 512, 8]               0\n",
      " ConvTranspose1d-109              [-1, 512, 15]         786,944\n",
      "     BatchNorm1d-110              [-1, 512, 15]           1,024\n",
      "            ReLU-111              [-1, 512, 15]               0\n",
      " ConvTranspose1d-112             [-1, 1024, 15]         525,312\n",
      "     BatchNorm1d-113             [-1, 1024, 15]           2,048\n",
      " ConvTranspose1d-114             [-1, 1024, 15]       2,098,176\n",
      "     BatchNorm1d-115             [-1, 1024, 15]           2,048\n",
      "            ReLU-116             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-117             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-118              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-119              [-1, 256, 15]             512\n",
      "            ReLU-120              [-1, 256, 15]               0\n",
      " ConvTranspose1d-121              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-122              [-1, 256, 15]             512\n",
      "            ReLU-123              [-1, 256, 15]               0\n",
      " ConvTranspose1d-124             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-125             [-1, 1024, 15]           2,048\n",
      "            ReLU-126             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-127             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-128              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-129              [-1, 256, 15]             512\n",
      "            ReLU-130              [-1, 256, 15]               0\n",
      " ConvTranspose1d-131              [-1, 256, 30]         196,864\n",
      "     BatchNorm1d-132              [-1, 256, 30]             512\n",
      "            ReLU-133              [-1, 256, 30]               0\n",
      " ConvTranspose1d-134              [-1, 512, 30]         131,584\n",
      "     BatchNorm1d-135              [-1, 512, 30]           1,024\n",
      " ConvTranspose1d-136              [-1, 512, 30]         524,800\n",
      "     BatchNorm1d-137              [-1, 512, 30]           1,024\n",
      "            ReLU-138              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-139              [-1, 512, 30]               0\n",
      " ConvTranspose1d-140              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-141              [-1, 128, 30]             256\n",
      "            ReLU-142              [-1, 128, 30]               0\n",
      " ConvTranspose1d-143              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-144              [-1, 128, 30]             256\n",
      "            ReLU-145              [-1, 128, 30]               0\n",
      " ConvTranspose1d-146              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-147              [-1, 512, 30]           1,024\n",
      "            ReLU-148              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-149              [-1, 512, 30]               0\n",
      " ConvTranspose1d-150              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-151              [-1, 128, 30]             256\n",
      "            ReLU-152              [-1, 128, 30]               0\n",
      " ConvTranspose1d-153              [-1, 128, 60]          49,280\n",
      "     BatchNorm1d-154              [-1, 128, 60]             256\n",
      "            ReLU-155              [-1, 128, 60]               0\n",
      " ConvTranspose1d-156              [-1, 256, 60]          33,024\n",
      "     BatchNorm1d-157              [-1, 256, 60]             512\n",
      " ConvTranspose1d-158              [-1, 256, 60]         131,328\n",
      "     BatchNorm1d-159              [-1, 256, 60]             512\n",
      "            ReLU-160              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-161              [-1, 256, 60]               0\n",
      " ConvTranspose1d-162               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-163               [-1, 64, 60]             128\n",
      "            ReLU-164               [-1, 64, 60]               0\n",
      " ConvTranspose1d-165               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-166               [-1, 64, 60]             128\n",
      "            ReLU-167               [-1, 64, 60]               0\n",
      " ConvTranspose1d-168              [-1, 256, 60]          16,640\n",
      "     BatchNorm1d-169              [-1, 256, 60]             512\n",
      "            ReLU-170              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-171              [-1, 256, 60]               0\n",
      " ConvTranspose1d-172               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-173               [-1, 64, 60]             128\n",
      "            ReLU-174               [-1, 64, 60]               0\n",
      " ConvTranspose1d-175               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-176               [-1, 64, 60]             128\n",
      "            ReLU-177               [-1, 64, 60]               0\n",
      " ConvTranspose1d-178                [-1, 9, 60]             585\n",
      "================================================================\n",
      "Total params: 21,620,297\n",
      "Trainable params: 21,620,297\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.41\n",
      "Params size (MB): 82.47\n",
      "Estimated Total Size (MB): 94.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ResNet_Autoencoder_Model import ResNet_Autoencoder\n",
    "\n",
    "channels = 9\n",
    "\n",
    "# Build model\n",
    "model = ResNet_Autoencoder(channels)\n",
    "model.load_state_dict(torch.load('../../melee_project_data/baseline_60s_autoencoder_weights.pt'))\n",
    "model.to('cuda')\n",
    "# # With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(channels, 60))\n",
    "\n",
    "# Check that the output shape and target shape match\n",
    "# training_example = torch.rand(9, 2 ** 12).to('cuda')\n",
    "# print('Target shape:', training_example.shape)\n",
    "# model.eval()\n",
    "# output = model(training_example)\n",
    "# print('Output shape:', output.shape)\n",
    "\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   1%|          | 266/32620 [00:45<1:31:22,  5.90batch/s, loss=0.0006116338]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 39\u001b[0m\n\u001b[1;32m     32\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# This seems to sometimes help\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# gc.collect()\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# torch.cuda.empty_cache()\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# start_time = time.time()\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Again, this sometimes seems to help\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Evaluate the trained model\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# evaluate_model(model, criterion, loaders, 'test', 'cuda')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 32\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, loaders, device, num_epochs, rolling_loss_number)\u001b[0m\n\u001b[1;32m     30\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Before calling step(), check for inf or NaN values in the gradients\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: inf values in gradients!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m( torch\u001b[38;5;241m.\u001b[39misnan(p\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "Cell \u001b[0;32mIn[40], line 32\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     30\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Before calling step(), check for inf or NaN values in the gradients\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(torch\u001b[38;5;241m.\u001b[39misinf(p\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: inf values in gradients!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m( torch\u001b[38;5;241m.\u001b[39misnan(p\u001b[38;5;241m.\u001b[39mgrad)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "# Pepare data loaders\n",
    "batch_size =  32 * 16 * 4\n",
    "num_workers = 22\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "\n",
    "# class LInfinityLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LInfinityLoss, self).__init__()\n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         # Compute the infinity norm of the difference\n",
    "#         return torch.max(torch.abs(predictions - targets))\n",
    "\n",
    "# class LPNormLoss(nn.Module):\n",
    "#     def __init__(self, p=2):\n",
    "#         super(LPNormLoss, self).__init__()\n",
    "#         self.p = p\n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         # Compute the lp norm of the difference\n",
    "#         return torch.norm(predictions - targets, p=self.p) ** self.p\n",
    "\n",
    "# Example usage:\n",
    "# criterion = LPNormLoss(p=2) \n",
    "# criterion = LInfinityLoss()\n",
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "optimizer = Adam(model.parameters(), lr=0.00001)\n",
    "num_epochs = 1\n",
    "\n",
    "# This seems to sometimes help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "# start_time = time.time()\n",
    "train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# Again, this sometimes seems to help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Evaluate the trained model\n",
    "# evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:22<00:00,  7.25batch/s, loss=0.0005786921]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Loss: 0.0005786921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loaders, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit='batch')\n",
    "        \n",
    "        for _, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            predictions.append(output_gpu.cpu().numpy())\n",
    "            targets.append(target_cpu.numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/163 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:19<00:00,  8.29batch/s]\n"
     ]
    }
   ],
   "source": [
    "pred, target = predict(model, loaders, 'test','cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
