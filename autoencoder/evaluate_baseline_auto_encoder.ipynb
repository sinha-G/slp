{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOX               103069\n",
      "FALCO              90719\n",
      "MARTH              53728\n",
      "CAPTAIN_FALCON     38006\n",
      "SHEIK              27623\n",
      "PEACH              17438\n",
      "JIGGLYPUFF         16374\n",
      "SAMUS               9524\n",
      "ICE_CLIMBERS        6849\n",
      "GANONDORF           6655\n",
      "YOSHI               5725\n",
      "LUIGI               5230\n",
      "DR_MARIO            4202\n",
      "PIKACHU             4096\n",
      "LINK                2502\n",
      "NESS                2306\n",
      "DONKEY_KONG         2026\n",
      "GAME_AND_WATCH      1967\n",
      "MEWTWO              1775\n",
      "MARIO               1713\n",
      "YOUNG_LINK          1447\n",
      "ROY                 1272\n",
      "BOWSER               940\n",
      "KIRBY                556\n",
      "PICHU                230\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())\n",
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Label   Count   Shift\n",
      "0              FOX  103069  193497\n",
      "1            FALCO   90717  168117\n",
      "2            MARTH   53728  106569\n",
      "3   CAPTAIN_FALCON   38006   70125\n",
      "4            SHEIK   27623   59145\n",
      "5            PEACH   17438   39398\n",
      "6       JIGGLYPUFF   16374   35581\n",
      "7            SAMUS    9524   23031\n",
      "8     ICE_CLIMBERS    6849   15620\n",
      "9        GANONDORF    6655   12805\n",
      "10           YOSHI    5725   12226\n",
      "11           LUIGI    5230   11464\n",
      "12        DR_MARIO    4202    9062\n",
      "13         PIKACHU    4096    8991\n",
      "14            LINK    2502    5598\n",
      "15            NESS    2306    5812\n",
      "16     DONKEY_KONG    2026    4333\n",
      "17  GAME_AND_WATCH    1967    3693\n",
      "18          MEWTWO    1775    4511\n",
      "19           MARIO    1713    3824\n",
      "20      YOUNG_LINK    1447    3278\n",
      "21             ROY    1272    2685\n",
      "22          BOWSER     940    2196\n",
      "23           KIRBY     556    1237\n",
      "24           PICHU     230     491\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(60,5000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           player_inputs_np_sub_path  length  num_segments  \\\n",
      "0  public\\FALCO\\bee06d45-fca6-437f-969a-901efa166...   28801             1   \n",
      "1  mango\\FALCO\\44e0962b-fdf7-4a16-acbe-61b5e5d609...   27200             1   \n",
      "2  ranked\\FALCO\\2f51bb81-4304-4c6d-ac53-960aba87c...   26024             1   \n",
      "3  ranked\\FALCO\\69cf9bb4-5f80-4e67-850d-ce0d7da1d...   25128             1   \n",
      "4  ranked\\FALCO\\04257d15-f02f-4001-a191-37b97d2ed...   24323             1   \n",
      "\n",
      "  labels  encoded_labels  \n",
      "0  FALCO               4  \n",
      "1  FALCO               4  \n",
      "2  FALCO               4  \n",
      "3  FALCO               4  \n",
      "4  FALCO               4  \n"
     ]
    }
   ],
   "source": [
    "train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(60, proportion_of_segments=1, test_ratio = .2, val = False)\n",
    "porportion = .05\n",
    "# train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "test_df = test_df.sample(frac=porportion, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 6)\n",
      "(25000, 6)\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mango\\FALCO\\b3c63d9d-efb7-4544-bdd6-9da7e221f1...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mango\\FALCO\\a24ef3f0-ab56-47e6-af18-5905aa43af...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mango\\FALCO\\24b523a3-18da-4ba2-a986-d0c99b6228...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mango\\FALCO\\60e0d81b-e0bd-420c-8fce-fe2b11645c...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>public\\FALCO\\b0925bbb-c009-49db-80e6-6985d4756...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           player_inputs_np_sub_path labels  encoded_labels  \\\n",
       "0  mango\\FALCO\\b3c63d9d-efb7-4544-bdd6-9da7e221f1...  FALCO               4   \n",
       "1  mango\\FALCO\\a24ef3f0-ab56-47e6-af18-5905aa43af...  FALCO               4   \n",
       "2  mango\\FALCO\\24b523a3-18da-4ba2-a986-d0c99b6228...  FALCO               4   \n",
       "3  mango\\FALCO\\60e0d81b-e0bd-420c-8fce-fe2b11645c...  FALCO               4   \n",
       "4  public\\FALCO\\b0925bbb-c009-49db-80e6-6985d4756...  FALCO               4   \n",
       "\n",
       "   segment_start_index  segment_index  segment_length  \n",
       "0                    0              0              60  \n",
       "1                    0              0              60  \n",
       "2                    0              0              60  \n",
       "3                    0              0              60  \n",
       "4                    0              0              60  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,int(segment_start):int(segment_end)]\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     transformed = np.zeros((13,60))\n",
    "        #     transformed[0,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] > 0)\n",
    "        #     transformed[1,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] < 0)\n",
    "        #     transformed[2,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] > 0)\n",
    "        #     transformed[3,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] < 0)\n",
    "        #     transformed[4,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] > 0)\n",
    "        #     transformed[5,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] < 0)\n",
    "        #     transformed[6,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] > 0)\n",
    "        #     transformed[7,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] < 0)\n",
    "        #     transformed[8:,:] = segment[4:]\n",
    "        #     segment = transformed\n",
    "        \n",
    "        if self.transform:\n",
    "            # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "            segment[0:4, :] -= .2875 * (segment[0:4, :] > 0)\n",
    "            segment[0:4, :] += .2875 * (segment[0:4, :] < 0)\n",
    "\n",
    "            # Scale inputs to be between -.5 and .5\n",
    "            segment[0:4, :] *= 1.40350877193 / 2\n",
    "            segment[0:4, :] += .5\n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(segment).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df,True)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df,True)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, loaders, device, num_epochs=1,rolling_loss_number = 100):\n",
    "    scaler = GradScaler()  # Initialize the gradient scaler\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        total = 0\n",
    "        rolling_loss = deque(maxlen=rolling_loss_number)\n",
    "        rolling_total = deque(maxlen=rolling_loss_number)\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            \n",
    "            # Resets the optimizer\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Runs the forward pass with autocasting.\n",
    "            with autocast():\n",
    "                output_gpu = model(target_gpu)\n",
    "                loss = criterion(output_gpu , target_gpu) / (9 * 60 * target_cpu.size(0))\n",
    "\n",
    "                # print(loss)\n",
    "            \n",
    "            # Scales loss and calls backward() to create scaled gradients\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Clip gradients to avoid explosion\n",
    "            scaler.unscale_(optimizer)  # unscale the gradients of optimizer's assigned params\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            # Before calling step(), check for inf or NaN values in the gradients\n",
    "            if any(torch.isinf(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: inf values in gradients!\")\n",
    "            elif any( torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: NaN values in gradients!\")\n",
    "                \n",
    "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
    "            # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n",
    "            # otherwise, optimizer.step() is skipped.\n",
    "            scaler.step(optimizer)\n",
    "            \n",
    "            # Updates the scale for next iteration.\n",
    "            scaler.update()\n",
    "\n",
    "            # Update progress\n",
    "            # train_loss += loss.item()\n",
    "            # total += target_gpu.size(0) / (9 * 60 * target_cpu.size[0])\n",
    "            batch_total = target_gpu.size(0)\n",
    "            rolling_total.append(batch_total)\n",
    "            current_batch_loss = loss.item() \n",
    "            rolling_loss.append(current_batch_loss * target_cpu.size(0))\n",
    "            \n",
    "            train_loader_tqdm.set_postfix(loss=f'{sum(rolling_loss) / sum(rolling_total):.10f}')\n",
    "            \n",
    "\n",
    "            \n",
    "            # i += 1\n",
    "            # if i > 10:\n",
    "            # break\n",
    "\n",
    "\n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu, target_gpu) / ((32 * 16 * 4) * 9 * 60)\n",
    "            \n",
    "            \n",
    "            total += target_gpu.shape[0] / (32 * 16 * 4)\n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.10f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / total:.10f}')\n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu, target_gpu) \n",
    "            \n",
    "            \n",
    "            \n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (batch_number + 1):.10f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / (batch_number + 1):.10f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 60]             640\n",
      "       BatchNorm1d-2               [-1, 64, 60]             128\n",
      "              ReLU-3               [-1, 64, 60]               0\n",
      "            Conv1d-4               [-1, 64, 60]          12,352\n",
      "       BatchNorm1d-5               [-1, 64, 60]             128\n",
      "              ReLU-6               [-1, 64, 60]               0\n",
      "            Conv1d-7              [-1, 256, 60]          16,640\n",
      "       BatchNorm1d-8              [-1, 256, 60]             512\n",
      "            Conv1d-9              [-1, 256, 60]           2,560\n",
      "      BatchNorm1d-10              [-1, 256, 60]             512\n",
      "             ReLU-11              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-12              [-1, 256, 60]               0\n",
      "           Conv1d-13               [-1, 64, 60]          16,448\n",
      "      BatchNorm1d-14               [-1, 64, 60]             128\n",
      "             ReLU-15               [-1, 64, 60]               0\n",
      "           Conv1d-16               [-1, 64, 60]          12,352\n",
      "      BatchNorm1d-17               [-1, 64, 60]             128\n",
      "             ReLU-18               [-1, 64, 60]               0\n",
      "           Conv1d-19              [-1, 256, 60]          16,640\n",
      "      BatchNorm1d-20              [-1, 256, 60]             512\n",
      "             ReLU-21              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-22              [-1, 256, 60]               0\n",
      "           Conv1d-23              [-1, 128, 60]          32,896\n",
      "      BatchNorm1d-24              [-1, 128, 60]             256\n",
      "             ReLU-25              [-1, 128, 60]               0\n",
      "           Conv1d-26              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-27              [-1, 128, 30]             256\n",
      "             ReLU-28              [-1, 128, 30]               0\n",
      "           Conv1d-29              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-30              [-1, 512, 30]           1,024\n",
      "           Conv1d-31              [-1, 512, 30]         131,584\n",
      "      BatchNorm1d-32              [-1, 512, 30]           1,024\n",
      "             ReLU-33              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-34              [-1, 512, 30]               0\n",
      "           Conv1d-35              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-36              [-1, 128, 30]             256\n",
      "             ReLU-37              [-1, 128, 30]               0\n",
      "           Conv1d-38              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-39              [-1, 128, 30]             256\n",
      "             ReLU-40              [-1, 128, 30]               0\n",
      "           Conv1d-41              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-42              [-1, 512, 30]           1,024\n",
      "             ReLU-43              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-44              [-1, 512, 30]               0\n",
      "           Conv1d-45              [-1, 256, 30]         131,328\n",
      "      BatchNorm1d-46              [-1, 256, 30]             512\n",
      "             ReLU-47              [-1, 256, 30]               0\n",
      "           Conv1d-48              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-49              [-1, 256, 15]             512\n",
      "             ReLU-50              [-1, 256, 15]               0\n",
      "           Conv1d-51             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-52             [-1, 1024, 15]           2,048\n",
      "           Conv1d-53             [-1, 1024, 15]         525,312\n",
      "      BatchNorm1d-54             [-1, 1024, 15]           2,048\n",
      "             ReLU-55             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-56             [-1, 1024, 15]               0\n",
      "           Conv1d-57              [-1, 256, 15]         262,400\n",
      "      BatchNorm1d-58              [-1, 256, 15]             512\n",
      "             ReLU-59              [-1, 256, 15]               0\n",
      "           Conv1d-60              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-61              [-1, 256, 15]             512\n",
      "             ReLU-62              [-1, 256, 15]               0\n",
      "           Conv1d-63             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-64             [-1, 1024, 15]           2,048\n",
      "             ReLU-65             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-66             [-1, 1024, 15]               0\n",
      "           Conv1d-67              [-1, 512, 15]         524,800\n",
      "      BatchNorm1d-68              [-1, 512, 15]           1,024\n",
      "             ReLU-69              [-1, 512, 15]               0\n",
      "           Conv1d-70               [-1, 512, 8]         786,944\n",
      "      BatchNorm1d-71               [-1, 512, 8]           1,024\n",
      "             ReLU-72               [-1, 512, 8]               0\n",
      "           Conv1d-73              [-1, 2048, 8]       1,050,624\n",
      "      BatchNorm1d-74              [-1, 2048, 8]           4,096\n",
      "           Conv1d-75              [-1, 2048, 8]       2,099,200\n",
      "      BatchNorm1d-76              [-1, 2048, 8]           4,096\n",
      "             ReLU-77              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-78              [-1, 2048, 8]               0\n",
      "           Conv1d-79               [-1, 512, 8]       1,049,088\n",
      "      BatchNorm1d-80               [-1, 512, 8]           1,024\n",
      "             ReLU-81               [-1, 512, 8]               0\n",
      "           Conv1d-82               [-1, 512, 8]         786,944\n",
      "      BatchNorm1d-83               [-1, 512, 8]           1,024\n",
      "             ReLU-84               [-1, 512, 8]               0\n",
      "           Conv1d-85              [-1, 2048, 8]       1,050,624\n",
      "      BatchNorm1d-86              [-1, 2048, 8]           4,096\n",
      "             ReLU-87              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-88              [-1, 2048, 8]               0\n",
      "           Linear-89                   [-1, 64]       1,048,640\n",
      "             ReLU-90                   [-1, 64]               0\n",
      "           Linear-91                   [-1, 64]           4,160\n",
      "           Linear-92                   [-1, 64]           4,160\n",
      "             ReLU-93                   [-1, 64]               0\n",
      "           Linear-94                [-1, 16384]       1,064,960\n",
      "             ReLU-95                [-1, 16384]               0\n",
      "  ConvTranspose1d-96               [-1, 512, 8]       1,049,088\n",
      "      BatchNorm1d-97               [-1, 512, 8]           1,024\n",
      "             ReLU-98               [-1, 512, 8]               0\n",
      "  ConvTranspose1d-99               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-100               [-1, 512, 8]           1,024\n",
      "            ReLU-101               [-1, 512, 8]               0\n",
      " ConvTranspose1d-102              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-103              [-1, 2048, 8]           4,096\n",
      "            ReLU-104              [-1, 2048, 8]               0\n",
      "Decoder_Bottleneck-105              [-1, 2048, 8]               0\n",
      " ConvTranspose1d-106               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-107               [-1, 512, 8]           1,024\n",
      "            ReLU-108               [-1, 512, 8]               0\n",
      " ConvTranspose1d-109              [-1, 512, 15]         786,944\n",
      "     BatchNorm1d-110              [-1, 512, 15]           1,024\n",
      "            ReLU-111              [-1, 512, 15]               0\n",
      " ConvTranspose1d-112             [-1, 1024, 15]         525,312\n",
      "     BatchNorm1d-113             [-1, 1024, 15]           2,048\n",
      " ConvTranspose1d-114             [-1, 1024, 15]       2,098,176\n",
      "     BatchNorm1d-115             [-1, 1024, 15]           2,048\n",
      "            ReLU-116             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-117             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-118              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-119              [-1, 256, 15]             512\n",
      "            ReLU-120              [-1, 256, 15]               0\n",
      " ConvTranspose1d-121              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-122              [-1, 256, 15]             512\n",
      "            ReLU-123              [-1, 256, 15]               0\n",
      " ConvTranspose1d-124             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-125             [-1, 1024, 15]           2,048\n",
      "            ReLU-126             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-127             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-128              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-129              [-1, 256, 15]             512\n",
      "            ReLU-130              [-1, 256, 15]               0\n",
      " ConvTranspose1d-131              [-1, 256, 30]         196,864\n",
      "     BatchNorm1d-132              [-1, 256, 30]             512\n",
      "            ReLU-133              [-1, 256, 30]               0\n",
      " ConvTranspose1d-134              [-1, 512, 30]         131,584\n",
      "     BatchNorm1d-135              [-1, 512, 30]           1,024\n",
      " ConvTranspose1d-136              [-1, 512, 30]         524,800\n",
      "     BatchNorm1d-137              [-1, 512, 30]           1,024\n",
      "            ReLU-138              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-139              [-1, 512, 30]               0\n",
      " ConvTranspose1d-140              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-141              [-1, 128, 30]             256\n",
      "            ReLU-142              [-1, 128, 30]               0\n",
      " ConvTranspose1d-143              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-144              [-1, 128, 30]             256\n",
      "            ReLU-145              [-1, 128, 30]               0\n",
      " ConvTranspose1d-146              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-147              [-1, 512, 30]           1,024\n",
      "            ReLU-148              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-149              [-1, 512, 30]               0\n",
      " ConvTranspose1d-150              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-151              [-1, 128, 30]             256\n",
      "            ReLU-152              [-1, 128, 30]               0\n",
      " ConvTranspose1d-153              [-1, 128, 60]          49,280\n",
      "     BatchNorm1d-154              [-1, 128, 60]             256\n",
      "            ReLU-155              [-1, 128, 60]               0\n",
      " ConvTranspose1d-156              [-1, 256, 60]          33,024\n",
      "     BatchNorm1d-157              [-1, 256, 60]             512\n",
      " ConvTranspose1d-158              [-1, 256, 60]         131,328\n",
      "     BatchNorm1d-159              [-1, 256, 60]             512\n",
      "            ReLU-160              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-161              [-1, 256, 60]               0\n",
      " ConvTranspose1d-162               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-163               [-1, 64, 60]             128\n",
      "            ReLU-164               [-1, 64, 60]               0\n",
      " ConvTranspose1d-165               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-166               [-1, 64, 60]             128\n",
      "            ReLU-167               [-1, 64, 60]               0\n",
      " ConvTranspose1d-168              [-1, 256, 60]          16,640\n",
      "     BatchNorm1d-169              [-1, 256, 60]             512\n",
      "            ReLU-170              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-171              [-1, 256, 60]               0\n",
      " ConvTranspose1d-172               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-173               [-1, 64, 60]             128\n",
      "            ReLU-174               [-1, 64, 60]               0\n",
      " ConvTranspose1d-175               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-176               [-1, 64, 60]             128\n",
      "            ReLU-177               [-1, 64, 60]               0\n",
      " ConvTranspose1d-178                [-1, 9, 60]             585\n",
      "================================================================\n",
      "Total params: 21,620,297\n",
      "Trainable params: 21,620,297\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.41\n",
      "Params size (MB): 82.47\n",
      "Estimated Total Size (MB): 94.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ResNet_Autoencoder_Model_Baseline import ResNet_Autoencoder\n",
    "\n",
    "channels = 9\n",
    "\n",
    "# Build model\n",
    "model = ResNet_Autoencoder(channels)\n",
    "model.load_state_dict(torch.load('../../melee_project_data/baseline_2_60s_autoencoder_weights.pt'))\n",
    "model.to('cuda')\n",
    "# # With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(channels, 60))\n",
    "\n",
    "# Check that the output shape and target shape match\n",
    "# training_example = torch.rand(9, 2 ** 12).to('cuda')\n",
    "# print('Target shape:', training_example.shape)\n",
    "# model.eval()\n",
    "# output = model(training_example)\n",
    "# print('Output shape:', output.shape)\n",
    "\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(nn.Module,):\n",
    "    def __init__(self, batch_size):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "        self.binary_ce = nn.BCELoss(reduce='sum')\n",
    "        self.epsilon = 1e-7\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # analogue_difference = -(pred[:,:4,:] - target[:,:4,:])\n",
    "        # angles = torch.arctan2(analogue_difference[:,[0,2],:],analogue_difference[:,[1,3],:])\n",
    "        # angle_abs_mean = torch.mean(torch.abs(angles), axis=2) \n",
    "        # angle_abs_mean = torch.mean(angle_abs_mean, axis=1)\n",
    "        # angle_abs_mean = torch.mean(angle_abs_mean) / (3.141592653589793) # so that it is between (0,1)\n",
    "        \n",
    "        # radi = torch.sqrt(analogue_difference[:,[0,2],:] ** 2 + analogue_difference[:,[1,3],:] ** 2)\n",
    "        # radi_mean = torch.mean(radi, axis=2)\n",
    "        # radi_mean = torch.mean(radi, axis=1)\n",
    "        # radi_mean = torch.mean(radi)\n",
    "        \n",
    "        analogue_difference = target[:, :4, :] - pred[:, :4, :]\n",
    "        angles = torch.arctan2(analogue_difference[:, [1, 3], :], analogue_difference[:, [0, 2], :])\n",
    "        \n",
    "        mean_sin = torch.mean(torch.sin(angles))\n",
    "        mean_cos = torch.mean(torch.cos(angles))\n",
    "        circular_mean_angle = torch.atan2(mean_sin, mean_cos)\n",
    "        angle_loss = 1 - torch.cos(circular_mean_angle)  # 1 - cos(theta) minimizes when theta -> 0\n",
    "        \n",
    "        radi = torch.sqrt(torch.sum(analogue_difference ** 2, dim=1))\n",
    "        radi_mean = torch.mean(radi)\n",
    "        \n",
    "       \n",
    "        \n",
    "        clipped_pred = torch.clamp(pred[:,-5:,:], self.epsilon, 1-self.epsilon)\n",
    "        BCE_loss_array = -(target[:,-5:,:] * torch.log(clipped_pred) + (1 - target[:,-5:,:]) * torch.log(1 - clipped_pred))\n",
    "        BCE_mean = torch.mean(BCE_loss_array, axis=2)\n",
    "        BCE_mean = torch.mean(BCE_mean, axis=1)\n",
    "        BCE_mean = torch.mean(BCE_mean)\n",
    "        \n",
    "        return (angle_loss * 2 + radi_mean * 2 + BCE_mean * 5) * (pred.size(0) / self.batch_size)\n",
    "    \n",
    "    \n",
    "class CustomLoss(nn.Module,):\n",
    "    def __init__(self, batch_size):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "        self.binary_ce = nn.BCELoss(reduce='sum')\n",
    "        self.epsilon = 1e-7\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "class CustomLoss(nn.Module,):\n",
    "    def __init__(self, batch_size):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "        self.binary_ce = nn.BCELoss(reduce='sum')\n",
    "        self.epsilon = 1e-7\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # analogue_difference = -(pred[:,:4,:] - target[:,:4,:])\n",
    "        # angles = torch.arctan2(analogue_difference[:,[0,2],:],analogue_difference[:,[1,3],:])\n",
    "        # angle_abs_mean = torch.mean(torch.abs(angles), axis=2) \n",
    "        # angle_abs_mean = torch.mean(angle_abs_mean, axis=1)\n",
    "        # angle_abs_mean = torch.mean(angle_abs_mean) / (3.141592653589793) # so that it is between (0,1)\n",
    "        \n",
    "        # radi = torch.sqrt(analogue_difference[:,[0,2],:] ** 2 + analogue_difference[:,[1,3],:] ** 2)\n",
    "        # radi_mean = torch.mean(radi, axis=2)\n",
    "        # radi_mean = torch.mean(radi, axis=1)\n",
    "        # radi_mean = torch.mean(radi)\n",
    "        \n",
    "        size = pred.size(0)\n",
    "        \n",
    "        # analogue_difference = target[:, :4, :] - pred[:, :4, :]\n",
    "        # angles = torch.arctan2(analogue_difference[:, [1, 3], :], analogue_difference[:, [0, 2], :])\n",
    "        \n",
    "        # mean_sin = torch.mean(torch.sin(angles))\n",
    "        # mean_cos = torch.mean(torch.cos(angles))\n",
    "        # circular_mean_angle = torch.atan2(mean_sin, mean_cos)\n",
    "        # angle_loss = 1 - torch.cos(circular_mean_angle)  # 1 - cos(theta) minimizes when theta -> 0\n",
    "        \n",
    "        # angles = torch.arctan2(pred[:, [0, 2], :], analogue_difference[:, [1, ], :])\n",
    "        \n",
    "        # Assume pred and target are [batch_size, 4, 60], with [:, :2, :] for joystick and [:, 2:, :] for C-stick\n",
    "        # Calculating angles for predicted and target values\n",
    "        pred_angles = torch.atan2(pred[:, [1, 3], :], pred[:, [0, 2], :])\n",
    "        target_angles = torch.atan2(target[:, [1, 3], :], target[:, [0, 2], :])\n",
    "\n",
    "        # Calculating squared difference of angles\n",
    "        angle_diff = pred_angles - target_angles\n",
    "        # Correct for the wrap-around issue\n",
    "        angle_diff = torch.atan2(torch.sin(angle_diff), torch.cos(angle_diff))\n",
    "        squared_angle_diff = angle_diff ** 2\n",
    "        squared_angle_diff_mean = torch.mean(squared_angle_diff)\n",
    "        \n",
    "        \n",
    "        analogue_difference = -(pred[:,:4,:] - target[:,:4,:])\n",
    "        radi = torch.sqrt(analogue_difference ** 2)\n",
    "        radi_mean = torch.mean(radi)\n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        clipped_pred = torch.clamp(pred[:,-5:,:], self.epsilon, 1-self.epsilon)\n",
    "        BCE_loss_array = -(target[:,-5:,:] * torch.log(clipped_pred) + (1 - target[:,-5:,:]) * torch.log(1 - clipped_pred))\n",
    "        BCE_mean = torch.mean(BCE_loss_array, axis=2)\n",
    "        BCE_mean = torch.mean(BCE_mean, axis=1)\n",
    "        BCE_mean = torch.mean(BCE_mean)\n",
    "        \n",
    "        return (squared_angle_diff_mean * 2 + BCE_mean * 5) * (size / self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "# Pepare data loaders\n",
    "batch_size =  32 * 16 * 4\n",
    "num_workers = 22\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "\n",
    "# class LInfinityLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(LInfinityLoss, self).__init__()\n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         # Compute the infinity norm of the difference\n",
    "#         return torch.max(torch.abs(predictions - targets))\n",
    "\n",
    "# class LPNormLoss(nn.Module):\n",
    "#     def __init__(self, p=2):\n",
    "#         super(LPNormLoss, self).__init__()\n",
    "#         self.p = p\n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         # Compute the lp norm of the difference\n",
    "#         return torch.norm(predictions - targets, p=self.p) ** self.p\n",
    "\n",
    "# Example usage:\n",
    "# criterion = LPNormLoss(p=2) \n",
    "# criterion = LInfinityLoss()\n",
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "criterion = CustomLoss(batch_size)\n",
    "optimizer = Adam(model.parameters(), lr=0.00001)\n",
    "num_epochs = 1\n",
    "\n",
    "# This seems to sometimes help\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "# start_time = time.time()\n",
    "# train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# Again, this sometimes seems to help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Evaluate the trained model\n",
    "# evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loaders, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit='batch')\n",
    "        \n",
    "        for _, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            output_gpu[:,4:] = torch.sigmoid(output_gpu[:,4:])\n",
    "            \n",
    "            predictions.append(output_gpu.cpu().numpy())\n",
    "            targets.append(target_cpu.numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 13/13 [00:04<00:00,  2.76batch/s]\n"
     ]
    }
   ],
   "source": [
    "pred, target = predict(model, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 9, 60)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2, 60)\n",
      "[[ 1.2114534   0.56722546  0.1945238   0.41473767 -0.2972267   0.6639792\n",
      "   0.40455726  1.1537422   1.1336186   1.1182882 ]\n",
      " [-0.31513587 -0.52172405 -2.7128515  -1.4265958  -0.60534894 -1.2343793\n",
      "   3.1194046   3.0062232  -0.47930446 -1.6753025 ]]\n"
     ]
    }
   ],
   "source": [
    "angles_jstick = np.arctan2(pred[:,[0,2],:]-target[:,[0,2],:],pred[:,[1,3],:]-target[:,[1,3],:])\n",
    "print(angles_jstick.shape)\n",
    "print(angles_jstick[0,:,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.521183   0.5046528  0.50356823 0.5025298  0.49913093 0.50424206\n",
      " 0.5026152  0.5069179  0.50575376 0.50485307]\n",
      "[0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5 0.5]\n"
     ]
    }
   ],
   "source": [
    "print(pred[0,0,:10])\n",
    "print(target[0,0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0002066559675667021\n",
      "Average Angle JSTICK: 0.8246167500813802\n",
      "Average Angle CSTICK: 1.54216677347819\n",
      "Average Radius: 1.428045654296875\n",
      "Average Radius: 1.4130874633789063\n"
     ]
    }
   ],
   "source": [
    "print('MSE:',(np.sum((pred[0,:2,:]-target[0,:2,:])**2))/(180))\n",
    "print('Average Angle JSTICK:',(np.sum(np.abs(angles_jstick[0,0,:]))/60))\n",
    "print('Average Angle CSTICK:',(np.sum(np.abs(angles_jstick[0,1,:]))/60))\n",
    "print('Average Radius:', np.sum(np.sqrt((pred[0,:2,:]**2+target[0,:2,:]**2)))/60)\n",
    "print('Average Radius:', np.sum(np.sqrt((pred[0,2:4,:]**2+target[0,2:4,:]**2)))/60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore what using the average angle and radius would be compared to MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 4, 60)\n",
      "\n",
      "Analogue Loss Compared:\n",
      "Average Angle JSTICK: 0.82461673\n",
      "Average Angle CSTICK: 1.5421668\n",
      "Average Radius JSTICK: 0.016763074\n",
      "Average Radius CSTICK: 0.003239665\n",
      "MSE: 0.00015843043414254983\n"
     ]
    }
   ],
   "source": [
    "analogue_difference = pred[:,:4,:] - target[:,:4,:]\n",
    "print(analogue_difference.shape)\n",
    "\n",
    "analogue_loss_angles = np.arctan2(analogue_difference[:,[0,2],:],analogue_difference[:,[1,3],:])\n",
    "analogue_loss_radius_squared = np.sqrt(analogue_difference[:,[0,2],:] ** 2 + analogue_difference[:,[1,3],:] ** 2)\n",
    "\n",
    "# print(analogue_loss_angles[0,:2,:5])\n",
    "# print(analogue_loss_radius_squared[0,:2,:5])\n",
    "\n",
    "avg_loss_angle_jstick = np.mean(np.abs(analogue_loss_angles[0,0,:])) \n",
    "avg_loss_angle_cstick = np.mean(np.abs(analogue_loss_angles[0,1,:])) \n",
    "avg_loss_radius_jstick = np.mean(np.abs(analogue_loss_radius_squared[0,0,:])) \n",
    "avg_loss_radius_cstick = np.mean(np.abs(analogue_loss_radius_squared[0,1,:])) \n",
    "\n",
    "print()\n",
    "print('Analogue Loss Compared:')\n",
    "\n",
    "print('Average Angle JSTICK:', avg_loss_angle_jstick)\n",
    "print('Average Angle CSTICK:', avg_loss_angle_cstick)\n",
    "\n",
    "print('Average Radius JSTICK:', avg_loss_radius_jstick)\n",
    "print('Average Radius CSTICK:', avg_loss_radius_cstick)\n",
    "\n",
    "print('MSE:', np.sum(analogue_difference[0,:,:] ** 2) / (4 * 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 4, 60)\n",
      "\n",
      "Analogue Loss Compared:\n",
      "Circular Mean Angle JSTICK: 0.9059241\n",
      "Circular Mean Angle CSTICK: 3.060217\n",
      "Average Radius JSTICK: 0.016763074\n",
      "Average Radius CSTICK: 0.003239665\n",
      "MSE: 0.00015843043414254983\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "\n",
    "analogue_difference = pred[:, :4, :] - target[:, :4, :]\n",
    "print(analogue_difference.shape)\n",
    "\n",
    "analogue_loss_angles = np.arctan2(analogue_difference[:, [1, 3], :], analogue_difference[:, [0, 2], :])\n",
    "analogue_loss_radius_squared = np.sqrt(analogue_difference[:, [0, 2], :] ** 2 + analogue_difference[:, [1, 3], :] ** 2)\n",
    "\n",
    "# Computing Circular Mean for angles\n",
    "mean_sin_jstick = np.mean(np.sin(analogue_loss_angles[0, 0, :]))\n",
    "mean_cos_jstick = np.mean(np.cos(analogue_loss_angles[0, 0, :]))\n",
    "circular_mean_angle_jstick = np.arctan2(mean_sin_jstick, mean_cos_jstick)\n",
    "\n",
    "mean_sin_cstick = np.mean(np.sin(analogue_loss_angles[0, 1, :]))\n",
    "mean_cos_cstick = np.mean(np.cos(analogue_loss_angles[0, 1, :]))\n",
    "circular_mean_angle_cstick = np.arctan2(mean_sin_cstick, mean_cos_cstick)\n",
    "\n",
    "# Averaging radii\n",
    "avg_loss_radius_jstick = np.mean(analogue_loss_radius_squared[0, 0, :])\n",
    "avg_loss_radius_cstick = np.mean(analogue_loss_radius_squared[0, 1, :])\n",
    "\n",
    "print()\n",
    "print('Analogue Loss Compared:')\n",
    "\n",
    "# Output circular means instead of average of absolute values\n",
    "print('Circular Mean Angle JSTICK:', circular_mean_angle_jstick)\n",
    "print('Circular Mean Angle CSTICK:', circular_mean_angle_cstick)\n",
    "\n",
    "print('Average Radius JSTICK:', avg_loss_radius_jstick)\n",
    "print('Average Radius CSTICK:', avg_loss_radius_cstick)\n",
    "\n",
    "# Computing MSE for verification\n",
    "mse = np.sum(analogue_difference[0, :, :] ** 2) / (4 * 60)\n",
    "print('MSE:', mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5)\n",
      "[[0.00032678 0.00042905 0.0005722  0.00035194 0.00042568]\n",
      " [0.01918583 0.0004474  0.000605   0.00191631 0.00239175]\n",
      " [0.00102462 0.00080669 0.00107307 0.00872025 0.00071917]\n",
      " ...\n",
      " [0.00055049 0.00053377 0.00062672 0.00057324 0.00056013]\n",
      " [0.00937921 0.00079227 0.00078771 0.00104979 0.00089436]\n",
      " [0.00054625 0.00034012 0.00050679 0.00159828 0.00058816]]\n"
     ]
    }
   ],
   "source": [
    "epsilon = 1e-7  # A small number to prevent log(0)\n",
    "clipped_preds = np.clip(pred, epsilon, 1 - epsilon)\n",
    "BCE_loss_array = -(target[:,4:,:] * np.log(clipped_preds[:,4:,:]) + (1 - target[:,4:,:]) * np.log(1 - clipped_preds[:,4:,:]))\n",
    "\n",
    "avg_loss_by_button = np.mean(BCE_loss_array,axis = 2)\n",
    "# avg_loss_by_button = np.mean(avg_loss_by_button,axis = 1)\n",
    "print(avg_loss_by_button.shape)\n",
    "print(avg_loss_by_button)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00212148 0.34825632 0.00687332 0.01907327 0.00275244]\n",
      " [0.12455419 0.3631464  0.00726736 0.10385385 0.01546485]\n",
      " [0.00665185 0.65478436 0.01288992 0.47259094 0.00465011]\n",
      " ...\n",
      " [0.0035738  0.43325781 0.0075283  0.03106665 0.00362177]\n",
      " [0.06088973 0.64307682 0.00946212 0.05689309 0.00578284]\n",
      " [0.00354623 0.27607265 0.00608758 0.08661844 0.003803  ]]\n"
     ]
    }
   ],
   "source": [
    "average_frequency = [0.154036,\t0.001232,\t0.083249,\t0.018452,\t0.154657]\n",
    "print(avg_loss_by_button / average_frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TRIGGER_LOGICAL_first_frame_target  TRIGGER_LOGICAL_first_frame_pred  \\\n",
      "count                        25000.000000                      25000.000000   \n",
      "mean                             0.143080                          0.142800   \n",
      "std                              0.350161                          0.349876   \n",
      "min                              0.000000                          0.000000   \n",
      "25%                              0.000000                          0.000000   \n",
      "50%                              0.000000                          0.000000   \n",
      "75%                              0.000000                          0.000000   \n",
      "max                              1.000000                          1.000000   \n",
      "\n",
      "       TRIGGER_LOGICAL_last_frame_target  TRIGGER_LOGICAL_last_frame_pred  \\\n",
      "count                       25000.000000                     25000.000000   \n",
      "mean                            0.188880                         0.184080   \n",
      "std                             0.391421                         0.387557   \n",
      "min                             0.000000                         0.000000   \n",
      "25%                             0.000000                         0.000000   \n",
      "50%                             0.000000                         0.000000   \n",
      "75%                             0.000000                         0.000000   \n",
      "max                             1.000000                         1.000000   \n",
      "\n",
      "       TRIGGER_LOGICAL_num_presses_target  TRIGGER_LOGICAL_num_presses_pred  \\\n",
      "count                        25000.000000                      25000.000000   \n",
      "mean                             0.812680                          0.804160   \n",
      "std                              0.808614                          0.798043   \n",
      "min                              0.000000                          0.000000   \n",
      "25%                              0.000000                          0.000000   \n",
      "50%                              1.000000                          1.000000   \n",
      "75%                              1.000000                          1.000000   \n",
      "max                              5.000000                          5.000000   \n",
      "\n",
      "       Z_first_frame_target  Z_first_frame_pred  Z_last_frame_target  \\\n",
      "count           25000.00000        25000.000000         25000.000000   \n",
      "mean                0.00452            0.004440             0.006720   \n",
      "std                 0.06708            0.066487             0.081701   \n",
      "min                 0.00000            0.000000             0.000000   \n",
      "25%                 0.00000            0.000000             0.000000   \n",
      "50%                 0.00000            0.000000             0.000000   \n",
      "75%                 0.00000            0.000000             0.000000   \n",
      "max                 1.00000            1.000000             1.000000   \n",
      "\n",
      "       Z_last_frame_pred  ...  B_last_frame_target  B_last_frame_pred  \\\n",
      "count       25000.000000  ...         25000.000000       25000.000000   \n",
      "mean            0.006160  ...             0.038320           0.034320   \n",
      "std             0.078245  ...             0.191971           0.182053   \n",
      "min             0.000000  ...             0.000000           0.000000   \n",
      "25%             0.000000  ...             0.000000           0.000000   \n",
      "50%             0.000000  ...             0.000000           0.000000   \n",
      "75%             0.000000  ...             0.000000           0.000000   \n",
      "max             1.000000  ...             1.000000           1.000000   \n",
      "\n",
      "       B_num_presses_target  B_num_presses_pred  X_or_Y_first_frame_target  \\\n",
      "count          25000.000000        25000.000000               25000.000000   \n",
      "mean               0.312040            0.307200                   0.083480   \n",
      "std                0.741763            0.732536                   0.276612   \n",
      "min                0.000000            0.000000                   0.000000   \n",
      "25%                0.000000            0.000000                   0.000000   \n",
      "50%                0.000000            0.000000                   0.000000   \n",
      "75%                0.000000            0.000000                   0.000000   \n",
      "max               10.000000           10.000000                   1.000000   \n",
      "\n",
      "       X_or_Y_first_frame_pred  X_or_Y_last_frame_target  \\\n",
      "count             25000.000000              25000.000000   \n",
      "mean                  0.083320                  0.101840   \n",
      "std                   0.276371                  0.302444   \n",
      "min                   0.000000                  0.000000   \n",
      "25%                   0.000000                  0.000000   \n",
      "50%                   0.000000                  0.000000   \n",
      "75%                   0.000000                  0.000000   \n",
      "max                   1.000000                  1.000000   \n",
      "\n",
      "       X_or_Y_last_frame_pred  X_or_Y_num_presses_target  \\\n",
      "count            25000.000000               25000.000000   \n",
      "mean                 0.098960                   0.900600   \n",
      "std                  0.298614                   0.860203   \n",
      "min                  0.000000                   0.000000   \n",
      "25%                  0.000000                   0.000000   \n",
      "50%                  0.000000                   1.000000   \n",
      "75%                  0.000000                   1.000000   \n",
      "max                  1.000000                   8.000000   \n",
      "\n",
      "       X_or_Y_num_presses_pred  \n",
      "count             25000.000000  \n",
      "mean                  0.870680  \n",
      "std                   0.853502  \n",
      "min                   0.000000  \n",
      "25%                   0.000000  \n",
      "50%                   1.000000  \n",
      "75%                   1.000000  \n",
      "max                   8.000000  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "def predicted_button_analysis(pred, target):\n",
    "    buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "    \n",
    "    # Create dictionary to hold the data\n",
    "    data = {}\n",
    "    \n",
    "    # Process for first frame and last frame for both target and pred\n",
    "    for index, button in enumerate(buttons):\n",
    "        data[f'{button}_first_frame_target'] = (target[:, 4+index, 0] > .5).astype(int)\n",
    "        data[f'{button}_first_frame_pred'] = (pred[:, 4+index, 0] > .5).astype(int)\n",
    "        data[f'{button}_last_frame_target'] = (target[:, 4+index, -1] > .5).astype(int)\n",
    "        data[f'{button}_last_frame_pred'] = (pred[:, 4+index, -1] > .5).astype(int)\n",
    "        \n",
    "        # Ensure that the dimensions match for prepend operation\n",
    "        prepend_target = np.expand_dims(target[:, 4+index, 0], axis=1)\n",
    "        prepend_pred = np.expand_dims(pred[:, 4+index, 0], axis=1)\n",
    "\n",
    "        transitions_target = np.diff(target[:, 4+index, :], axis=1, prepend=prepend_target)\n",
    "        transitions_pred = np.diff(pred[:, 4+index, :], axis=1, prepend=prepend_pred)\n",
    "        \n",
    "        count_0_to_1_target = np.sum(transitions_target > .5, axis=1)\n",
    "        count_0_to_1_target += target[:,4+index,0] > .5\n",
    "        count_0_to_1_pred = np.sum(transitions_pred > .5, axis=1)\n",
    "        count_0_to_1_pred += pred[:,4+index,0] > .5\n",
    "        \n",
    "        data[f'{button}_num_presses_target'] = count_0_to_1_target\n",
    "        data[f'{button}_num_presses_pred'] = count_0_to_1_pred\n",
    "        \n",
    "    # Create DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'pred' and 'target' are defined and appropriate for this function\n",
    "df = predicted_button_analysis(pred, target)\n",
    "print(df.describe())\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TRIGGER_LOGICAL -----\n",
      "\n",
      "Pressed 0 times\n",
      "   Count\n",
      "0   9912\n",
      "1    171\n",
      "2      8\n",
      "Accuracy: 0.9823\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "    Count\n",
      "-1    217\n",
      " 0   9931\n",
      " 1    140\n",
      " 2      2\n",
      "Accuracy: 0.9651\n",
      "Under-prediction rate: 0.6045\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2      3\n",
      "-1    218\n",
      " 0   3649\n",
      " 1     27\n",
      "Accuracy: 0.9364\n",
      "Under-prediction rate: 0.8911\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3      1\n",
      "-2      8\n",
      "-1     83\n",
      " 0    563\n",
      " 1      6\n",
      "Accuracy: 0.8517\n",
      "Under-prediction rate: 0.9388\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-3      1\n",
      "-2      3\n",
      "-1     12\n",
      " 0     39\n",
      "Accuracy: 0.7091\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-5      1\n",
      "-4      1\n",
      "-3      1\n",
      "-1      1\n",
      " 0      2\n",
      "Accuracy: 0.3333\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 6 times\n",
      "Empty DataFrame\n",
      "Columns: [Count]\n",
      "Index: []\n",
      "Accuracy: 0.0000\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "----- Z -----\n",
      "\n",
      "Pressed 0 times\n",
      "   Count\n",
      "0  23771\n",
      "1      6\n",
      "Accuracy: 0.9997\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "    Count\n",
      "-1     30\n",
      " 0   1001\n",
      "Accuracy: 0.9709\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2      1\n",
      "-1      5\n",
      " 0    122\n",
      "Accuracy: 0.9531\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3      1\n",
      " 0     46\n",
      "Accuracy: 0.9787\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-2      1\n",
      "-1      4\n",
      " 0      8\n",
      "Accuracy: 0.6154\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 5 times\n",
      "   Count\n",
      "0      2\n",
      "Accuracy: 1.0000\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 6 times\n",
      "   Count\n",
      "0      1\n",
      "Accuracy: 1.0000\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "----- A -----\n",
      "\n",
      "Pressed 0 times\n",
      "   Count\n",
      "0  16945\n",
      "1     19\n",
      "Accuracy: 0.9989\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "    Count\n",
      "-1     85\n",
      " 0   5517\n",
      " 1      5\n",
      "Accuracy: 0.9839\n",
      "Under-prediction rate: 0.9444\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-1     46\n",
      " 0   1546\n",
      " 1      2\n",
      "Accuracy: 0.9699\n",
      "Under-prediction rate: 0.9583\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-1     37\n",
      " 0    477\n",
      "Accuracy: 0.9280\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-2      5\n",
      "-1     15\n",
      " 0    184\n",
      "Accuracy: 0.9020\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-2      1\n",
      "-1      9\n",
      " 0     65\n",
      "Accuracy: 0.8667\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-2      2\n",
      "-1      4\n",
      " 0     19\n",
      "Accuracy: 0.7600\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "----- B -----\n",
      "\n",
      "Pressed 0 times\n",
      "   Count\n",
      "0  19697\n",
      "1     38\n",
      "Accuracy: 0.9981\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "    Count\n",
      "-1     90\n",
      " 0   3619\n",
      "Accuracy: 0.9757\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2      4\n",
      "-1     18\n",
      " 0    962\n",
      " 1      1\n",
      "Accuracy: 0.9766\n",
      "Under-prediction rate: 0.9565\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3      1\n",
      "-1     13\n",
      " 0    311\n",
      "Accuracy: 0.9569\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-3      1\n",
      "-2      2\n",
      "-1      6\n",
      " 0    141\n",
      "Accuracy: 0.9400\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-3      1\n",
      "-1      4\n",
      " 0     52\n",
      "Accuracy: 0.9123\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-1      3\n",
      " 0     16\n",
      "Accuracy: 0.8421\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "----- X_or_Y -----\n",
      "\n",
      "Pressed 0 times\n",
      "   Count\n",
      "0   9083\n",
      "1      2\n",
      "Accuracy: 0.9998\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "    Count\n",
      "-1    397\n",
      " 0  10083\n",
      " 1      5\n",
      "Accuracy: 0.9617\n",
      "Under-prediction rate: 0.9876\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2     10\n",
      "-1    254\n",
      " 0   4226\n",
      " 1      2\n",
      "Accuracy: 0.9408\n",
      "Under-prediction rate: 0.9925\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3      1\n",
      "-2      5\n",
      "-1     64\n",
      " 0    715\n",
      " 1      1\n",
      "Accuracy: 0.9097\n",
      "Under-prediction rate: 0.9859\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-2      1\n",
      "-1      4\n",
      " 0    101\n",
      "Accuracy: 0.9528\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-1      2\n",
      " 0     22\n",
      "Accuracy: 0.9167\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-2      1\n",
      " 0     11\n",
      "Accuracy: 0.9167\n",
      "Under-prediction rate: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "# buttons = ['X_or_Y']\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame(np.arange(7,dtype=np.int16),columns=['Target Pressed'])\n",
    "# print(summary_df)\n",
    "\n",
    "\n",
    "for index, button in enumerate(buttons):\n",
    "    print('-----', button, '-----')\n",
    "    example_data = []\n",
    "    accuracy_data = []\n",
    "    under_predicted_data = []\n",
    "    for i in range(7):\n",
    "        print()\n",
    "        print(f'Pressed {i} times')\n",
    "        df_button_is_pressed = df[df[f'{button}_num_presses_target'] == i]\n",
    "        columns = [\n",
    "                    f'{button}_first_frame_target',\n",
    "                    f'{button}_first_frame_pred',\n",
    "                    f'{button}_last_frame_target',\n",
    "                    f'{button}_last_frame_pred',\n",
    "                    f'{button}_num_presses_target',\n",
    "                    f'{button}_num_presses_pred']    \n",
    "        df_button_is_pressed = df_button_is_pressed[columns]\n",
    "        \n",
    "        # print(f'Target was pressed {i} time(s): < 0 means under predicting')\n",
    "        df_button_is_pressed['Off by'] = df_button_is_pressed[f'{button}_num_presses_pred'] - df_button_is_pressed[f'{button}_num_presses_target']\n",
    "        counts = df_button_is_pressed['Off by'].value_counts().sort_index().to_frame(name='Count')\n",
    "\n",
    "        # Calculating accuracy\n",
    "        total_presses = counts['Count'].sum()\n",
    "        correct_predictions = counts.loc[0, 'Count'] if 0 in counts.index else 0\n",
    "        accuracy = correct_predictions / total_presses if total_presses > 0 else 0\n",
    "        print(counts)\n",
    "        print('Accuracy:', \"{:.4f}\".format(accuracy))\n",
    "        accuracy_data += [accuracy]\n",
    "        \n",
    "                # Calculating under-prediction rate among non-zero predictions\n",
    "        under_predicted = counts[counts.index < 0]['Count'].sum() if any(counts.index < 0) else 0\n",
    "        non_zero_predictions = total_presses - (counts.loc[0, 'Count'] if 0 in counts.index else 0)\n",
    "        under_prediction_rate = under_predicted / non_zero_predictions if non_zero_predictions > 0 else 0\n",
    "        print(f'Under-prediction rate: {under_prediction_rate:.4f}')\n",
    "        under_predicted_data += [under_prediction_rate]\n",
    "        \n",
    "        example_data += [df_button_is_pressed.shape[0] / df.shape[0]]\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    summary_df[f'{button} Examples'] = example_data\n",
    "    summary_df[f'{button} Correct'] = accuracy_data\n",
    "    summary_df[f'{button} Under'] = under_predicted_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table shows:\n",
      "- The percentage of test examples that were actually pressed n times.\n",
      "- Accuracy of the prediction given the button was pressed n times.\n",
      "- Under prediction rate of an incorrect prediction given the button was pressed n times.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Pressed</th>\n",
       "      <th>TRIGGER_LOGICAL Examples</th>\n",
       "      <th>TRIGGER_LOGICAL Correct</th>\n",
       "      <th>TRIGGER_LOGICAL Under</th>\n",
       "      <th>Z Examples</th>\n",
       "      <th>Z Correct</th>\n",
       "      <th>Z Under</th>\n",
       "      <th>A Examples</th>\n",
       "      <th>A Correct</th>\n",
       "      <th>A Under</th>\n",
       "      <th>B Examples</th>\n",
       "      <th>B Correct</th>\n",
       "      <th>B Under</th>\n",
       "      <th>X_or_Y Examples</th>\n",
       "      <th>X_or_Y Correct</th>\n",
       "      <th>X_or_Y Under</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.40364</td>\n",
       "      <td>0.982261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.95108</td>\n",
       "      <td>0.999748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67856</td>\n",
       "      <td>0.998880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.78940</td>\n",
       "      <td>0.998074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.36340</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.41160</td>\n",
       "      <td>0.965112</td>\n",
       "      <td>0.604457</td>\n",
       "      <td>0.04124</td>\n",
       "      <td>0.970902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.22428</td>\n",
       "      <td>0.983949</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.14836</td>\n",
       "      <td>0.975735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.41940</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.987562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.15588</td>\n",
       "      <td>0.936361</td>\n",
       "      <td>0.891129</td>\n",
       "      <td>0.00512</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06376</td>\n",
       "      <td>0.969887</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.03940</td>\n",
       "      <td>0.976650</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.17968</td>\n",
       "      <td>0.940784</td>\n",
       "      <td>0.992481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.02644</td>\n",
       "      <td>0.851740</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.978723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02056</td>\n",
       "      <td>0.928016</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.01300</td>\n",
       "      <td>0.956923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.03144</td>\n",
       "      <td>0.909669</td>\n",
       "      <td>0.985915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00220</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00816</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00600</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00424</td>\n",
       "      <td>0.952830</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00228</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00096</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target Pressed  TRIGGER_LOGICAL Examples  TRIGGER_LOGICAL Correct  \\\n",
       "0               0                   0.40364                 0.982261   \n",
       "1               1                   0.41160                 0.965112   \n",
       "2               2                   0.15588                 0.936361   \n",
       "3               3                   0.02644                 0.851740   \n",
       "4               4                   0.00220                 0.709091   \n",
       "5               5                   0.00024                 0.333333   \n",
       "6               6                   0.00000                 0.000000   \n",
       "\n",
       "   TRIGGER_LOGICAL Under  Z Examples  Z Correct  Z Under  A Examples  \\\n",
       "0               0.000000     0.95108   0.999748      0.0     0.67856   \n",
       "1               0.604457     0.04124   0.970902      1.0     0.22428   \n",
       "2               0.891129     0.00512   0.953125      1.0     0.06376   \n",
       "3               0.938776     0.00188   0.978723      1.0     0.02056   \n",
       "4               1.000000     0.00052   0.615385      1.0     0.00816   \n",
       "5               1.000000     0.00008   1.000000      0.0     0.00300   \n",
       "6               0.000000     0.00004   1.000000      0.0     0.00100   \n",
       "\n",
       "   A Correct   A Under  B Examples  B Correct   B Under  X_or_Y Examples  \\\n",
       "0   0.998880  0.000000     0.78940   0.998074  0.000000          0.36340   \n",
       "1   0.983949  0.944444     0.14836   0.975735  1.000000          0.41940   \n",
       "2   0.969887  0.958333     0.03940   0.976650  0.956522          0.17968   \n",
       "3   0.928016  1.000000     0.01300   0.956923  1.000000          0.03144   \n",
       "4   0.901961  1.000000     0.00600   0.940000  1.000000          0.00424   \n",
       "5   0.866667  1.000000     0.00228   0.912281  1.000000          0.00096   \n",
       "6   0.760000  1.000000     0.00076   0.842105  1.000000          0.00048   \n",
       "\n",
       "   X_or_Y Correct  X_or_Y Under  \n",
       "0        0.999780      0.000000  \n",
       "1        0.961660      0.987562  \n",
       "2        0.940784      0.992481  \n",
       "3        0.909669      0.985915  \n",
       "4        0.952830      1.000000  \n",
       "5        0.916667      1.000000  \n",
       "6        0.916667      1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Table shows:')\n",
    "print('- The percentage of test examples that were actually pressed n times.')\n",
    "print('- Accuracy of the prediction given the button was pressed n times.')\n",
    "print('- Under prediction rate of an incorrect prediction given the button was pressed n times.')           \n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table shows:\n",
      "- Percentage of test examples where the button was not pressed on the first or last frame\n",
      "- Given the button was pressed or not on the first or last frame, what was the accuracy of the prediction.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Button</th>\n",
       "      <th>Ratio target[0]==0</th>\n",
       "      <th>Acc target[0]==0</th>\n",
       "      <th>Acc target[0]==1</th>\n",
       "      <th>Ratio target[-1]==0</th>\n",
       "      <th>Acc target[-1]==0</th>\n",
       "      <th>Acc target[-1]==1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRIGGER_LOGICAL</td>\n",
       "      <td>0.85692</td>\n",
       "      <td>0.998600</td>\n",
       "      <td>0.989656</td>\n",
       "      <td>0.81112</td>\n",
       "      <td>0.999260</td>\n",
       "      <td>0.971410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z</td>\n",
       "      <td>0.99548</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>0.99328</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.910714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.95536</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>0.981183</td>\n",
       "      <td>0.93340</td>\n",
       "      <td>0.999914</td>\n",
       "      <td>0.978979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.93172</td>\n",
       "      <td>0.999871</td>\n",
       "      <td>0.989455</td>\n",
       "      <td>0.96168</td>\n",
       "      <td>0.999501</td>\n",
       "      <td>0.883090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_or_Y</td>\n",
       "      <td>0.91652</td>\n",
       "      <td>0.999956</td>\n",
       "      <td>0.997604</td>\n",
       "      <td>0.89816</td>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.970935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Button  Ratio target[0]==0  Acc target[0]==0  Acc target[0]==1  \\\n",
       "0  TRIGGER_LOGICAL             0.85692          0.998600          0.989656   \n",
       "1                Z             0.99548          0.999960          0.973451   \n",
       "2                A             0.95536          0.999916          0.981183   \n",
       "3                B             0.93172          0.999871          0.989455   \n",
       "4           X_or_Y             0.91652          0.999956          0.997604   \n",
       "\n",
       "   Ratio target[-1]==0  Acc target[-1]==0  Acc target[-1]==1  \n",
       "0              0.81112           0.999260           0.971410  \n",
       "1              0.99328           0.999960           0.910714  \n",
       "2              0.93340           0.999914           0.978979  \n",
       "3              0.96168           0.999501           0.883090  \n",
       "4              0.89816           0.999911           0.970935  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "\n",
    "first_and_last_df = pd.DataFrame(buttons, columns=['Button'])\n",
    "for index, button in enumerate(buttons):\n",
    "    first_frame_0 = (df[f'{button}_first_frame_target'] == 0)\n",
    "    last_frame_0 = (df[f'{button}_last_frame_target'] == 0)\n",
    "    \n",
    "    first_and_last_df.loc[index, 'Ratio target[0]==0'] = first_frame_0.mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[0]==0'] = 1 - df.loc[first_frame_0, f'{button}_first_frame_pred'].mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[0]==1'] = df.loc[~first_frame_0, f'{button}_first_frame_pred'].mean()\n",
    "    \n",
    "    first_and_last_df.loc[index, 'Ratio target[-1]==0'] = last_frame_0.mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[-1]==0'] = 1-df.loc[last_frame_0, f'{button}_last_frame_pred'].mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[-1]==1'] = df.loc[~last_frame_0, f'{button}_last_frame_pred'].mean()\n",
    "    \n",
    "print('Table shows:')\n",
    "print('- Percentage of test examples where the button was not pressed on the first or last frame')\n",
    "print('- Given the button was pressed or not on the first or last frame, what was the accuracy of the prediction.')\n",
    "\n",
    "first_and_last_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the target button was pressed once and the prediction was pressed once. How big was the difference in length of the button press. TO DO: further restrict to the prediction being pressed for the same number of frames and seeing if it was pressed at the exact same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIGGER_LOGICAL\n",
      "[[ -51    1]\n",
      " [ -37    1]\n",
      " [ -26    1]\n",
      " [ -22    2]\n",
      " [ -19    1]\n",
      " [ -15    1]\n",
      " [  -7    1]\n",
      " [  -6    1]\n",
      " [  -5    1]\n",
      " [  -4    2]\n",
      " [  -3    3]\n",
      " [  -2   65]\n",
      " [  -1 1263]\n",
      " [   0 8068]\n",
      " [   1  486]\n",
      " [   2   16]\n",
      " [   3    2]\n",
      " [   6    1]\n",
      " [   9    1]\n",
      " [  11    1]\n",
      " [  12    1]\n",
      " [  15    1]\n",
      " [  17    1]\n",
      " [  24    1]\n",
      " [  26    1]\n",
      " [  27    1]\n",
      " [  29    1]\n",
      " [  31    1]\n",
      " [  37    1]\n",
      " [  40    1]\n",
      " [  47    1]\n",
      " [  54    1]\n",
      " [  58    1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z\n",
      "[[ -5   1]\n",
      " [ -3   1]\n",
      " [ -2   2]\n",
      " [ -1  29]\n",
      " [  0 944]\n",
      " [  1  24]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGdCAYAAABO2DpVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAX1klEQVR4nO3df5BVdf348dcCcRFlr0Cg7LCwiOUvAg2E/FEfKNQYNG0mahzMFR1HHNSUyR/bTNEv3e2XWsSgOQZOadAvtDK1ZFD/ABRRJqXRxCBWUDGNvcB3ulu79/sH812/+5Ef3t333ctdHo+Z88c5nst5eby6T889e25VoVAoBABAAn3KPQAA0HsICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASKZfTx+wvb09tm/fHoMGDYqqqqqePjwA0AWFQiF27doVNTU10afP/q9L9HhYbN++PWpra3v6sABAAs3NzTFy5Mj9/vUeD4tBgwZFxN7Bqqure/rwAEAX5HK5qK2t7fg5vj89Hhb/7+OP6upqYQEAFeZgtzG4eRMASEZYAADJFBUWdXV1UVVV9Z5l3rx5pZoPAKggRd1jsW7dumhra+tYf/HFF+Occ86JWbNmJR8MAKg8RYXFsGHDOq03NTXF2LFj43/+53+SDgUAVKYu32PR2toaP//5z+Pyyy/3oCsAICK68eumDz74YOzcuTMuu+yyA+6Xz+cjn893rOdyua4eEgA4xHX5isW9994bM2bMiJqamgPu19jYGNlstmPx1E0A6L2qCoVCodgX/eMf/4jjjjsufvvb38aFF154wH33dcWitrY2WlpaPCALACpELpeLbDZ70J/fXfooZMmSJTF8+PCYOXPmQffNZDKRyWS6chgAoMIU/VFIe3t7LFmyJOrr66Nfvx5/IjgAcAgrOiwef/zx2Lp1a1x++eWlmAcAqGBFX3I499xzowu3ZQAAhwHfFQIAJOMmCYDDUN0tD5d7hOS2NB38FwooPVcsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIJmiw2Lbtm1xySWXxNChQ+OII46Ij3zkI/Hss8+WYjYAoML0K2bnf/3rX3HWWWfFtGnT4pFHHolhw4bFK6+8EoMHDy7VfABABSkqLL7zne9EbW1tLFmypGPbmDFjkg8FAFSmoj4K+d3vfheTJk2KWbNmxfDhw+O0006Le+6554CvyefzkcvlOi0AQO9UVFj8/e9/j8WLF8eHPvSheOyxx+Lqq6+O6667Lu677779vqaxsTGy2WzHUltb2+2hAYBDU1WhUCi835379+8fkyZNitWrV3dsu+6662LdunWxZs2afb4mn89HPp/vWM/lclFbWxstLS1RXV3djdEB6Kq6Wx4u9wjJbWmaWe4RerVcLhfZbPagP7+LumIxYsSIOPnkkzttO+mkk2Lr1q37fU0mk4nq6upOCwDQOxUVFmeddVa8/PLLnbb97W9/i9GjRycdCgCoTEWFxQ033BBr166N2267LTZt2hQPPPBA/OQnP4l58+aVaj4AoIIUFRann356rFixIn7xi1/EuHHj4lvf+lbceeedMXv27FLNBwBUkKKeYxERcf7558f5559filkAgArnu0IAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACRTVFh8/etfj6qqqk7LiSeeWKrZAIAK06/YF5xyyinx+OOPv/sH9Cv6jwAAeqmiq6Bfv35x7LHHlmIWAKDCFX2PxSuvvBI1NTVx3HHHxezZs2Pr1q0H3D+fz0cul+u0AAC9U1FhMWXKlFi6dGk8+uijsXjx4ti8eXN8/OMfj127du33NY2NjZHNZjuW2trabg8NAByaqgqFQqGrL965c2eMHj06br/99rjiiiv2uU8+n498Pt+xnsvlora2NlpaWqK6urqrhwagG+puebjcIyS3pWlmuUfo1XK5XGSz2YP+/O7WnZdHH310fPjDH45Nmzbtd59MJhOZTKY7hwEAKkS3nmOxe/fuePXVV2PEiBGp5gEAKlhRYfHlL385nnzyydiyZUusXr06PvvZz0bfvn3j4osvLtV8AEAFKeqjkNdeey0uvvjiePvtt2PYsGFx9tlnx9q1a2PYsGGlmg8AqCBFhcWyZctKNQcA0Av4rhAAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgmW6FRVNTU1RVVcX111+faBwAoJJ1OSzWrVsXd999d4wfPz7lPABABetSWOzevTtmz54d99xzTwwePDj1TABAhepSWMybNy9mzpwZ06dPP+i++Xw+crlcpwUA6J36FfuCZcuWxXPPPRfr1q17X/s3NjbGN77xjaIHAwAqT1FXLJqbm+NLX/pS3H///TFgwID39ZqGhoZoaWnpWJqbm7s0KABw6CvqisX69etjx44d8dGPfrRjW1tbWzz11FPx4x//OPL5fPTt27fTazKZTGQymTTTAgCHtKLC4lOf+lS88MILnbbNmTMnTjzxxLj55pvfExUAwOGlqLAYNGhQjBs3rtO2I488MoYOHfqe7QDA4ceTNwGAZIr+rZD/7YknnkgwBgDQG7hiAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIJl+5R4AoKfU3fJwuUdIbkvTzHKPAJ24YgEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGQ/IAuCw5aFp6bliAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEimqLBYvHhxjB8/Pqqrq6O6ujrOOOOMeOSRR0o1GwBQYYoKi5EjR0ZTU1OsX78+nn322fjkJz8ZF154YWzcuLFU8wEAFaSoB2RdcMEFndZvvfXWWLx4caxduzZOOeWUpIMBAJWny0/ebGtri1/96lexZ8+eOOOMM/a7Xz6fj3w+37Gey+W6ekgA4BBX9M2bL7zwQhx11FGRyWRi7ty5sWLFijj55JP3u39jY2Nks9mOpba2tlsDAwCHrqLD4oQTTogNGzbE008/HVdffXXU19fHX//61/3u39DQEC0tLR1Lc3NztwYGAA5dRX8U0r9//zj++OMjImLixImxbt26+OEPfxh33333PvfPZDKRyWS6NyUAUBG6/RyL9vb2TvdQAACHr6KuWDQ0NMSMGTNi1KhRsWvXrnjggQfiiSeeiMcee6xU8wEAFaSosNixY0dceuml8frrr0c2m43x48fHY489Fuecc06p5gMAKkhRYXHvvfeWag4AoBfwXSEAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIpKiwaGxvj9NNPj0GDBsXw4cPjoosuipdffrlUswEAFaaosHjyySdj3rx5sXbt2vjzn/8c//nPf+Lcc8+NPXv2lGo+AKCC9Ctm50cffbTT+tKlS2P48OGxfv36+MQnPpF0MACg8nTrHouWlpaIiBgyZEiSYQCAylbUFYv/X3t7e1x//fVx1llnxbhx4/a7Xz6fj3w+37Gey+W6ekgA4BDX5SsW8+bNixdffDGWLVt2wP0aGxsjm812LLW1tV09JABwiOtSWFxzzTXxhz/8IVatWhUjR4484L4NDQ3R0tLSsTQ3N3dpUADg0FfURyGFQiGuvfbaWLFiRTzxxBMxZsyYg74mk8lEJpPp8oAAQOUoKizmzZsXDzzwQDz00EMxaNCgeOONNyIiIpvNxhFHHFGSAQGAylHURyGLFy+OlpaWmDp1aowYMaJjWb58eanmAwAqSNEfhQAA7I/vCgEAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkEy/cg8AlF7dLQ+Xe4TktjTNLPcIwD4UfcXiqaeeigsuuCBqamqiqqoqHnzwwRKMBQBUoqLDYs+ePTFhwoRYtGhRKeYBACpY0R+FzJgxI2bMmFGKWQCAClfyeyzy+Xzk8/mO9VwuV+pDAgBlUvLfCmlsbIxsNtux1NbWlvqQAECZlDwsGhoaoqWlpWNpbm4u9SEBgDIp+UchmUwmMplMqQ8DABwCPCALAEim6CsWu3fvjk2bNnWsb968OTZs2BBDhgyJUaNGJR0OAKgsRYfFs88+G9OmTetYnz9/fkRE1NfXx9KlS5MNBgBUnqLDYurUqVEoFEoxCwBQ4dxjAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJFPybzftSXW3PFzuEZLb0jSz3CNUNO8JgJ7ligUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIBlhAQAkIywAgGSEBQCQjLAAAJIRFgBAMsICAEhGWAAAyQgLACAZYQEAJCMsAIBkhAUAkIywAACSERYAQDLCAgBIRlgAAMkICwAgmS6FxaJFi6Kuri4GDBgQU6ZMiWeeeSb1XABABSo6LJYvXx7z58+PBQsWxHPPPRcTJkyI8847L3bs2FGK+QCAClJ0WNx+++1x5ZVXxpw5c+Lkk0+Ou+66KwYOHBg//elPSzEfAFBB+hWzc2tra6xfvz4aGho6tvXp0yemT58ea9as2edr8vl85PP5jvWWlpaIiMjlcl2Z94Da8/8n+Z9ZbqU4T4cT74m9nIe9nId3ORd7OQ/F/7mFQuHAOxaKsG3btkJEFFavXt1p+4033liYPHnyPl+zYMGCQkRYLBaLxWLpBUtzc/MBW6GoKxZd0dDQEPPnz+9Yb29vj3feeSeGDh0aVVVVpT58SeRyuaitrY3m5uaorq4u9zhl4zzs5Ty8y7nYy3nYy3l4V284F4VCIXbt2hU1NTUH3K+osPjgBz8Yffv2jTfffLPT9jfffDOOPfbYfb4mk8lEJpPptO3oo48u5rCHrOrq6op9g6TkPOzlPLzLudjLedjLeXhXpZ+LbDZ70H2Kunmzf//+MXHixFi5cmXHtvb29li5cmWcccYZxU8IAPQqRX8UMn/+/Kivr49JkybF5MmT484774w9e/bEnDlzSjEfAFBBig6LL3zhC/HWW2/F1772tXjjjTfi1FNPjUcffTSOOeaYUsx3SMpkMrFgwYL3fMRzuHEe9nIe3uVc7OU87OU8vOtwOhdVhYP+3ggAwPvju0IAgGSEBQCQjLAAAJIRFgBAMsKim+rq6qKqqqrT0tTUVO6xyiafz8epp54aVVVVsWHDhnKPUxaf+cxnYtSoUTFgwIAYMWJEfPGLX4zt27eXe6wetWXLlrjiiitizJgxccQRR8TYsWNjwYIF0draWu7Retytt94aZ555ZgwcOLDXPBzw/Vq0aFHU1dXFgAEDYsqUKfHMM8+Ue6Qe99RTT8UFF1wQNTU1UVVVFQ8++GC5Ryo5YZHAN7/5zXj99dc7lmuvvbbcI5XNTTfddNDHvfZ206ZNi1/+8pfx8ssvx29+85t49dVX43Of+1y5x+pRL730UrS3t8fdd98dGzdujDvuuCPuuuuu+MpXvlLu0Xpca2trzJo1K66++upyj9Kjli9fHvPnz48FCxbEc889FxMmTIjzzjsvduzYUe7RetSePXtiwoQJsWjRonKP0nOK+RIy3mv06NGFO+64o9xjHBL++Mc/Fk488cTCxo0bCxFReP7558s90iHhoYceKlRVVRVaW1vLPUpZffe73y2MGTOm3GOUzZIlSwrZbLbcY/SYyZMnF+bNm9ex3tbWVqipqSk0NjaWcaryiojCihUryj1GyblikUBTU1MMHTo0TjvttPje974X//3vf8s9Uo97880348orr4yf/exnMXDgwHKPc8h455134v77748zzzwzPvCBD5R7nLJqaWmJIUOGlHsMekBra2usX78+pk+f3rGtT58+MX369FizZk0ZJ6MnCItuuu6662LZsmWxatWquOqqq+K2226Lm266qdxj9ahCoRCXXXZZzJ07NyZNmlTucQ4JN998cxx55JExdOjQ2Lp1azz00EPlHqmsNm3aFAsXLoyrrrqq3KPQA/75z39GW1vbe57IfMwxx8Qbb7xRpqnoKcJiH2655Zb33JD5v5eXXnopIvZ+d8rUqVNj/PjxMXfu3PjBD34QCxcujHw+X+a/i+57v+dh4cKFsWvXrmhoaCj3yCVTzHsiIuLGG2+M559/Pv70pz9F375949JLL41CL3jIbbHnISJi27Zt8elPfzpmzZoVV155ZZkmT6sr5wEOFx7pvQ9vvfVWvP322wfc57jjjov+/fu/Z/vGjRtj3Lhx8dJLL8UJJ5xQqhF7xPs9D5///Ofj97//fVRVVXVsb2tri759+8bs2bPjvvvuK/WoJded98Rrr70WtbW1sXr16or/FuBiz8P27dtj6tSp8bGPfSyWLl0affr0jv+X6cr7YenSpXH99dfHzp07Szxd+bW2tsbAgQPj17/+dVx00UUd2+vr62Pnzp2H7RW8qqqqWLFiRadz0hsV/SVkh4Nhw4bFsGHDuvTaDRs2RJ8+fWL48OGJp+p57/c8/OhHP4pvf/vbHevbt2+P8847L5YvXx5Tpkwp5Yg9pjvvifb29oiIXnEVq5jzsG3btpg2bVpMnDgxlixZ0muiIqJ774fDQf/+/WPixImxcuXKjh+i7e3tsXLlyrjmmmvKOxwlJyy6Yc2aNfH000/HtGnTYtCgQbFmzZq44YYb4pJLLonBgweXe7weM2rUqE7rRx11VEREjB07NkaOHFmOkcrm6aefjnXr1sXZZ58dgwcPjldffTW++tWvxtixYyv+akUxtm3bFlOnTo3Ro0fH97///Xjrrbc6/tqxxx5bxsl63tatW+Odd96JrVu3RltbW8fzXY4//viOf1d6o/nz50d9fX1MmjQpJk+eHHfeeWfs2bMn5syZU+7RetTu3btj06ZNHeubN2+ODRs2xJAhQ97z385eo7y/lFLZ1q9fX5gyZUohm80WBgwYUDjppJMKt912W+Hf//53uUcrq82bNx+2v276l7/8pTBt2rTCkCFDCplMplBXV1eYO3du4bXXXiv3aD1qyZIlhYjY53K4qa+v3+d5WLVqVblHK7mFCxcWRo0aVejfv39h8uTJhbVr15Z7pB63atWqff7zr6+vL/doJeMeCwAgmd7zoScAUHbCAgBIRlgAAMkICwAgGWEBACQjLACAZIQFAJCMsAAAkhEWAEAywgIASEZYAADJCAsAIJn/C6yks5kzJRhsAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[  -2    1]\n",
      " [  -1   25]\n",
      " [   0 4849]\n",
      " [   1  608]\n",
      " [   2   33]\n",
      " [  46    1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "[[  -5    1]\n",
      " [  -2    4]\n",
      " [  -1   96]\n",
      " [   0 3410]\n",
      " [   1  104]\n",
      " [   2    3]\n",
      " [   3    1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_or_Y\n",
      "[[  -2    2]\n",
      " [  -1  218]\n",
      " [   0 9780]\n",
      " [   1   82]\n",
      " [   2    1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "results = []\n",
    "\n",
    "for index, button in enumerate(buttons):\n",
    "    button_is_pressed_once = (df[f'{button}_num_presses_target'] == 1) & (df[f'{button}_num_presses_pred'] == 1)\n",
    "    \n",
    "    \n",
    "    # Filtering rows where the button was pressed exactly once in both target and prediction\n",
    "    target_button_is_pressed_once = target[button_is_pressed_once, 4+index, :]\n",
    "    pred_button_is_pressed_once = pred[button_is_pressed_once, 4+index, :]\n",
    "    \n",
    "    # Calculating indices for the first and last button press in the target and prediction for each example\n",
    "    index_of_first_1_target = np.argmax(target_button_is_pressed_once > 0.5, axis=1)\n",
    "    index_of_first_1_pred = np.argmax(pred_button_is_pressed_once > 0.5, axis=1)\n",
    "    index_of_last_1_target = (target_button_is_pressed_once.shape[1] - np.argmax(target_button_is_pressed_once[:, ::-1] > 0.5, axis=1))\n",
    "    index_of_last_1_pred = (pred_button_is_pressed_once.shape[1] - np.argmax(pred_button_is_pressed_once[:, ::-1] > 0.5, axis=1))\n",
    "\n",
    "    length_of_target_press = index_of_last_1_target - index_of_first_1_target\n",
    "    length_of_pred_press = index_of_last_1_pred - index_of_first_1_pred\n",
    "    \n",
    "    unique, count = np.unique(length_of_pred_press - length_of_target_press, return_counts=True)\n",
    "    print(button)\n",
    "    print(np.array([unique,count]).T)\n",
    "\n",
    "    plt.bar(unique,np.log(count+1))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the differece in the angle of the joystick and c-stick.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45.        45.        45.        ... 45.        45.        45.       ]\n",
      " [ 1.0050856  1.0050856  1.0050856 ...  1.0050856  1.0050856  1.0050856]\n",
      " [45.        45.        45.        ... 45.        45.        45.       ]\n",
      " ...\n",
      " [45.        45.        45.        ... 45.        45.        45.       ]\n",
      " [45.        45.        45.        ... 45.        45.        45.       ]\n",
      " [ 1.0050856  2.009553   3.0127897 ...  4.844002   4.685901   5.4403324]]\n",
      "[[0.70710677 0.70710677 0.70710677 ... 0.70710677 0.70710677 0.70710677]\n",
      " [0.50007695 0.50007695 0.50007695 ... 0.50007695 0.50007695 0.50007695]\n",
      " [0.70710677 0.70710677 0.70710677 ... 0.70710677 0.70710677 0.70710677]\n",
      " ...\n",
      " [0.70710677 0.70710677 0.70710677 ... 0.70710677 0.70710677 0.70710677]\n",
      " [0.70710677 0.70710677 0.70710677 ... 0.70710677 0.70710677 0.70710677]\n",
      " [0.50007695 0.5003077  0.500692   ... 0.519399   0.5368822  0.55513227]]\n"
     ]
    }
   ],
   "source": [
    "target_angle_JSTICK = np.arctan2(target[:,0,:], target[:,1,:]) * 180 / np.pi\n",
    "predicted_angle_JSTICK = np.arctan2(target[:,0,:], target[:,1,:]) * 180 / np.pi\n",
    "\n",
    "print(target_angle_JSTICK)\n",
    "# print(predicted_angle_JSTICK)\n",
    "\n",
    "target_radius_JSTICK = np.sqrt(target[:,0,:] ** 2 + target[:,1,:] ** 2)\n",
    "\n",
    "print(target_radius_JSTICK)\n",
    "\n",
    "\n",
    "u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.         0.         0.       ...   0.         0.         0.      ]\n",
      " [-90.       -90.       -90.       ... -90.       -90.       -90.      ]\n",
      " [  0.         0.         0.       ...   0.         0.         0.      ]\n",
      " ...\n",
      " [  0.         0.         0.       ...   0.         0.         0.      ]\n",
      " [  0.         0.         0.       ...   0.         0.         0.      ]\n",
      " [-90.       -90.       -90.       ... -67.696396 -66.54903  -65.163086]]\n",
      "[[  46.75091    44.634445   43.041008 ...  134.63177    44.79178\n",
      "    43.52984 ]\n",
      " [ -72.92611   -73.356094  -72.935234 ... -107.390396 -110.156105\n",
      "  -123.9908  ]\n",
      " [ 128.86421  -135.56233   -44.74625  ... -132.60854  -133.23145\n",
      "   -49.92035 ]\n",
      " ...\n",
      " [  43.728924   43.827778   42.189346 ...  134.67223    44.8963\n",
      "    44.178852]\n",
      " [  44.631542  -44.552494 -134.91252  ...  134.1983    134.31468\n",
      "  -134.28758 ]\n",
      " [ -65.21549   -65.757545  -65.0967   ...  -67.00291   -62.56648\n",
      "   -59.472424]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_no_transform = target[:, :4, :] - .5\n",
    "target_no_transform[0:4, :] /= 1.40350877193 / 2\n",
    "target_no_transform -= .2875 * (target_no_transform[:, 0:4, :] < 0)\n",
    "target_no_transform += .2875 * (target_no_transform[:, 0:4, :] > 0)\n",
    "\n",
    " \n",
    "predicted_no_transform = pred[:, :4, :] - .5\n",
    "predicted_no_transform[0:4, :] /= 1.40350877193 / 2\n",
    "predicted_no_transform -= .2875 * (predicted_no_transform[:, 0:4, :] < 0)\n",
    "predicted_no_transform += .2875 * (predicted_no_transform[:, 0:4, :] > 0)\n",
    "\n",
    "target_angle_JSTICK = np.arctan2(target_no_transform[:,0,:], target_no_transform[:,1,:]) * 180 / np.pi\n",
    "predicted_angle_JSTICK = np.arctan2(predicted_no_transform[:,0,:], predicted_no_transform[:,1,:]) * 180 / np.pi\n",
    "\n",
    "target_radius_JSTICK = np.sqrt(target_no_transform[:,0,:] ** 2 + target_no_transform[:,1,:] ** 2)\n",
    "pred_radius_JSTICK = np.sqrt(predicted_no_transform[:,0,:] ** 2 + predicted_no_transform[:,1,:] ** 2)\n",
    "\n",
    "# print(target_no_transform[:,0,:])\n",
    "# # print(target_no_transform[:,1,:])\n",
    "# print()\n",
    "\n",
    "# print(predicted_no_transform[:,0,:])\n",
    "# # print(predicted_no_transform[:,1,:])\n",
    "# print()\n",
    "\n",
    "print(target_angle_JSTICK)\n",
    "print(predicted_angle_JSTICK)\n",
    "print()\n",
    "\n",
    "# print(target_radius_JSTICK)\n",
    "# print(pred_radius_JSTICK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
