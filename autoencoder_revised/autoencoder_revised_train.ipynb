{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Autoencoder\n",
    "\n",
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "\n",
    "# We will not be training with a label.\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder_revised/../slp_package/input_dataset.py:113: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36775, 8)\n",
      "(18384, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>num_segments</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189376</th>\n",
       "      <td>ranked\\MARTH\\b9c68915-3403-4c88-aff9-79d7863f0...</td>\n",
       "      <td>11843</td>\n",
       "      <td>3</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>7200</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361954</th>\n",
       "      <td>ranked\\FOX\\c2f3f359-2737-47d8-bfce-611f8d20f04...</td>\n",
       "      <td>15361</td>\n",
       "      <td>4</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711560</th>\n",
       "      <td>public\\GANONDORF\\6edef536-a77e-49ec-be82-2af92...</td>\n",
       "      <td>9053</td>\n",
       "      <td>2</td>\n",
       "      <td>GANONDORF</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535109</th>\n",
       "      <td>public\\SHEIK\\30ec5656-97b5-4a95-aca8-785b9e328...</td>\n",
       "      <td>8532</td>\n",
       "      <td>2</td>\n",
       "      <td>SHEIK</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319026</th>\n",
       "      <td>public\\FOX\\856fac67-2d48-4e71-a647-ce2a3be201c...</td>\n",
       "      <td>7277</td>\n",
       "      <td>2</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                player_inputs_np_sub_path  length  \\\n",
       "189376  ranked\\MARTH\\b9c68915-3403-4c88-aff9-79d7863f0...   11843   \n",
       "361954  ranked\\FOX\\c2f3f359-2737-47d8-bfce-611f8d20f04...   15361   \n",
       "711560  public\\GANONDORF\\6edef536-a77e-49ec-be82-2af92...    9053   \n",
       "535109  public\\SHEIK\\30ec5656-97b5-4a95-aca8-785b9e328...    8532   \n",
       "319026  public\\FOX\\856fac67-2d48-4e71-a647-ce2a3be201c...    7277   \n",
       "\n",
       "        num_segments     labels  encoded_labels  segment_index  \\\n",
       "189376             3      MARTH              14              2   \n",
       "361954             4        FOX               5              0   \n",
       "711560             2  GANONDORF               7              1   \n",
       "535109             2      SHEIK              22              0   \n",
       "319026             2        FOX               5              1   \n",
       "\n",
       "        segment_start_index  segment_length  \n",
       "189376                 7200            3600  \n",
       "361954                    0            3600  \n",
       "711560                 3600            3600  \n",
       "535109                    0            3600  \n",
       "319026                 3600            3600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_length = 3600\n",
    "shift = 800\n",
    "\n",
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(segment_length, proportion_of_segments=1, test_ratio = .20, val = False)\n",
    "porportion = .05\n",
    "train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "porportion = .1\n",
    "test_df = test_df.sample(frac=porportion, random_state = 42)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading and optionally transforming game segments from compressed NumPy files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must include the following columns:\n",
    "          - 'player_inputs_np_sub_path': file paths to the compressed NumPy files\n",
    "          - 'encoded_labels': integer-encoded labels\n",
    "          - 'segment_start_index': start index for each segment\n",
    "          - 'segment_length': length of each segment in frames\n",
    "    transform : bool, default=False\n",
    "        If True, applies a specific transformation to each loaded segment (e.g., scaling analog inputs).\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=False):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "        # Optional: you can store a shape attribute to document the shape \n",
    "        # of data that __getitem__ will return. \n",
    "        # We'll initialize it to None and fill it when the first item is fetched.\n",
    "        self.sample_shape = None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the sample (and possibly label) from the dataset at index 'idx'.\n",
    "\n",
    "        In this custom dataset:\n",
    "          1. We open the compressed file corresponding to self.file_paths[idx].\n",
    "          2. We slice out the segment using self.segment_start_index[idx] and\n",
    "             self.segment_length[idx].\n",
    "          3. If transform=True, we apply additional transformations (shifting, scaling, etc.).\n",
    "          4. We return a PyTorch tensor containing the processed segment.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            Index of the sample to be fetched.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A tensor representing the selected segment, after optional transformations.\n",
    "        \"\"\"\n",
    "        # Load the uncompressed file\n",
    "        file_path = self.file_paths[idx].replace('\\\\', '/')\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + file_path, 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "        # Determine slice boundaries\n",
    "        start = int(self.segment_start_index[idx])\n",
    "        end = start + int(self.segment_length[idx])\n",
    "\n",
    "        # Extract the segment\n",
    "        segment = segment[:, start:end]\n",
    "\n",
    "        # Apply transformations if requested\n",
    "        if self.transform:\n",
    "            # Example transformation: shape = (9+4, 3600) for some reason\n",
    "            transformed = np.zeros((9 + 4, int(self.segment_length[idx])))\n",
    "\n",
    "            # 1) Shift and scale analog inputs to [0, 1]\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            analog_transformed *= 0.5 / 0.725\n",
    "            analog_transformed += 0.5\n",
    "            transformed[0:4] = analog_transformed\n",
    "\n",
    "            # 2) Mark positions where analog inputs are zero\n",
    "            transformed[4:8] += (segment[:4] == 0)\n",
    "\n",
    "            # # Possible additional transformations:\n",
    "            # # 3) Some custom “transition” measure on last 5 rows\n",
    "            # prepend = np.expand_dims(segment[-5:, 0], axis=1)\n",
    "            # transitions = np.abs(np.diff(segment[-5:], axis=1, prepend=prepend))\n",
    "            # transformed[8:13] += transitions\n",
    "\n",
    "            # 4) Add button inputs\n",
    "            transformed[-5:] += segment[-5:]\n",
    "\n",
    "        else:\n",
    "            # If not transforming, produce something simpler (9 x 60)\n",
    "            transformed = np.zeros((9, int(self.segment_length[idx])))\n",
    "\n",
    "            # 1) Shift and scale analog inputs to [0, 1]\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            analog_transformed *= 0.5 / 0.725\n",
    "            analog_transformed += 0.5\n",
    "            transformed[0:4] = analog_transformed\n",
    "\n",
    "            # 2) Transform the Trigger to 0/1\n",
    "            transformed[-5] += (segment[-5] > 0.5)\n",
    "\n",
    "            # 3) The last 4 rows become button inputs\n",
    "            transformed[-4:] += segment[-4:]\n",
    "\n",
    "        # Convert to PyTorch tensor\n",
    "        segment_tensor = torch.from_numpy(transformed).float()\n",
    "\n",
    "        # Optionally store the shape of the output the first time __getitem__ is called\n",
    "        if self.sample_shape is None:\n",
    "            self.sample_shape = segment_tensor.shape\n",
    "\n",
    "        return segment_tensor\n",
    "\n",
    "\n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers,  transform = True):\n",
    "    \"\"\"\n",
    "    Creates DataLoader objects for training and testing sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pd.DataFrame\n",
    "    test_df : pd.DataFrame\n",
    "    batch_size : int\n",
    "    num_workers : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict of DataLoader\n",
    "        'train' -> training DataLoader\n",
    "        'test' -> testing DataLoader\n",
    "    \"\"\"\n",
    "    train_dataset = TrainingDataset(train_df, transform=transform)\n",
    "    test_dataset = TrainingDataset(test_df, transform=transform)\n",
    "\n",
    "    loaders = {\n",
    "        'train': DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=num_workers, \n",
    "            pin_memory=True,\n",
    "            persistent_workers=True\n",
    "        ),\n",
    "        'test': DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=num_workers, \n",
    "            pin_memory=True,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "    }\n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_virtual_epochs(model, criterion, optimizer, loaders, device, channels, segment_length, num_epochs=1, bce_scale=100):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=15, factor=0.1)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    vepoch_total = 0\n",
    "    vepoch_loss_sum = 0\n",
    "    best_vepoch_loss = float('inf')\n",
    "    early_stopping_patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        virtual_epoch_start_time = time.time()\n",
    "\n",
    "        # Initialize variables for tracking gradient and parameter stats\n",
    "        grad_max = float('-inf')\n",
    "        grad_min = float('inf')\n",
    "        param_max = float('-inf')\n",
    "        param_min = float('inf')\n",
    "\n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output_gpu = model(target_gpu)\n",
    "            loss = criterion(output_gpu, target_gpu) / (channels * segment_length * target_cpu.size(0))\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            # Track max and min of gradients\n",
    "            batch_grad_max = max((p.grad.max().item() for p in model.parameters() if p.grad is not None), default=grad_max)\n",
    "            batch_grad_min = min((p.grad.min().item() for p in model.parameters() if p.grad is not None), default=grad_min)\n",
    "            grad_max = max(grad_max, batch_grad_max)\n",
    "            grad_min = min(grad_min, batch_grad_min)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            vepoch_total += target_cpu.size(0)\n",
    "            vepoch_loss_sum += loss.item() * target_cpu.size(0)\n",
    "\n",
    "            if time.time() - virtual_epoch_start_time > 60:\n",
    "                vepoch_loss = vepoch_loss_sum / vepoch_total\n",
    "                if best_vepoch_loss > vepoch_loss:\n",
    "                    best_vepoch_loss = vepoch_loss\n",
    "                else:\n",
    "                    early_stopping_patience += 1\n",
    "\n",
    "                # Calculate max and min of model parameters at the end of the virtual epoch\n",
    "                param_max = max(p.data.max().item() for p in model.parameters())\n",
    "                param_min = min(p.data.min().item() for p in model.parameters())\n",
    "\n",
    "                train_loader_tqdm.set_postfix(\n",
    "                    Best=f'{best_vepoch_loss * bce_scale:.10f}',\n",
    "                    Vepoch=f'{vepoch_loss * bce_scale:.10f}',\n",
    "                    patience=early_stopping_patience,\n",
    "                    Grad_Max=grad_max,\n",
    "                    Grad_Min=grad_min,\n",
    "                    Param_Max=param_max,\n",
    "                    Param_Min=param_min\n",
    "                )\n",
    "                # print('Grad Max:', grad_max, ' Grad Min:', grad_min)\n",
    "                virtual_epoch_start_time = time.time()\n",
    "                vepoch_total = 0\n",
    "                vepoch_loss_sum = 0\n",
    "                grad_max = float('-inf')  # Reset for next virtual epoch\n",
    "                grad_min = float('inf')   # Reset for next virtual epoch\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def predict(model, loaders, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit='batch')\n",
    "        \n",
    "        for _, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            # output_gpu = torch.sigmoid(output_gpu)\n",
    "            \n",
    "            predictions.append(torch.sigmoid(output_gpu).cpu().numpy())\n",
    "            targets.append(target_cpu.numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    return predictions, targets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, bce_scale=100, transform=False, weighted=False, channels=13, segment_length=3600):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "        # Fraction of times each button is pressed in your sample\n",
    "        buttons_sample_mean = [\n",
    "            0.16908772957310006,  # TRIGGER_LOGICAL\n",
    "            0.008974353071937505, # Z\n",
    "            0.060945588829374495, # A\n",
    "            0.04591526858731047,  # B\n",
    "            0.09663690337362206   # X_or_Y\n",
    "        ]\n",
    "        # If transform == True, you also have additional ones for jstick/cstick?\n",
    "        trigger_logical_sample_mean = [\n",
    "            0.45849791926398437,  # JSTICK_X_LOGICAL\n",
    "            0.6879025510132348,   # JSTICK_Y_LOGICAL\n",
    "            0.9726537459234259,   # CSTICK_X_LOGICAL\n",
    "            0.971675825912117     # CSTICK_Y_LOGICAL\n",
    "        ]\n",
    "\n",
    "        # Create pos_weight or bce_weights depending on your logic\n",
    "        if transform:\n",
    "            # Merge your two sets if needed\n",
    "            sample_means = trigger_logical_sample_mean + buttons_sample_mean\n",
    "        else:\n",
    "            sample_means = buttons_sample_mean\n",
    "\n",
    "        # pos_weight for each dimension: (1 - p) / p\n",
    "        pos_weight_vals = np.zeros((channels, segment_length))\n",
    "        for i, mean in enumerate(sample_means):\n",
    "            p_pos = mean\n",
    "            p_neg = 1.0 - mean\n",
    "            \n",
    "            pos_weight_vals[i,:] += p_neg / p_pos\n",
    "        pos_weight_tensor = torch.tensor(pos_weight_vals, dtype=torch.float, device='cuda')\n",
    "\n",
    "        if weighted:\n",
    "            # Use pos_weight instead of 'weight'\n",
    "            self.BCE = nn.BCEWithLogitsLoss(reduction='sum', pos_weight=pos_weight_tensor)\n",
    "        else:\n",
    "            self.BCE = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "        # Save the other components\n",
    "        self.bce_scale = bce_scale\n",
    "        self.MSE = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred, target shape: (B, Channels, T)\n",
    "        We'll assume:\n",
    "          - pred[:, 0:4, :] are analog predictions (MSE)\n",
    "          - pred[:, 4:, :] are button predictions (BCE)\n",
    "        \"\"\"\n",
    "        # 1) MSE for first 4 analog channels\n",
    "        mse_loss = self.MSE(torch.sigmoid(pred[:, 0:4, :]), target[:, 0:4, :]) \n",
    "        # 2) BCE for the rest\n",
    "        bce_loss = self.BCE(pred[:, 4:, :], target[:, 4:, :])\n",
    "\n",
    "        # Scale & return combined\n",
    "        return mse_loss + bce_loss / self.bce_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 3600]             896\n",
      "       BatchNorm1d-2             [-1, 64, 3600]             128\n",
      "              ReLU-3             [-1, 64, 3600]               0\n",
      "            Conv1d-4             [-1, 64, 3600]          12,352\n",
      "       BatchNorm1d-5             [-1, 64, 3600]             128\n",
      "              ReLU-6             [-1, 64, 3600]               0\n",
      "            Conv1d-7            [-1, 256, 3600]          16,640\n",
      "       BatchNorm1d-8            [-1, 256, 3600]             512\n",
      "            Conv1d-9            [-1, 256, 3600]           3,584\n",
      "      BatchNorm1d-10            [-1, 256, 3600]             512\n",
      "             ReLU-11            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-12            [-1, 256, 3600]               0\n",
      "           Conv1d-13             [-1, 64, 3600]          16,448\n",
      "      BatchNorm1d-14             [-1, 64, 3600]             128\n",
      "             ReLU-15             [-1, 64, 3600]               0\n",
      "           Conv1d-16             [-1, 64, 3600]          12,352\n",
      "      BatchNorm1d-17             [-1, 64, 3600]             128\n",
      "             ReLU-18             [-1, 64, 3600]               0\n",
      "           Conv1d-19            [-1, 256, 3600]          16,640\n",
      "      BatchNorm1d-20            [-1, 256, 3600]             512\n",
      "             ReLU-21            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-22            [-1, 256, 3600]               0\n",
      "           Conv1d-23             [-1, 64, 3600]          16,448\n",
      "      BatchNorm1d-24             [-1, 64, 3600]             128\n",
      "             ReLU-25             [-1, 64, 3600]               0\n",
      "           Conv1d-26             [-1, 64, 3600]          12,352\n",
      "      BatchNorm1d-27             [-1, 64, 3600]             128\n",
      "             ReLU-28             [-1, 64, 3600]               0\n",
      "           Conv1d-29            [-1, 256, 3600]          16,640\n",
      "      BatchNorm1d-30            [-1, 256, 3600]             512\n",
      "             ReLU-31            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-32            [-1, 256, 3600]               0\n",
      "           Conv1d-33            [-1, 128, 3600]          32,896\n",
      "      BatchNorm1d-34            [-1, 128, 3600]             256\n",
      "             ReLU-35            [-1, 128, 3600]               0\n",
      "           Conv1d-36            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-37            [-1, 128, 1800]             256\n",
      "             ReLU-38            [-1, 128, 1800]               0\n",
      "           Conv1d-39            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-40            [-1, 512, 1800]           1,024\n",
      "           Conv1d-41            [-1, 512, 1800]         131,584\n",
      "      BatchNorm1d-42            [-1, 512, 1800]           1,024\n",
      "             ReLU-43            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-44            [-1, 512, 1800]               0\n",
      "           Conv1d-45            [-1, 128, 1800]          65,664\n",
      "      BatchNorm1d-46            [-1, 128, 1800]             256\n",
      "             ReLU-47            [-1, 128, 1800]               0\n",
      "           Conv1d-48            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-49            [-1, 128, 1800]             256\n",
      "             ReLU-50            [-1, 128, 1800]               0\n",
      "           Conv1d-51            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-52            [-1, 512, 1800]           1,024\n",
      "             ReLU-53            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-54            [-1, 512, 1800]               0\n",
      "           Conv1d-55            [-1, 128, 1800]          65,664\n",
      "      BatchNorm1d-56            [-1, 128, 1800]             256\n",
      "             ReLU-57            [-1, 128, 1800]               0\n",
      "           Conv1d-58            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-59            [-1, 128, 1800]             256\n",
      "             ReLU-60            [-1, 128, 1800]               0\n",
      "           Conv1d-61            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-62            [-1, 512, 1800]           1,024\n",
      "             ReLU-63            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-64            [-1, 512, 1800]               0\n",
      "           Conv1d-65            [-1, 128, 1800]          65,664\n",
      "      BatchNorm1d-66            [-1, 128, 1800]             256\n",
      "             ReLU-67            [-1, 128, 1800]               0\n",
      "           Conv1d-68            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-69            [-1, 128, 1800]             256\n",
      "             ReLU-70            [-1, 128, 1800]               0\n",
      "           Conv1d-71            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-72            [-1, 512, 1800]           1,024\n",
      "             ReLU-73            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-74            [-1, 512, 1800]               0\n",
      "           Conv1d-75            [-1, 256, 1800]         131,328\n",
      "      BatchNorm1d-76            [-1, 256, 1800]             512\n",
      "             ReLU-77            [-1, 256, 1800]               0\n",
      "           Conv1d-78             [-1, 256, 900]         196,864\n",
      "      BatchNorm1d-79             [-1, 256, 900]             512\n",
      "             ReLU-80             [-1, 256, 900]               0\n",
      "           Conv1d-81            [-1, 1024, 900]         263,168\n",
      "      BatchNorm1d-82            [-1, 1024, 900]           2,048\n",
      "           Conv1d-83            [-1, 1024, 900]         525,312\n",
      "      BatchNorm1d-84            [-1, 1024, 900]           2,048\n",
      "             ReLU-85            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-86            [-1, 1024, 900]               0\n",
      "           Conv1d-87             [-1, 256, 900]         262,400\n",
      "      BatchNorm1d-88             [-1, 256, 900]             512\n",
      "             ReLU-89             [-1, 256, 900]               0\n",
      "           Conv1d-90             [-1, 256, 900]         196,864\n",
      "      BatchNorm1d-91             [-1, 256, 900]             512\n",
      "             ReLU-92             [-1, 256, 900]               0\n",
      "           Conv1d-93            [-1, 1024, 900]         263,168\n",
      "      BatchNorm1d-94            [-1, 1024, 900]           2,048\n",
      "             ReLU-95            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-96            [-1, 1024, 900]               0\n",
      "           Conv1d-97             [-1, 256, 900]         262,400\n",
      "      BatchNorm1d-98             [-1, 256, 900]             512\n",
      "             ReLU-99             [-1, 256, 900]               0\n",
      "          Conv1d-100             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-101             [-1, 256, 900]             512\n",
      "            ReLU-102             [-1, 256, 900]               0\n",
      "          Conv1d-103            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-104            [-1, 1024, 900]           2,048\n",
      "            ReLU-105            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-106            [-1, 1024, 900]               0\n",
      "          Conv1d-107             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-108             [-1, 256, 900]             512\n",
      "            ReLU-109             [-1, 256, 900]               0\n",
      "          Conv1d-110             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-111             [-1, 256, 900]             512\n",
      "            ReLU-112             [-1, 256, 900]               0\n",
      "          Conv1d-113            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-114            [-1, 1024, 900]           2,048\n",
      "            ReLU-115            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-116            [-1, 1024, 900]               0\n",
      "          Conv1d-117             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-118             [-1, 256, 900]             512\n",
      "            ReLU-119             [-1, 256, 900]               0\n",
      "          Conv1d-120             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-121             [-1, 256, 900]             512\n",
      "            ReLU-122             [-1, 256, 900]               0\n",
      "          Conv1d-123            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-124            [-1, 1024, 900]           2,048\n",
      "            ReLU-125            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-126            [-1, 1024, 900]               0\n",
      "          Conv1d-127             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-128             [-1, 256, 900]             512\n",
      "            ReLU-129             [-1, 256, 900]               0\n",
      "          Conv1d-130             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-131             [-1, 256, 900]             512\n",
      "            ReLU-132             [-1, 256, 900]               0\n",
      "          Conv1d-133            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-134            [-1, 1024, 900]           2,048\n",
      "            ReLU-135            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-136            [-1, 1024, 900]               0\n",
      "          Conv1d-137             [-1, 512, 900]         524,800\n",
      "     BatchNorm1d-138             [-1, 512, 900]           1,024\n",
      "            ReLU-139             [-1, 512, 900]               0\n",
      "          Conv1d-140             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-141             [-1, 512, 450]           1,024\n",
      "            ReLU-142             [-1, 512, 450]               0\n",
      "          Conv1d-143            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-144            [-1, 2048, 450]           4,096\n",
      "          Conv1d-145            [-1, 2048, 450]       2,099,200\n",
      "     BatchNorm1d-146            [-1, 2048, 450]           4,096\n",
      "            ReLU-147            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-148            [-1, 2048, 450]               0\n",
      "          Conv1d-149             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-150             [-1, 512, 450]           1,024\n",
      "            ReLU-151             [-1, 512, 450]               0\n",
      "          Conv1d-152             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-153             [-1, 512, 450]           1,024\n",
      "            ReLU-154             [-1, 512, 450]               0\n",
      "          Conv1d-155            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-156            [-1, 2048, 450]           4,096\n",
      "            ReLU-157            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-158            [-1, 2048, 450]               0\n",
      "          Conv1d-159             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-160             [-1, 512, 450]           1,024\n",
      "            ReLU-161             [-1, 512, 450]               0\n",
      "          Conv1d-162             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-163             [-1, 512, 450]           1,024\n",
      "            ReLU-164             [-1, 512, 450]               0\n",
      "          Conv1d-165            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-166            [-1, 2048, 450]           4,096\n",
      "            ReLU-167            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-168            [-1, 2048, 450]               0\n",
      "          Conv1d-169              [-1, 15, 225]          92,175\n",
      "     BatchNorm1d-170              [-1, 15, 225]              30\n",
      "            ReLU-171              [-1, 15, 225]               0\n",
      "          Linear-172                 [-1, 2048]       6,914,048\n",
      "            ReLU-173                 [-1, 2048]               0\n",
      "     BatchNorm1d-174                 [-1, 2048]           4,096\n",
      "         Encoder-175                 [-1, 2048]               0\n",
      "          Linear-176                 [-1, 3375]       6,915,375\n",
      "            ReLU-177                 [-1, 3375]               0\n",
      "     BatchNorm1d-178                 [-1, 3375]           6,750\n",
      " ConvTranspose1d-179            [-1, 2048, 450]          94,208\n",
      "     BatchNorm1d-180            [-1, 2048, 450]           4,096\n",
      "            ReLU-181            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-182             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-183             [-1, 512, 450]           1,024\n",
      "            ReLU-184             [-1, 512, 450]               0\n",
      " ConvTranspose1d-185             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-186             [-1, 512, 450]           1,024\n",
      "            ReLU-187             [-1, 512, 450]               0\n",
      " ConvTranspose1d-188            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-189            [-1, 2048, 450]           4,096\n",
      "            ReLU-190            [-1, 2048, 450]               0\n",
      "Decoder_Bottleneck-191            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-192             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-193             [-1, 512, 450]           1,024\n",
      "            ReLU-194             [-1, 512, 450]               0\n",
      " ConvTranspose1d-195             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-196             [-1, 512, 450]           1,024\n",
      "            ReLU-197             [-1, 512, 450]               0\n",
      " ConvTranspose1d-198            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-199            [-1, 2048, 450]           4,096\n",
      "            ReLU-200            [-1, 2048, 450]               0\n",
      "Decoder_Bottleneck-201            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-202             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-203             [-1, 512, 450]           1,024\n",
      "            ReLU-204             [-1, 512, 450]               0\n",
      " ConvTranspose1d-205             [-1, 512, 900]         786,944\n",
      "     BatchNorm1d-206             [-1, 512, 900]           1,024\n",
      "            ReLU-207             [-1, 512, 900]               0\n",
      " ConvTranspose1d-208            [-1, 1024, 900]         525,312\n",
      "     BatchNorm1d-209            [-1, 1024, 900]           2,048\n",
      "        Upsample-210            [-1, 2048, 900]               0\n",
      " ConvTranspose1d-211            [-1, 1024, 900]       2,098,176\n",
      "     BatchNorm1d-212            [-1, 1024, 900]           2,048\n",
      "            ReLU-213            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-214            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-215             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-216             [-1, 256, 900]             512\n",
      "            ReLU-217             [-1, 256, 900]               0\n",
      " ConvTranspose1d-218             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-219             [-1, 256, 900]             512\n",
      "            ReLU-220             [-1, 256, 900]               0\n",
      " ConvTranspose1d-221            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-222            [-1, 1024, 900]           2,048\n",
      "            ReLU-223            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-224            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-225             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-226             [-1, 256, 900]             512\n",
      "            ReLU-227             [-1, 256, 900]               0\n",
      " ConvTranspose1d-228             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-229             [-1, 256, 900]             512\n",
      "            ReLU-230             [-1, 256, 900]               0\n",
      " ConvTranspose1d-231            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-232            [-1, 1024, 900]           2,048\n",
      "            ReLU-233            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-234            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-235             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-236             [-1, 256, 900]             512\n",
      "            ReLU-237             [-1, 256, 900]               0\n",
      " ConvTranspose1d-238             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-239             [-1, 256, 900]             512\n",
      "            ReLU-240             [-1, 256, 900]               0\n",
      " ConvTranspose1d-241            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-242            [-1, 1024, 900]           2,048\n",
      "            ReLU-243            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-244            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-245             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-246             [-1, 256, 900]             512\n",
      "            ReLU-247             [-1, 256, 900]               0\n",
      " ConvTranspose1d-248             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-249             [-1, 256, 900]             512\n",
      "            ReLU-250             [-1, 256, 900]               0\n",
      " ConvTranspose1d-251            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-252            [-1, 1024, 900]           2,048\n",
      "            ReLU-253            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-254            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-255             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-256             [-1, 256, 900]             512\n",
      "            ReLU-257             [-1, 256, 900]               0\n",
      " ConvTranspose1d-258             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-259             [-1, 256, 900]             512\n",
      "            ReLU-260             [-1, 256, 900]               0\n",
      " ConvTranspose1d-261            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-262            [-1, 1024, 900]           2,048\n",
      "            ReLU-263            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-264            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-265             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-266             [-1, 256, 900]             512\n",
      "            ReLU-267             [-1, 256, 900]               0\n",
      " ConvTranspose1d-268            [-1, 256, 1800]         196,864\n",
      "     BatchNorm1d-269            [-1, 256, 1800]             512\n",
      "            ReLU-270            [-1, 256, 1800]               0\n",
      " ConvTranspose1d-271            [-1, 512, 1800]         131,584\n",
      "     BatchNorm1d-272            [-1, 512, 1800]           1,024\n",
      "        Upsample-273           [-1, 1024, 1800]               0\n",
      " ConvTranspose1d-274            [-1, 512, 1800]         524,800\n",
      "     BatchNorm1d-275            [-1, 512, 1800]           1,024\n",
      "            ReLU-276            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-277            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-278            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-279            [-1, 128, 1800]             256\n",
      "            ReLU-280            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-281            [-1, 128, 1800]          49,280\n",
      "     BatchNorm1d-282            [-1, 128, 1800]             256\n",
      "            ReLU-283            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-284            [-1, 512, 1800]          66,048\n",
      "     BatchNorm1d-285            [-1, 512, 1800]           1,024\n",
      "            ReLU-286            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-287            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-288            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-289            [-1, 128, 1800]             256\n",
      "            ReLU-290            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-291            [-1, 128, 1800]          49,280\n",
      "     BatchNorm1d-292            [-1, 128, 1800]             256\n",
      "            ReLU-293            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-294            [-1, 512, 1800]          66,048\n",
      "     BatchNorm1d-295            [-1, 512, 1800]           1,024\n",
      "            ReLU-296            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-297            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-298            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-299            [-1, 128, 1800]             256\n",
      "            ReLU-300            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-301            [-1, 128, 1800]          49,280\n",
      "     BatchNorm1d-302            [-1, 128, 1800]             256\n",
      "            ReLU-303            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-304            [-1, 512, 1800]          66,048\n",
      "     BatchNorm1d-305            [-1, 512, 1800]           1,024\n",
      "            ReLU-306            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-307            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-308            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-309            [-1, 128, 1800]             256\n",
      "            ReLU-310            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-311            [-1, 128, 3600]          49,280\n",
      "     BatchNorm1d-312            [-1, 128, 3600]             256\n",
      "            ReLU-313            [-1, 128, 3600]               0\n",
      " ConvTranspose1d-314            [-1, 256, 3600]          33,024\n",
      "     BatchNorm1d-315            [-1, 256, 3600]             512\n",
      "        Upsample-316            [-1, 512, 3600]               0\n",
      " ConvTranspose1d-317            [-1, 256, 3600]         131,328\n",
      "     BatchNorm1d-318            [-1, 256, 3600]             512\n",
      "            ReLU-319            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-320            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-321             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-322             [-1, 64, 3600]             128\n",
      "            ReLU-323             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-324             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-325             [-1, 64, 3600]             128\n",
      "            ReLU-326             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-327            [-1, 256, 3600]          16,640\n",
      "     BatchNorm1d-328            [-1, 256, 3600]             512\n",
      "            ReLU-329            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-330            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-331             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-332             [-1, 64, 3600]             128\n",
      "            ReLU-333             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-334             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-335             [-1, 64, 3600]             128\n",
      "            ReLU-336             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-337            [-1, 256, 3600]          16,640\n",
      "     BatchNorm1d-338            [-1, 256, 3600]             512\n",
      "            ReLU-339            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-340            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-341             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-342             [-1, 64, 3600]             128\n",
      "            ReLU-343             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-344             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-345             [-1, 64, 3600]             128\n",
      "            ReLU-346             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-347             [-1, 13, 3600]             845\n",
      "         Decoder-348             [-1, 13, 3600]               0\n",
      "================================================================\n",
      "Total params: 45,942,855\n",
      "Trainable params: 45,942,855\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.18\n",
      "Forward/backward pass size (MB): 1403.67\n",
      "Params size (MB): 175.26\n",
      "Estimated Total Size (MB): 1579.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# trasform = True adds binary features corresponding to when the analog inputs are 0.\n",
    "transform = True\n",
    "# bce_scale is a tunable parameter that scales the binary cross-entropy loss.\n",
    "bce_scale = 1\n",
    "# weighted = True weights the loss function to account for the imbalance of the button being pressed.\n",
    "weighted = False\n",
    "\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size=16, num_workers=20,  transform=transform)\n",
    "# Grab one item (segment tensor) from the train dataset\n",
    "train_dataset = loaders['train'].dataset\n",
    "first_item = train_dataset[0]\n",
    "channels = first_item.size(0)\n",
    "print(channels)\n",
    "\n",
    "from Convolutional_Autoencoder_Model import ResNet_Autoencoder\n",
    "# Initialize the model\n",
    "model = ResNet_Autoencoder(channels)\n",
    "model = model.cuda()\n",
    "\n",
    "# With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(channels, segment_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 2299/2299 [05:45<00:00,  6.65batch/s, Best=0.2180233898, Grad_Max=0.0395, Grad_Min=-0.0399, Param_Max=1.14, Param_Min=-0.39, Vepoch=0.2180233898, patience=0]\n"
     ]
    }
   ],
   "source": [
    "criterion = CustomLoss(bce_scale=bce_scale, transform=transform, weighted=weighted)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "# This seems to sometimes help\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "\n",
    "# start_time = time.time()\n",
    "# train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', channels, segment_length, num_epochs, bce_scale=bce_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'autoencoder_revised_short_test_train_4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1149/1149 [00:57<00:00, 19.96batch/s]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pred, target = predict(model, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>How Close</th>\n",
       "      <th>JSTICK_X</th>\n",
       "      <th>JSTICK_Y</th>\n",
       "      <th>CSTICK_X</th>\n",
       "      <th>CSTICK_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9.586688</td>\n",
       "      <td>2.219871</td>\n",
       "      <td>24.697799</td>\n",
       "      <td>41.902476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>27.239586</td>\n",
       "      <td>7.346814</td>\n",
       "      <td>77.243435</td>\n",
       "      <td>82.990942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>41.318648</td>\n",
       "      <td>14.342485</td>\n",
       "      <td>92.266912</td>\n",
       "      <td>91.545580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>46.013402</td>\n",
       "      <td>22.056547</td>\n",
       "      <td>94.508448</td>\n",
       "      <td>94.399924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>46.506626</td>\n",
       "      <td>29.850058</td>\n",
       "      <td>95.718324</td>\n",
       "      <td>95.509877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>46.846545</td>\n",
       "      <td>38.519735</td>\n",
       "      <td>96.373572</td>\n",
       "      <td>96.141131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>47.138321</td>\n",
       "      <td>49.776008</td>\n",
       "      <td>96.715464</td>\n",
       "      <td>96.500201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>47.404937</td>\n",
       "      <td>63.883857</td>\n",
       "      <td>96.898568</td>\n",
       "      <td>96.716267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>47.653075</td>\n",
       "      <td>70.703589</td>\n",
       "      <td>97.001636</td>\n",
       "      <td>96.865142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>47.889644</td>\n",
       "      <td>72.398482</td>\n",
       "      <td>97.073359</td>\n",
       "      <td>96.977118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   How Close   JSTICK_X   JSTICK_Y   CSTICK_X   CSTICK_Y\n",
       "0          0   9.586688   2.219871  24.697799  41.902476\n",
       "1          1  27.239586   7.346814  77.243435  82.990942\n",
       "2          2  41.318648  14.342485  92.266912  91.545580\n",
       "3          3  46.013402  22.056547  94.508448  94.399924\n",
       "4          4  46.506626  29.850058  95.718324  95.509877\n",
       "5          5  46.846545  38.519735  96.373572  96.141131\n",
       "6          6  47.138321  49.776008  96.715464  96.500201\n",
       "7          7  47.404937  63.883857  96.898568  96.716267\n",
       "8          8  47.653075  70.703589  97.001636  96.865142\n",
       "9          9  47.889644  72.398482  97.073359  96.977118"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_stick_targets = np.round(target[:,0:4] / 0.008620689655172415 ).astype(np.int32)\n",
    "integer_stick_pred = np.round(pred[:,0:4] / 0.008620689655172415).astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "n = 10\n",
    "\n",
    "buttons = ['JSTICK_X', 'JSTICK_Y', 'CSTICK_X', 'CSTICK_Y']\n",
    "# buttons = ['X_or_Y']\n",
    "\n",
    "\n",
    "stick_accuracy_df = pd.DataFrame(np.arange(n,dtype=np.int16),columns=['How Close'])\n",
    "# print(summary_df)\n",
    "\n",
    "\n",
    "for j in range(4):\n",
    "    unique, counts = np.unique(integer_stick_pred[:,j] - integer_stick_targets[:,j], return_counts=True)\n",
    "    data = []\n",
    "    num = np.sum(counts)\n",
    "    for i in range(n):\n",
    "        mask = np.abs(unique) <= i\n",
    "        data += [np.sum(counts[mask]) / num * 100]\n",
    "    stick_accuracy_df[buttons[j]] = data\n",
    "        \n",
    "stick_accuracy_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95.70332747074751, 97.8092906875544, 99.72092127212069, 99.51466401943719]\n"
     ]
    }
   ],
   "source": [
    "target_stick_is_zero = (integer_stick_targets == 0)*1\n",
    "pred_stick_is_zero = (integer_stick_pred == 0)*1\n",
    "\n",
    "zero_accuracy = []\n",
    "# find the accuracy of the model when the stick is zero\n",
    "for j in range(4):\n",
    "    diff = np.abs(target_stick_is_zero[:,j] - pred_stick_is_zero[:,j])\n",
    "    data = []\n",
    "    num_correct = np.sum(diff == 0)\n",
    "    zero_accuracy.append(num_correct / np.prod(diff.shape) * 100)\n",
    "print(zero_accuracy)\n",
    "# zero_accuracy_df = pd.DataFrame(columns=buttons, data=[zero_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Button</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Acc of 0</th>\n",
       "      <th>Acc of 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRIGGER_LOGICAL</td>\n",
       "      <td>16.365003</td>\n",
       "      <td>99.999967</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z</td>\n",
       "      <td>19.814653</td>\n",
       "      <td>99.999684</td>\n",
       "      <td>0.000489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>18.745656</td>\n",
       "      <td>99.887907</td>\n",
       "      <td>1.002105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>19.120770</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_or_Y</td>\n",
       "      <td>18.013614</td>\n",
       "      <td>97.978792</td>\n",
       "      <td>17.909374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Button   Accuracy    Acc of 0   Acc of 1\n",
       "0  TRIGGER_LOGICAL  16.365003   99.999967   0.000010\n",
       "1                Z  19.814653   99.999684   0.000489\n",
       "2                A  18.745656   99.887907   1.002105\n",
       "3                B  19.120770  100.000000   0.000000\n",
       "4           X_or_Y  18.013614   97.978792  17.909374"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data setup (make sure you have your actual data in these variables)\n",
    "# target = np.random.randint(0, 2, (100, 9))  # Example target array\n",
    "# pred = np.random.random((100, 9))  # Example predictions array\n",
    "buttons = [ 'TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "\n",
    "# Initializing the DataFrame\n",
    "button_accuracy_df = pd.DataFrame(columns=['Button', 'Accuracy', 'Acc of 0', 'Acc of 1'])\n",
    "\n",
    "target_buttons = target[:, 4 + 4 * transform:]\n",
    "pred_buttons = pred[:, 4 + 4 * transform:] > 0.5\n",
    "total = np.prod(target_buttons.shape)\n",
    "\n",
    "# Computing accuracies and filling the DataFrame\n",
    "rows = []  # List to hold row data\n",
    "\n",
    "for i, button in enumerate(buttons):\n",
    "    correct_predictions = np.sum(target_buttons[:, i] == pred_buttons[:, i])\n",
    "    correct_zeros = np.sum((target_buttons[:, i] == 0) & (pred_buttons[:, i] == 0))\n",
    "    correct_ones = np.sum((target_buttons[:, i] == 1) & (pred_buttons[:, i] == 1))\n",
    "\n",
    "    accuracy = correct_predictions / total * 100\n",
    "    acc_of_0 = correct_zeros / np.sum(target_buttons[:, i] == 0) * 100 if np.sum(target_buttons[:, i] == 0) > 0 else 0\n",
    "    acc_of_1 = correct_ones / np.sum(target_buttons[:, i] == 1) * 100 if np.sum(target_buttons[:, i] == 1) > 0 else 0\n",
    "\n",
    "    rows.append({\n",
    "        'Button': button,\n",
    "        'Accuracy': accuracy,\n",
    "        'Acc of 0': acc_of_0,\n",
    "        'Acc of 1': acc_of_1\n",
    "    })\n",
    "\n",
    "# Use concat to add all new rows to the DataFrame at once\n",
    "button_accuracy_df = pd.concat([button_accuracy_df, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# Output the DataFrame\n",
    "button_accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Zero-detection Accuracy\n",
    "If you stored an extra feature or you can detect (predicted_stick < some threshold),\n",
    "measure how often the model is correct about \"stick == 0.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-detection accuracy: 54.01%\n"
     ]
    }
   ],
   "source": [
    "def zero_detection_accuracy(pred_stick, target_stick, zero_bin_threshold=0.01):\n",
    "    \"\"\"\n",
    "    pred_stick: np.ndarray of shape (N, 4, T)  # 4 analog channels\n",
    "    target_stick: same shape\n",
    "    zero_bin_threshold: float\n",
    "        If the value is within [0.5 - zero_bin_threshold, 0.5 + zero_bin_threshold],\n",
    "        we consider it \"zero.\" Or in your bin-based approach, you might define an integer\n",
    "        bin for zero and check for that.\n",
    "    \n",
    "    Returns: float accuracy (0..100) of zero detection\n",
    "    \"\"\"\n",
    "    # Suppose \"true zero\" is where target is exactly 0 in the original scale\n",
    "    # or has been transformed to 0.5 in your scale. So we do:\n",
    "    is_true_zero = np.isclose(target_stick, 0.5, atol=zero_bin_threshold)\n",
    "\n",
    "    # Similarly for predictions:\n",
    "    is_pred_zero = np.isclose(pred_stick, 0.5, atol=zero_bin_threshold)\n",
    "\n",
    "    correct = (is_true_zero == is_pred_zero).sum()\n",
    "    total = np.prod(is_true_zero.shape)\n",
    "\n",
    "    return correct / total * 100.0\n",
    "\n",
    "# Example usage:\n",
    "pred_analog = pred[:, :4, :]  # 4 analog channels\n",
    "target_analog = target[:, :4, :]\n",
    "zero_acc = zero_detection_accuracy(pred_analog, target_analog, zero_bin_threshold=0.01)\n",
    "print(f\"Zero-detection accuracy: {zero_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Count Accuracy of Button Presses\n",
    "We compare total frames of '1' the model predicts vs. ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button_0 {'gt_count': 30224142, 'pred_count': 66182400, 'count_diff': 35958258.0, 'relative_error_%': 118.97197280240408}\n",
      "button_1 {'gt_count': 45711956, 'pred_count': 66182400, 'count_diff': 20470444.0, 'relative_error_%': 44.781378420997775}\n",
      "button_2 {'gt_count': 64347744, 'pred_count': 66182400, 'count_diff': 1834656.0, 'relative_error_%': 2.8511582317477977}\n",
      "button_3 {'gt_count': 64297672, 'pred_count': 66182400, 'count_diff': 1884728.0, 'relative_error_%': 2.9312538718353593}\n",
      "button_4 {'gt_count': 11200982, 'pred_count': 66182400, 'count_diff': 54981418.0, 'relative_error_%': 490.86247973615133}\n",
      "button_5 {'gt_count': 613130, 'pred_count': 66182400, 'count_diff': 65569270.0, 'relative_error_%': 10694.187203366158}\n",
      "button_6 {'gt_count': 4122523, 'pred_count': 66182400, 'count_diff': 62059877.0, 'relative_error_%': 1505.3858280475295}\n",
      "button_7 {'gt_count': 2909479, 'pred_count': 66182400, 'count_diff': 63272921.0, 'relative_error_%': 2174.7165385967655}\n",
      "button_8 {'gt_count': 6538710, 'pred_count': 66182400, 'count_diff': 59643690.0, 'relative_error_%': 912.1629495726207}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def button_press_count_accuracy(pred_logits, target_binary, threshold=0.5):\n",
    "    \"\"\"\n",
    "    pred_logits: (N, num_buttons, T)\n",
    "    target_binary: (N, num_buttons, T)\n",
    "    Returns: list of dicts or a dict summarizing the count error\n",
    "    \"\"\"\n",
    "    pred_probs = 1 / (1 + np.exp(-pred_logits))\n",
    "    pred_bin = (pred_probs >= threshold).astype(int)\n",
    "\n",
    "    results = {}\n",
    "    num_buttons = pred_bin.shape[1]\n",
    "\n",
    "    for b in range(num_buttons):\n",
    "        # total frames of 1 in ground truth\n",
    "        gt_count = target_binary[:, b, :].sum()\n",
    "        # total frames of 1 in predictions\n",
    "        pred_count = pred_bin[:, b, :].sum()\n",
    "\n",
    "        count_diff = float(abs(gt_count - pred_count))\n",
    "        # You could measure absolute error, relative error, etc.\n",
    "        rel_error = count_diff / (gt_count + 1e-8) * 100.0  # in %\n",
    "\n",
    "        results[f'button_{b}'] = {\n",
    "            'gt_count': int(gt_count),\n",
    "            'pred_count': int(pred_count),\n",
    "            'count_diff': count_diff,\n",
    "            'relative_error_%': rel_error\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "count_results = button_press_count_accuracy(pred[:,4:,:], target[:,4:,:])\n",
    "for k,v in count_results.items():\n",
    "   print(k, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Temporal Alignment of Button Presses\n",
    "For each button, detect frames where it transitions from 0->1.\n",
    "Then check if the model's predicted onset is within +/- k frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m timing_results \u001b[38;5;241m=\u001b[39m \u001b[43monset_alignment_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m timing_results\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     63\u001b[0m    \u001b[38;5;28mprint\u001b[39m(k, v)\n",
      "Cell \u001b[0;32mIn[16], line 34\u001b[0m, in \u001b[0;36monset_alignment_score\u001b[0;34m(pred_logits, target_binary, threshold, tolerance)\u001b[0m\n\u001b[1;32m     30\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(B):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Onset indices for ground truth\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     target_onsets \u001b[38;5;241m=\u001b[39m \u001b[43monset_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_binary\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Onset indices for predictions\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     pred_onsets \u001b[38;5;241m=\u001b[39m onset_indices(pred_bin[:, b, :])\n",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m, in \u001b[0;36monset_indices\u001b[0;34m(binary_array)\u001b[0m\n\u001b[1;32m     10\u001b[0m arr \u001b[38;5;241m=\u001b[39m binary_array[i]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# shift arr by 1 to compare\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m arr_shifted \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# detect transitions\u001b[39;00m\n\u001b[1;32m     14\u001b[0m transitions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere((arr_shifted \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m&\u001b[39m (arr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def onset_indices(binary_array):\n",
    "    \"\"\"\n",
    "    binary_array: shape (N, T) in {0,1}\n",
    "    Returns: list of onset indices for each sample in the batch\n",
    "    \"\"\"\n",
    "    # We'll do it for each sample separately\n",
    "    # 0->1 means array[i, t-1] = 0, array[i,t] = 1\n",
    "    onsets = []\n",
    "    for i in range(binary_array.shape[0]):\n",
    "        arr = binary_array[i]\n",
    "        # shift arr by 1 to compare\n",
    "        arr_shifted = np.pad(arr[:-1], (1,0), 'constant', constant_values=0)\n",
    "        # detect transitions\n",
    "        transitions = np.where((arr_shifted == 0) & (arr == 1))[0]\n",
    "        onsets.append(transitions)\n",
    "    return onsets\n",
    "\n",
    "def onset_alignment_score(pred_logits, target_binary, threshold=0.5, tolerance=3):\n",
    "    \"\"\"\n",
    "    For each 0->1 transition in target, check if there's a predicted onset\n",
    "    within +/- tolerance frames.\n",
    "    Return fraction of onsets matched.\n",
    "    \"\"\"\n",
    "    pred_probs = 1 / (1 + np.exp(-pred_logits))\n",
    "    pred_bin = (pred_probs >= threshold).astype(int)\n",
    "\n",
    "    # We'll flatten batch dimension, or handle sample by sample\n",
    "    # Suppose shape is (N, 1, T) for a single button or do it for each button separately.\n",
    "    N, B, T = pred_bin.shape\n",
    "    results = {}\n",
    "\n",
    "    for b in range(B):\n",
    "        # Onset indices for ground truth\n",
    "        target_onsets = onset_indices(target_binary[:, b, :])\n",
    "        # Onset indices for predictions\n",
    "        pred_onsets = onset_indices(pred_bin[:, b, :])\n",
    "\n",
    "        total_onsets = 0\n",
    "        matched_onsets = 0\n",
    "\n",
    "        for i in range(N):\n",
    "            tg = target_onsets[i]\n",
    "            pd = pred_onsets[i]\n",
    "\n",
    "            total_onsets += len(tg)\n",
    "            # For each truth onset, see if there's a predicted onset within +/- tolerance\n",
    "            for t_onset in tg:\n",
    "                if np.any(abs(pd - t_onset) <= tolerance):\n",
    "                    matched_onsets += 1\n",
    "\n",
    "        match_ratio = matched_onsets / (total_onsets + 1e-8)\n",
    "        results[f'button_{b}'] = {\n",
    "            \"total_truth_onsets\": total_onsets,\n",
    "            \"matched_onsets\": matched_onsets,\n",
    "            \"match_ratio\": match_ratio\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "timing_results = onset_alignment_score(pred[:,4:,:], target[:,4:,:], threshold=0.5, tolerance=3)\n",
    "for k, v in timing_results.items():\n",
    "   print(k, v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
