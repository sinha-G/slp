{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revised Autoencoder\n",
    "\n",
    "## Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "\n",
    "# We will not be training with a label.\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder_revised/../slp_package/input_dataset.py:113: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1472456, 8)\n",
      "(81775, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>num_segments</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>328970</th>\n",
       "      <td>mango\\MARTH\\bdcc275f-6c5b-48c1-8a32-d8641335e7...</td>\n",
       "      <td>9817</td>\n",
       "      <td>4</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>5400</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700726</th>\n",
       "      <td>public\\FOX\\08a81341-be91-4149-a92a-833097df689...</td>\n",
       "      <td>8214</td>\n",
       "      <td>3</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639275</th>\n",
       "      <td>public\\FOX\\bec5d2b8-a142-4b88-ab76-0db69e671b8...</td>\n",
       "      <td>8009</td>\n",
       "      <td>3</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720107</th>\n",
       "      <td>ranked\\FOX\\cb41809a-778a-4cb0-82dc-f43f28e39f1...</td>\n",
       "      <td>11254</td>\n",
       "      <td>5</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1800</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784662</th>\n",
       "      <td>mango\\FOX\\37a24d1b-1df5-428d-a938-e6dc0c1fba35...</td>\n",
       "      <td>11049</td>\n",
       "      <td>5</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                player_inputs_np_sub_path  length  \\\n",
       "328970  mango\\MARTH\\bdcc275f-6c5b-48c1-8a32-d8641335e7...    9817   \n",
       "700726  public\\FOX\\08a81341-be91-4149-a92a-833097df689...    8214   \n",
       "639275  public\\FOX\\bec5d2b8-a142-4b88-ab76-0db69e671b8...    8009   \n",
       "720107  ranked\\FOX\\cb41809a-778a-4cb0-82dc-f43f28e39f1...   11254   \n",
       "784662  mango\\FOX\\37a24d1b-1df5-428d-a938-e6dc0c1fba35...   11049   \n",
       "\n",
       "        num_segments labels  encoded_labels  segment_index  \\\n",
       "328970             4  MARTH              14              3   \n",
       "700726             3    FOX               5              2   \n",
       "639275             3    FOX               5              2   \n",
       "720107             5    FOX               5              1   \n",
       "784662             5    FOX               5              0   \n",
       "\n",
       "        segment_start_index  segment_length  \n",
       "328970                 5400            3600  \n",
       "700726                 3600            3600  \n",
       "639275                 3600            3600  \n",
       "720107                 1800            3600  \n",
       "784662                    0            3600  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_length = 3600\n",
    "shift = 1800\n",
    "\n",
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(segment_length,shift=shift, proportion_of_segments=1, test_ratio = .1, val = False)\n",
    "porportion = 1\n",
    "train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "porportion = .5\n",
    "test_df = test_df.sample(frac=porportion, random_state = 42)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading and optionally transforming game segments from compressed NumPy files.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must include the following columns:\n",
    "          - 'player_inputs_np_sub_path': file paths to the compressed NumPy files\n",
    "          - 'encoded_labels': integer-encoded labels\n",
    "          - 'segment_start_index': start index for each segment\n",
    "          - 'segment_length': length of each segment in frames\n",
    "    transform : bool, default=False\n",
    "        If True, applies a specific transformation to each loaded segment (e.g., scaling analog inputs).\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=False):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "        # Optional: you can store a shape attribute to document the shape \n",
    "        # of data that __getitem__ will return. \n",
    "        # We'll initialize it to None and fill it when the first item is fetched.\n",
    "        self.sample_shape = None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves the sample (and possibly label) from the dataset at index 'idx'.\n",
    "\n",
    "        In this custom dataset:\n",
    "          1. We open the compressed file corresponding to self.file_paths[idx].\n",
    "          2. We slice out the segment using self.segment_start_index[idx] and\n",
    "             self.segment_length[idx].\n",
    "          3. If transform=True, we apply additional transformations (shifting, scaling, etc.).\n",
    "          4. We return a PyTorch tensor containing the processed segment.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        idx : int\n",
    "            Index of the sample to be fetched.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A tensor representing the selected segment, after optional transformations.\n",
    "        \"\"\"\n",
    "        # Load the uncompressed file\n",
    "        file_path = self.file_paths[idx].replace('\\\\', '/')\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + file_path, 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "\n",
    "        # Determine slice boundaries\n",
    "        start = int(self.segment_start_index[idx])\n",
    "        end = start + int(self.segment_length[idx])\n",
    "\n",
    "        # Extract the segment\n",
    "        segment = segment[:, start:end]\n",
    "\n",
    "        # Apply transformations if requested\n",
    "        if self.transform:\n",
    "            # Example transformation: shape = (9+4, 3600) for some reason\n",
    "            transformed = np.zeros((9 + 4, int(self.segment_length[idx])))\n",
    "\n",
    "            # 1) Shift and scale analog inputs to [0, 1]\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            analog_transformed *= 0.5 / 0.725\n",
    "            analog_transformed += 0.5\n",
    "            transformed[0:4] = analog_transformed\n",
    "\n",
    "            # 2) Mark positions where analog inputs are zero\n",
    "            transformed[4:8] += (segment[:4] == 0)\n",
    "\n",
    "            # # Possible additional transformations:\n",
    "            # # 3) Some custom “transition” measure on last 5 rows\n",
    "            # prepend = np.expand_dims(segment[-5:, 0], axis=1)\n",
    "            # transitions = np.abs(np.diff(segment[-5:], axis=1, prepend=prepend))\n",
    "            # transformed[8:13] += transitions\n",
    "\n",
    "            # 4) Add button inputs\n",
    "            transformed[-5:] += segment[-5:]\n",
    "\n",
    "        else:\n",
    "            # If not transforming, produce something simpler (9 x 60)\n",
    "            transformed = np.zeros((9, int(self.segment_length[idx])))\n",
    "\n",
    "            # 1) Shift and scale analog inputs to [0, 1]\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            analog_transformed *= 0.5 / 0.725\n",
    "            analog_transformed += 0.5\n",
    "            transformed[0:4] = analog_transformed\n",
    "\n",
    "            # 2) Transform the Trigger to 0/1\n",
    "            transformed[-5] += (segment[-5] > 0.5)\n",
    "\n",
    "            # 3) The last 4 rows become button inputs\n",
    "            transformed[-4:] += segment[-4:]\n",
    "\n",
    "        # Convert to PyTorch tensor\n",
    "        segment_tensor = torch.from_numpy(transformed).float()\n",
    "\n",
    "        # Optionally store the shape of the output the first time __getitem__ is called\n",
    "        if self.sample_shape is None:\n",
    "            self.sample_shape = segment_tensor.shape\n",
    "\n",
    "        return segment_tensor\n",
    "\n",
    "\n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers,  transform = True):\n",
    "    \"\"\"\n",
    "    Creates DataLoader objects for training and testing sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df : pd.DataFrame\n",
    "    test_df : pd.DataFrame\n",
    "    batch_size : int\n",
    "    num_workers : int\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict of DataLoader\n",
    "        'train' -> training DataLoader\n",
    "        'test' -> testing DataLoader\n",
    "    \"\"\"\n",
    "    train_dataset = TrainingDataset(train_df, transform=transform)\n",
    "    test_dataset = TrainingDataset(test_df, transform=transform)\n",
    "\n",
    "    loaders = {\n",
    "        'train': DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=num_workers, \n",
    "            pin_memory=True,\n",
    "            persistent_workers=True\n",
    "        ),\n",
    "        'test': DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=num_workers, \n",
    "            pin_memory=True,\n",
    "            persistent_workers=True\n",
    "        )\n",
    "    }\n",
    "    return loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_with_virtual_epochs(model, criterion, optimizer, loaders, device, channels, segment_length, num_epochs=1, bce_scale=100):\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=15, factor=0.1)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    vepoch_total = 0\n",
    "    vepoch_loss_sum = 0\n",
    "    best_vepoch_loss = float('inf')\n",
    "    early_stopping_patience = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        virtual_epoch_start_time = time.time()\n",
    "\n",
    "        # Initialize variables for tracking gradient and parameter stats\n",
    "        grad_max = float('-inf')\n",
    "        grad_min = float('inf')\n",
    "        param_max = float('-inf')\n",
    "        param_min = float('inf')\n",
    "\n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output_gpu = model(target_gpu)\n",
    "            loss = criterion(output_gpu, target_gpu) / (channels * segment_length * target_cpu.size(0))\n",
    "            \n",
    "            loss.backward()\n",
    "\n",
    "            # Track max and min of gradients\n",
    "            batch_grad_max = max((p.grad.max().item() for p in model.parameters() if p.grad is not None), default=grad_max)\n",
    "            batch_grad_min = min((p.grad.min().item() for p in model.parameters() if p.grad is not None), default=grad_min)\n",
    "            grad_max = max(grad_max, batch_grad_max)\n",
    "            grad_min = min(grad_min, batch_grad_min)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            vepoch_total += target_cpu.size(0)\n",
    "            vepoch_loss_sum += loss.item() * target_cpu.size(0)\n",
    "\n",
    "            if time.time() - virtual_epoch_start_time > 60:\n",
    "                vepoch_loss = vepoch_loss_sum / vepoch_total\n",
    "                if best_vepoch_loss > vepoch_loss:\n",
    "                    best_vepoch_loss = vepoch_loss\n",
    "                else:\n",
    "                    early_stopping_patience += 1\n",
    "\n",
    "                # Calculate max and min of model parameters at the end of the virtual epoch\n",
    "                param_max = max(p.data.max().item() for p in model.parameters())\n",
    "                param_min = min(p.data.min().item() for p in model.parameters())\n",
    "\n",
    "                train_loader_tqdm.set_postfix(\n",
    "                    Best=f'{best_vepoch_loss * bce_scale:.10f}',\n",
    "                    Vepoch=f'{vepoch_loss * bce_scale:.10f}',\n",
    "                    patience=early_stopping_patience,\n",
    "                    Grad_Max=grad_max,\n",
    "                    Grad_Min=grad_min,\n",
    "                    Param_Max=param_max,\n",
    "                    Param_Min=param_min\n",
    "                )\n",
    "                # print('Grad Max:', grad_max, ' Grad Min:', grad_min)\n",
    "                virtual_epoch_start_time = time.time()\n",
    "                vepoch_total = 0\n",
    "                vepoch_loss_sum = 0\n",
    "                grad_max = float('-inf')  # Reset for next virtual epoch\n",
    "                grad_min = float('inf')   # Reset for next virtual epoch\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def predict(model, loaders, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit='batch')\n",
    "        \n",
    "        for _, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            # output_gpu = torch.sigmoid(output_gpu)\n",
    "            \n",
    "            predictions.append(torch.sigmoid(output_gpu).cpu().numpy())\n",
    "            targets.append(target_cpu.numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    return predictions, targets\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self, bce_scale=100, transform=False, weighted=False, channels=13, segment_length=3600):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        \n",
    "        # Fraction of times each button is pressed in your sample\n",
    "        buttons_sample_mean = [\n",
    "            0.16908772957310006,  # TRIGGER_LOGICAL\n",
    "            0.008974353071937505, # Z\n",
    "            0.060945588829374495, # A\n",
    "            0.04591526858731047,  # B\n",
    "            0.09663690337362206   # X_or_Y\n",
    "        ]\n",
    "        # If transform == True, you also have additional ones for jstick/cstick?\n",
    "        trigger_logical_sample_mean = [\n",
    "            0.45849791926398437,  # JSTICK_X_LOGICAL\n",
    "            0.6879025510132348,   # JSTICK_Y_LOGICAL\n",
    "            0.9726537459234259,   # CSTICK_X_LOGICAL\n",
    "            0.971675825912117     # CSTICK_Y_LOGICAL\n",
    "        ]\n",
    "\n",
    "        # Create pos_weight or bce_weights depending on your logic\n",
    "        if transform:\n",
    "            # Merge your two sets if needed\n",
    "            sample_means = trigger_logical_sample_mean + buttons_sample_mean\n",
    "        else:\n",
    "            sample_means = buttons_sample_mean\n",
    "\n",
    "        # pos_weight for each dimension: (1 - p) / p\n",
    "        pos_weight_vals = np.zeros((channels-4, segment_length))\n",
    "        for i, mean in enumerate(sample_means):\n",
    "            p_pos = mean\n",
    "            p_neg = 1.0 - mean\n",
    "            \n",
    "            pos_weight_vals[i,:] += p_neg / p_pos\n",
    "        pos_weight_tensor = torch.tensor(pos_weight_vals, dtype=torch.float, device='cuda')\n",
    "\n",
    "        if weighted:\n",
    "            # Use pos_weight instead of 'weight'\n",
    "            self.BCE = nn.BCEWithLogitsLoss(reduction='sum', pos_weight=pos_weight_tensor)\n",
    "        else:\n",
    "            self.BCE = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "\n",
    "        # Save the other components\n",
    "        self.bce_scale = bce_scale\n",
    "        self.MSE = nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred, target shape: (B, Channels, T)\n",
    "        We'll assume:\n",
    "          - pred[:, 0:4, :] are analog predictions (MSE)\n",
    "          - pred[:, 4:, :] are button predictions (BCE)\n",
    "        \"\"\"\n",
    "        # 1) MSE for first 4 analog channels\n",
    "        mse_loss = self.MSE(torch.sigmoid(pred[:, 0:4, :]), target[:, 0:4, :]) \n",
    "        # 2) BCE for the rest\n",
    "        bce_loss = self.BCE(pred[:, 4:, :], target[:, 4:, :])\n",
    "\n",
    "        # Scale & return combined\n",
    "        return mse_loss + bce_loss / self.bce_scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 3600]             896\n",
      "       BatchNorm1d-2             [-1, 64, 3600]             128\n",
      "              ReLU-3             [-1, 64, 3600]               0\n",
      "            Conv1d-4             [-1, 64, 3600]          12,352\n",
      "       BatchNorm1d-5             [-1, 64, 3600]             128\n",
      "              ReLU-6             [-1, 64, 3600]               0\n",
      "            Conv1d-7            [-1, 256, 3600]          16,640\n",
      "       BatchNorm1d-8            [-1, 256, 3600]             512\n",
      "            Conv1d-9            [-1, 256, 3600]           3,584\n",
      "      BatchNorm1d-10            [-1, 256, 3600]             512\n",
      "             ReLU-11            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-12            [-1, 256, 3600]               0\n",
      "           Conv1d-13             [-1, 64, 3600]          16,448\n",
      "      BatchNorm1d-14             [-1, 64, 3600]             128\n",
      "             ReLU-15             [-1, 64, 3600]               0\n",
      "           Conv1d-16             [-1, 64, 3600]          12,352\n",
      "      BatchNorm1d-17             [-1, 64, 3600]             128\n",
      "             ReLU-18             [-1, 64, 3600]               0\n",
      "           Conv1d-19            [-1, 256, 3600]          16,640\n",
      "      BatchNorm1d-20            [-1, 256, 3600]             512\n",
      "             ReLU-21            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-22            [-1, 256, 3600]               0\n",
      "           Conv1d-23             [-1, 64, 3600]          16,448\n",
      "      BatchNorm1d-24             [-1, 64, 3600]             128\n",
      "             ReLU-25             [-1, 64, 3600]               0\n",
      "           Conv1d-26             [-1, 64, 3600]          12,352\n",
      "      BatchNorm1d-27             [-1, 64, 3600]             128\n",
      "             ReLU-28             [-1, 64, 3600]               0\n",
      "           Conv1d-29            [-1, 256, 3600]          16,640\n",
      "      BatchNorm1d-30            [-1, 256, 3600]             512\n",
      "             ReLU-31            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-32            [-1, 256, 3600]               0\n",
      "           Conv1d-33            [-1, 128, 3600]          32,896\n",
      "      BatchNorm1d-34            [-1, 128, 3600]             256\n",
      "             ReLU-35            [-1, 128, 3600]               0\n",
      "           Conv1d-36            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-37            [-1, 128, 1800]             256\n",
      "             ReLU-38            [-1, 128, 1800]               0\n",
      "           Conv1d-39            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-40            [-1, 512, 1800]           1,024\n",
      "           Conv1d-41            [-1, 512, 1800]         131,584\n",
      "      BatchNorm1d-42            [-1, 512, 1800]           1,024\n",
      "             ReLU-43            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-44            [-1, 512, 1800]               0\n",
      "           Conv1d-45            [-1, 128, 1800]          65,664\n",
      "      BatchNorm1d-46            [-1, 128, 1800]             256\n",
      "             ReLU-47            [-1, 128, 1800]               0\n",
      "           Conv1d-48            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-49            [-1, 128, 1800]             256\n",
      "             ReLU-50            [-1, 128, 1800]               0\n",
      "           Conv1d-51            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-52            [-1, 512, 1800]           1,024\n",
      "             ReLU-53            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-54            [-1, 512, 1800]               0\n",
      "           Conv1d-55            [-1, 128, 1800]          65,664\n",
      "      BatchNorm1d-56            [-1, 128, 1800]             256\n",
      "             ReLU-57            [-1, 128, 1800]               0\n",
      "           Conv1d-58            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-59            [-1, 128, 1800]             256\n",
      "             ReLU-60            [-1, 128, 1800]               0\n",
      "           Conv1d-61            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-62            [-1, 512, 1800]           1,024\n",
      "             ReLU-63            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-64            [-1, 512, 1800]               0\n",
      "           Conv1d-65            [-1, 128, 1800]          65,664\n",
      "      BatchNorm1d-66            [-1, 128, 1800]             256\n",
      "             ReLU-67            [-1, 128, 1800]               0\n",
      "           Conv1d-68            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-69            [-1, 128, 1800]             256\n",
      "             ReLU-70            [-1, 128, 1800]               0\n",
      "           Conv1d-71            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-72            [-1, 512, 1800]           1,024\n",
      "             ReLU-73            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-74            [-1, 512, 1800]               0\n",
      "           Conv1d-75            [-1, 256, 1800]         131,328\n",
      "      BatchNorm1d-76            [-1, 256, 1800]             512\n",
      "             ReLU-77            [-1, 256, 1800]               0\n",
      "           Conv1d-78             [-1, 256, 900]         196,864\n",
      "      BatchNorm1d-79             [-1, 256, 900]             512\n",
      "             ReLU-80             [-1, 256, 900]               0\n",
      "           Conv1d-81            [-1, 1024, 900]         263,168\n",
      "      BatchNorm1d-82            [-1, 1024, 900]           2,048\n",
      "           Conv1d-83            [-1, 1024, 900]         525,312\n",
      "      BatchNorm1d-84            [-1, 1024, 900]           2,048\n",
      "             ReLU-85            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-86            [-1, 1024, 900]               0\n",
      "           Conv1d-87             [-1, 256, 900]         262,400\n",
      "      BatchNorm1d-88             [-1, 256, 900]             512\n",
      "             ReLU-89             [-1, 256, 900]               0\n",
      "           Conv1d-90             [-1, 256, 900]         196,864\n",
      "      BatchNorm1d-91             [-1, 256, 900]             512\n",
      "             ReLU-92             [-1, 256, 900]               0\n",
      "           Conv1d-93            [-1, 1024, 900]         263,168\n",
      "      BatchNorm1d-94            [-1, 1024, 900]           2,048\n",
      "             ReLU-95            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-96            [-1, 1024, 900]               0\n",
      "           Conv1d-97             [-1, 256, 900]         262,400\n",
      "      BatchNorm1d-98             [-1, 256, 900]             512\n",
      "             ReLU-99             [-1, 256, 900]               0\n",
      "          Conv1d-100             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-101             [-1, 256, 900]             512\n",
      "            ReLU-102             [-1, 256, 900]               0\n",
      "          Conv1d-103            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-104            [-1, 1024, 900]           2,048\n",
      "            ReLU-105            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-106            [-1, 1024, 900]               0\n",
      "          Conv1d-107             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-108             [-1, 256, 900]             512\n",
      "            ReLU-109             [-1, 256, 900]               0\n",
      "          Conv1d-110             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-111             [-1, 256, 900]             512\n",
      "            ReLU-112             [-1, 256, 900]               0\n",
      "          Conv1d-113            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-114            [-1, 1024, 900]           2,048\n",
      "            ReLU-115            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-116            [-1, 1024, 900]               0\n",
      "          Conv1d-117             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-118             [-1, 256, 900]             512\n",
      "            ReLU-119             [-1, 256, 900]               0\n",
      "          Conv1d-120             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-121             [-1, 256, 900]             512\n",
      "            ReLU-122             [-1, 256, 900]               0\n",
      "          Conv1d-123            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-124            [-1, 1024, 900]           2,048\n",
      "            ReLU-125            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-126            [-1, 1024, 900]               0\n",
      "          Conv1d-127             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-128             [-1, 256, 900]             512\n",
      "            ReLU-129             [-1, 256, 900]               0\n",
      "          Conv1d-130             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-131             [-1, 256, 900]             512\n",
      "            ReLU-132             [-1, 256, 900]               0\n",
      "          Conv1d-133            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-134            [-1, 1024, 900]           2,048\n",
      "            ReLU-135            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-136            [-1, 1024, 900]               0\n",
      "          Conv1d-137             [-1, 512, 900]         524,800\n",
      "     BatchNorm1d-138             [-1, 512, 900]           1,024\n",
      "            ReLU-139             [-1, 512, 900]               0\n",
      "          Conv1d-140             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-141             [-1, 512, 450]           1,024\n",
      "            ReLU-142             [-1, 512, 450]               0\n",
      "          Conv1d-143            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-144            [-1, 2048, 450]           4,096\n",
      "          Conv1d-145            [-1, 2048, 450]       2,099,200\n",
      "     BatchNorm1d-146            [-1, 2048, 450]           4,096\n",
      "            ReLU-147            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-148            [-1, 2048, 450]               0\n",
      "          Conv1d-149             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-150             [-1, 512, 450]           1,024\n",
      "            ReLU-151             [-1, 512, 450]               0\n",
      "          Conv1d-152             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-153             [-1, 512, 450]           1,024\n",
      "            ReLU-154             [-1, 512, 450]               0\n",
      "          Conv1d-155            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-156            [-1, 2048, 450]           4,096\n",
      "            ReLU-157            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-158            [-1, 2048, 450]               0\n",
      "          Conv1d-159             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-160             [-1, 512, 450]           1,024\n",
      "            ReLU-161             [-1, 512, 450]               0\n",
      "          Conv1d-162             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-163             [-1, 512, 450]           1,024\n",
      "            ReLU-164             [-1, 512, 450]               0\n",
      "          Conv1d-165            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-166            [-1, 2048, 450]           4,096\n",
      "            ReLU-167            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-168            [-1, 2048, 450]               0\n",
      "          Conv1d-169              [-1, 15, 225]          92,175\n",
      "     BatchNorm1d-170              [-1, 15, 225]              30\n",
      "            ReLU-171              [-1, 15, 225]               0\n",
      "          Linear-172                 [-1, 2048]       6,914,048\n",
      "            ReLU-173                 [-1, 2048]               0\n",
      "     BatchNorm1d-174                 [-1, 2048]           4,096\n",
      "         Encoder-175                 [-1, 2048]               0\n",
      "          Linear-176                 [-1, 3375]       6,915,375\n",
      "            ReLU-177                 [-1, 3375]               0\n",
      "     BatchNorm1d-178                 [-1, 3375]           6,750\n",
      " ConvTranspose1d-179            [-1, 2048, 450]          94,208\n",
      "     BatchNorm1d-180            [-1, 2048, 450]           4,096\n",
      "            ReLU-181            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-182             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-183             [-1, 512, 450]           1,024\n",
      "            ReLU-184             [-1, 512, 450]               0\n",
      " ConvTranspose1d-185             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-186             [-1, 512, 450]           1,024\n",
      "            ReLU-187             [-1, 512, 450]               0\n",
      " ConvTranspose1d-188            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-189            [-1, 2048, 450]           4,096\n",
      "            ReLU-190            [-1, 2048, 450]               0\n",
      "Decoder_Bottleneck-191            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-192             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-193             [-1, 512, 450]           1,024\n",
      "            ReLU-194             [-1, 512, 450]               0\n",
      " ConvTranspose1d-195             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-196             [-1, 512, 450]           1,024\n",
      "            ReLU-197             [-1, 512, 450]               0\n",
      " ConvTranspose1d-198            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-199            [-1, 2048, 450]           4,096\n",
      "            ReLU-200            [-1, 2048, 450]               0\n",
      "Decoder_Bottleneck-201            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-202             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-203             [-1, 512, 450]           1,024\n",
      "            ReLU-204             [-1, 512, 450]               0\n",
      " ConvTranspose1d-205             [-1, 512, 900]         786,944\n",
      "     BatchNorm1d-206             [-1, 512, 900]           1,024\n",
      "            ReLU-207             [-1, 512, 900]               0\n",
      " ConvTranspose1d-208            [-1, 1024, 900]         525,312\n",
      "     BatchNorm1d-209            [-1, 1024, 900]           2,048\n",
      "        Upsample-210            [-1, 2048, 900]               0\n",
      " ConvTranspose1d-211            [-1, 1024, 900]       2,098,176\n",
      "     BatchNorm1d-212            [-1, 1024, 900]           2,048\n",
      "            ReLU-213            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-214            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-215             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-216             [-1, 256, 900]             512\n",
      "            ReLU-217             [-1, 256, 900]               0\n",
      " ConvTranspose1d-218             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-219             [-1, 256, 900]             512\n",
      "            ReLU-220             [-1, 256, 900]               0\n",
      " ConvTranspose1d-221            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-222            [-1, 1024, 900]           2,048\n",
      "            ReLU-223            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-224            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-225             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-226             [-1, 256, 900]             512\n",
      "            ReLU-227             [-1, 256, 900]               0\n",
      " ConvTranspose1d-228             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-229             [-1, 256, 900]             512\n",
      "            ReLU-230             [-1, 256, 900]               0\n",
      " ConvTranspose1d-231            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-232            [-1, 1024, 900]           2,048\n",
      "            ReLU-233            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-234            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-235             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-236             [-1, 256, 900]             512\n",
      "            ReLU-237             [-1, 256, 900]               0\n",
      " ConvTranspose1d-238             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-239             [-1, 256, 900]             512\n",
      "            ReLU-240             [-1, 256, 900]               0\n",
      " ConvTranspose1d-241            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-242            [-1, 1024, 900]           2,048\n",
      "            ReLU-243            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-244            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-245             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-246             [-1, 256, 900]             512\n",
      "            ReLU-247             [-1, 256, 900]               0\n",
      " ConvTranspose1d-248             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-249             [-1, 256, 900]             512\n",
      "            ReLU-250             [-1, 256, 900]               0\n",
      " ConvTranspose1d-251            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-252            [-1, 1024, 900]           2,048\n",
      "            ReLU-253            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-254            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-255             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-256             [-1, 256, 900]             512\n",
      "            ReLU-257             [-1, 256, 900]               0\n",
      " ConvTranspose1d-258             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-259             [-1, 256, 900]             512\n",
      "            ReLU-260             [-1, 256, 900]               0\n",
      " ConvTranspose1d-261            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-262            [-1, 1024, 900]           2,048\n",
      "            ReLU-263            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-264            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-265             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-266             [-1, 256, 900]             512\n",
      "            ReLU-267             [-1, 256, 900]               0\n",
      " ConvTranspose1d-268            [-1, 256, 1800]         196,864\n",
      "     BatchNorm1d-269            [-1, 256, 1800]             512\n",
      "            ReLU-270            [-1, 256, 1800]               0\n",
      " ConvTranspose1d-271            [-1, 512, 1800]         131,584\n",
      "     BatchNorm1d-272            [-1, 512, 1800]           1,024\n",
      "        Upsample-273           [-1, 1024, 1800]               0\n",
      " ConvTranspose1d-274            [-1, 512, 1800]         524,800\n",
      "     BatchNorm1d-275            [-1, 512, 1800]           1,024\n",
      "            ReLU-276            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-277            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-278            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-279            [-1, 128, 1800]             256\n",
      "            ReLU-280            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-281            [-1, 128, 1800]          49,280\n",
      "     BatchNorm1d-282            [-1, 128, 1800]             256\n",
      "            ReLU-283            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-284            [-1, 512, 1800]          66,048\n",
      "     BatchNorm1d-285            [-1, 512, 1800]           1,024\n",
      "            ReLU-286            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-287            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-288            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-289            [-1, 128, 1800]             256\n",
      "            ReLU-290            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-291            [-1, 128, 1800]          49,280\n",
      "     BatchNorm1d-292            [-1, 128, 1800]             256\n",
      "            ReLU-293            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-294            [-1, 512, 1800]          66,048\n",
      "     BatchNorm1d-295            [-1, 512, 1800]           1,024\n",
      "            ReLU-296            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-297            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-298            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-299            [-1, 128, 1800]             256\n",
      "            ReLU-300            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-301            [-1, 128, 1800]          49,280\n",
      "     BatchNorm1d-302            [-1, 128, 1800]             256\n",
      "            ReLU-303            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-304            [-1, 512, 1800]          66,048\n",
      "     BatchNorm1d-305            [-1, 512, 1800]           1,024\n",
      "            ReLU-306            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-307            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-308            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-309            [-1, 128, 1800]             256\n",
      "            ReLU-310            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-311            [-1, 128, 3600]          49,280\n",
      "     BatchNorm1d-312            [-1, 128, 3600]             256\n",
      "            ReLU-313            [-1, 128, 3600]               0\n",
      " ConvTranspose1d-314            [-1, 256, 3600]          33,024\n",
      "     BatchNorm1d-315            [-1, 256, 3600]             512\n",
      "        Upsample-316            [-1, 512, 3600]               0\n",
      " ConvTranspose1d-317            [-1, 256, 3600]         131,328\n",
      "     BatchNorm1d-318            [-1, 256, 3600]             512\n",
      "            ReLU-319            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-320            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-321             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-322             [-1, 64, 3600]             128\n",
      "            ReLU-323             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-324             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-325             [-1, 64, 3600]             128\n",
      "            ReLU-326             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-327            [-1, 256, 3600]          16,640\n",
      "     BatchNorm1d-328            [-1, 256, 3600]             512\n",
      "            ReLU-329            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-330            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-331             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-332             [-1, 64, 3600]             128\n",
      "            ReLU-333             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-334             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-335             [-1, 64, 3600]             128\n",
      "            ReLU-336             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-337            [-1, 256, 3600]          16,640\n",
      "     BatchNorm1d-338            [-1, 256, 3600]             512\n",
      "            ReLU-339            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-340            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-341             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-342             [-1, 64, 3600]             128\n",
      "            ReLU-343             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-344             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-345             [-1, 64, 3600]             128\n",
      "            ReLU-346             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-347             [-1, 13, 3600]             845\n",
      "         Decoder-348             [-1, 13, 3600]               0\n",
      "================================================================\n",
      "Total params: 45,942,855\n",
      "Trainable params: 45,942,855\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.18\n",
      "Forward/backward pass size (MB): 1403.67\n",
      "Params size (MB): 175.26\n",
      "Estimated Total Size (MB): 1579.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# trasform = True adds binary features corresponding to when the analog inputs are 0.\n",
    "transform = True\n",
    "# bce_scale is a tunable parameter that scales the binary cross-entropy loss.\n",
    "bce_scale = 100\n",
    "# weighted = True weights the loss function to account for the imbalance of the button being pressed.\n",
    "weighted = True\n",
    "\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size=16, num_workers=20,  transform=transform)\n",
    "# Grab one item (segment tensor) from the train dataset\n",
    "train_dataset = loaders['train'].dataset\n",
    "first_item = train_dataset[0]\n",
    "channels = first_item.size(0)\n",
    "print(channels)\n",
    "\n",
    "from Convolutional_Autoencoder_Model import ResNet_Autoencoder\n",
    "# Initialize the model\n",
    "model = ResNet_Autoencoder(channels)\n",
    "model = model.cuda()\n",
    "\n",
    "# With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(channels, segment_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are two tables to help you interpret **Binary Cross-Entropy (BCE)** loss in terms of approximate accuracy and what constitutes a \"good\" score for BCE in different contexts.\n",
    "\n",
    "---\n",
    "\n",
    "## **Table 1: Approximate BCE Loss to Accuracy Conversion**\n",
    "The relationship between BCE and accuracy depends on how well the model differentiates between positive and negative classes. While these values can vary based on data distribution, below is a general mapping:\n",
    "\n",
    "| **BCE Loss** | **Approximate Accuracy (%)** | **Interpretation**                  |\n",
    "|--------------|-------------------------------|-------------------------------------|\n",
    "| 0.69         | 50%                          | Random guessing (e.g., balanced binary classes) |\n",
    "| 0.50         | 70%                          | Slightly better than random         |\n",
    "| 0.30         | 85%                          | Good prediction capability          |\n",
    "| 0.15         | 93%                          | Excellent prediction capability     |\n",
    "| 0.05         | 98%                          | Almost perfect                      |\n",
    "| 0.01         | ~99.9%                       | Near flawless prediction            |\n",
    "\n",
    "### Notes:\n",
    "1. **Loss and accuracy are not perfectly linear**: BCE measures how confident the model is in its predictions, while accuracy simply measures the fraction of correct predictions. Small BCE loss does not always imply perfect accuracy, especially for imbalanced datasets.\n",
    "2. **Threshold Assumption**: The accuracy assumes a threshold of 0.5 to classify outputs as positive/negative.\n",
    "\n",
    "---\n",
    "\n",
    "## **Table 2: What Is a \"Good\" BCE Score?**\n",
    "What qualifies as a \"good\" BCE loss depends heavily on the context of the task, the dataset, and whether your data is balanced or imbalanced. Here's a guide:\n",
    "\n",
    "| **BCE Loss Range** | **Context/Interpretation**              | **Example**                    |\n",
    "|---------------------|-----------------------------------------|---------------------------------|\n",
    "| **0.69+**           | Random guessing; model not learning.   | Imbalanced dataset without weighting or a naive model. |\n",
    "| **0.5 - 0.69**      | Slightly better than random.           | Early training or poorly tuned model. |\n",
    "| **0.3 - 0.5**       | Decent; learning useful patterns.      | Baseline for balanced binary classification tasks. |\n",
    "| **0.1 - 0.3**       | Good; strong predictive performance.   | Typical for well-trained models on balanced datasets. |\n",
    "| **< 0.1**           | Excellent; near-perfect classification.| Highly confident predictions on well-modeled data. |\n",
    "| **< 0.01**          | Overfitting or trivial task.           | Could indicate model memorizing training data. |\n",
    "\n",
    "### Notes:\n",
    "1. **Balanced vs. Imbalanced Datasets**:\n",
    "   - On **balanced datasets**, a BCE of ~0.3 or below is generally good.\n",
    "   - On **imbalanced datasets**, a low BCE may indicate the model is simply predicting the majority class. In such cases, consider weighted BCE loss or metrics like precision, recall, and F1-score.\n",
    "2. **Dataset Difficulty**: For harder datasets (e.g., noisy data or highly overlapping classes), a BCE of ~0.4 could still represent excellent performance.\n",
    "\n",
    "---\n",
    "\n",
    "## Example Use Case Interpretation\n",
    "- If your BCE loss stabilizes around **0.2**, you can expect accuracy to be around **90-92%** on a balanced dataset.\n",
    "- If you see **0.01** BCE loss, double-check for overfitting, especially if the test BCE is much higher than the training BCE.\n",
    "\n",
    "If you provide specifics about your task (e.g., balanced or imbalanced classes, the dataset type), I can refine the interpretation further!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1: 100%|██████████| 92029/92029 [3:26:28<00:00,  7.43batch/s, Best=0.4354037318, Grad_Max=0.00498, Grad_Min=-0.00482, Param_Max=1.59, Param_Min=-1.35, Vepoch=0.4410146753, patience=103]   \n"
     ]
    }
   ],
   "source": [
    "criterion = CustomLoss(bce_scale=bce_scale, transform=transform, weighted=weighted, channels=channels, segment_length=segment_length)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 1\n",
    "\n",
    "# This seems to sometimes help\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "\n",
    "# start_time = time.time()\n",
    "# train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', channels, segment_length, num_epochs, bce_scale=bce_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/workspace/melee_project_data/autoencoder_models/autoencoder_revised_one_epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5111/5111 [04:15<00:00, 20.02batch/s]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pred, target = predict(model, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>How Close</th>\n",
       "      <th>JSTICK_X</th>\n",
       "      <th>JSTICK_Y</th>\n",
       "      <th>CSTICK_X</th>\n",
       "      <th>CSTICK_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23.334191</td>\n",
       "      <td>30.823776</td>\n",
       "      <td>68.872342</td>\n",
       "      <td>70.788014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>45.892614</td>\n",
       "      <td>56.804105</td>\n",
       "      <td>92.195836</td>\n",
       "      <td>92.295496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>55.297101</td>\n",
       "      <td>64.883439</td>\n",
       "      <td>95.826098</td>\n",
       "      <td>95.307862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>61.410927</td>\n",
       "      <td>69.757600</td>\n",
       "      <td>96.897887</td>\n",
       "      <td>96.205170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>65.926010</td>\n",
       "      <td>73.318168</td>\n",
       "      <td>97.198969</td>\n",
       "      <td>96.621605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>69.485562</td>\n",
       "      <td>76.147949</td>\n",
       "      <td>97.315974</td>\n",
       "      <td>96.875920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>72.433136</td>\n",
       "      <td>78.506577</td>\n",
       "      <td>97.382867</td>\n",
       "      <td>97.055283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>74.946807</td>\n",
       "      <td>80.525916</td>\n",
       "      <td>97.431227</td>\n",
       "      <td>97.193124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>77.138498</td>\n",
       "      <td>82.291070</td>\n",
       "      <td>97.469996</td>\n",
       "      <td>97.305327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>79.075976</td>\n",
       "      <td>83.857887</td>\n",
       "      <td>97.502939</td>\n",
       "      <td>97.400375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   How Close   JSTICK_X   JSTICK_Y   CSTICK_X   CSTICK_Y\n",
       "0          0  23.334191  30.823776  68.872342  70.788014\n",
       "1          1  45.892614  56.804105  92.195836  92.295496\n",
       "2          2  55.297101  64.883439  95.826098  95.307862\n",
       "3          3  61.410927  69.757600  96.897887  96.205170\n",
       "4          4  65.926010  73.318168  97.198969  96.621605\n",
       "5          5  69.485562  76.147949  97.315974  96.875920\n",
       "6          6  72.433136  78.506577  97.382867  97.055283\n",
       "7          7  74.946807  80.525916  97.431227  97.193124\n",
       "8          8  77.138498  82.291070  97.469996  97.305327\n",
       "9          9  79.075976  83.857887  97.502939  97.400375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_stick_targets = np.round(target[:,0:4] / 0.008620689655172415 ).astype(np.int32)\n",
    "integer_stick_pred = np.round(pred[:,0:4] / 0.008620689655172415).astype(np.int32)\n",
    "\n",
    "\n",
    "\n",
    "n = 10\n",
    "\n",
    "buttons = ['JSTICK_X', 'JSTICK_Y', 'CSTICK_X', 'CSTICK_Y']\n",
    "# buttons = ['X_or_Y']\n",
    "\n",
    "\n",
    "stick_accuracy_df = pd.DataFrame(np.arange(n,dtype=np.int16),columns=['How Close'])\n",
    "# print(summary_df)\n",
    "\n",
    "\n",
    "for j in range(4):\n",
    "    unique, counts = np.unique(integer_stick_pred[:,j] - integer_stick_targets[:,j], return_counts=True)\n",
    "    data = []\n",
    "    num = np.sum(counts)\n",
    "    for i in range(n):\n",
    "        mask = np.abs(unique) <= i\n",
    "        data += [np.sum(counts[mask]) / num * 100]\n",
    "    stick_accuracy_df[buttons[j]] = data\n",
    "        \n",
    "stick_accuracy_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95.19907571588709, 97.4271425659839, 99.72547980569992, 99.66317877645301]\n"
     ]
    }
   ],
   "source": [
    "target_stick_is_zero = (integer_stick_targets == 0)*1\n",
    "pred_stick_is_zero = (integer_stick_pred == 0)*1\n",
    "\n",
    "zero_accuracy = []\n",
    "# find the accuracy of the model when the stick is zero\n",
    "for j in range(4):\n",
    "    diff = np.abs(target_stick_is_zero[:,j] - pred_stick_is_zero[:,j])\n",
    "    data = []\n",
    "    num_correct = np.sum(diff == 0)\n",
    "    zero_accuracy.append(num_correct / np.prod(diff.shape) * 100)\n",
    "print(zero_accuracy)\n",
    "# zero_accuracy_df = pd.DataFrame(columns=buttons, data=[zero_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Button</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Acc of 0</th>\n",
       "      <th>Acc of 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRIGGER_LOGICAL</td>\n",
       "      <td>17.151562</td>\n",
       "      <td>87.060622</td>\n",
       "      <td>93.896117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z</td>\n",
       "      <td>19.795249</td>\n",
       "      <td>98.967030</td>\n",
       "      <td>99.990756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>18.491760</td>\n",
       "      <td>92.075718</td>\n",
       "      <td>98.283654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>19.153975</td>\n",
       "      <td>95.610165</td>\n",
       "      <td>99.176081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_or_Y</td>\n",
       "      <td>16.800952</td>\n",
       "      <td>83.082631</td>\n",
       "      <td>92.378738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Button   Accuracy   Acc of 0   Acc of 1\n",
       "0  TRIGGER_LOGICAL  17.151562  87.060622  93.896117\n",
       "1                Z  19.795249  98.967030  99.990756\n",
       "2                A  18.491760  92.075718  98.283654\n",
       "3                B  19.153975  95.610165  99.176081\n",
       "4           X_or_Y  16.800952  83.082631  92.378738"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example data setup (make sure you have your actual data in these variables)\n",
    "# target = np.random.randint(0, 2, (100, 9))  # Example target array\n",
    "# pred = np.random.random((100, 9))  # Example predictions array\n",
    "buttons = [ 'TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "\n",
    "# Initializing the DataFrame\n",
    "button_accuracy_df = pd.DataFrame(columns=['Button', 'Accuracy', 'Acc of 0', 'Acc of 1'])\n",
    "\n",
    "target_buttons = target[:, 4 + 4 * transform:]\n",
    "pred_buttons = pred[:, 4 + 4 * transform:] > 0.5\n",
    "total = np.prod(target_buttons.shape)\n",
    "\n",
    "# Computing accuracies and filling the DataFrame\n",
    "rows = []  # List to hold row data\n",
    "\n",
    "for i, button in enumerate(buttons):\n",
    "    correct_predictions = np.sum(target_buttons[:, i] == pred_buttons[:, i])\n",
    "    correct_zeros = np.sum((target_buttons[:, i] == 0) & (pred_buttons[:, i] == 0))\n",
    "    correct_ones = np.sum((target_buttons[:, i] == 1) & (pred_buttons[:, i] == 1))\n",
    "\n",
    "    accuracy = correct_predictions / total * 100\n",
    "    acc_of_0 = correct_zeros / np.sum(target_buttons[:, i] == 0) * 100 if np.sum(target_buttons[:, i] == 0) > 0 else 0\n",
    "    acc_of_1 = correct_ones / np.sum(target_buttons[:, i] == 1) * 100 if np.sum(target_buttons[:, i] == 1) > 0 else 0\n",
    "\n",
    "    rows.append({\n",
    "        'Button': button,\n",
    "        'Accuracy': accuracy,\n",
    "        'Acc of 0': acc_of_0,\n",
    "        'Acc of 1': acc_of_1\n",
    "    })\n",
    "\n",
    "# Use concat to add all new rows to the DataFrame at once\n",
    "button_accuracy_df = pd.concat([button_accuracy_df, pd.DataFrame(rows)], ignore_index=True)\n",
    "\n",
    "# Output the DataFrame\n",
    "button_accuracy_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
