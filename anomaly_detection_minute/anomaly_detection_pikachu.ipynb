{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    'character_name': ['PIKACHU'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIKACHU    4096\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/anomaly_detection_minute/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PIKACHU\\daa0e300-d731-42ea-a634-28c9db71...</td>\n",
       "      <td>7244</td>\n",
       "      <td>PIKACHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PIKACHU\\142d032c-4d4a-4056-b9a9-aca37c88...</td>\n",
       "      <td>7384</td>\n",
       "      <td>PIKACHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YOSHIS_STORY</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PIKACHU\\3a508695-3da7-464a-b228-88d0f051...</td>\n",
       "      <td>14390</td>\n",
       "      <td>PIKACHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PIKACHU\\1be3107a-58a6-4f48-80c0-191cf926...</td>\n",
       "      <td>11363</td>\n",
       "      <td>PIKACHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BATTLEFIELD</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PIKACHU\\0b446825-d7e3-405d-9b67-33a80ba1...</td>\n",
       "      <td>9797</td>\n",
       "      <td>PIKACHU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True               PIKACHU   \n",
       "1     POKEMON_STADIUM            2       True               PIKACHU   \n",
       "2        YOSHIS_STORY            2       True               PIKACHU   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True               PIKACHU   \n",
       "4         BATTLEFIELD            2       True               PIKACHU   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length   labels  \n",
       "0  mango\\PIKACHU\\daa0e300-d731-42ea-a634-28c9db71...    7244  PIKACHU  \n",
       "1  mango\\PIKACHU\\142d032c-4d4a-4056-b9a9-aca37c88...    7384  PIKACHU  \n",
       "2  mango\\PIKACHU\\3a508695-3da7-464a-b228-88d0f051...   14390  PIKACHU  \n",
       "3  mango\\PIKACHU\\1be3107a-58a6-4f48-80c0-191cf926...   11363  PIKACHU  \n",
       "4  mango\\PIKACHU\\0b446825-d7e3-405d-9b67-33a80ba1...    9797  PIKACHU  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())\n",
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Label  Count  Shift\n",
      "0  PIKACHU   4067   2032\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(3600,15000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           player_inputs_np_sub_path  length  num_segments  \\\n",
      "0  public\\PIKACHU\\683b5d15-bc36-4c91-8503-aff1dee...    9693             3   \n",
      "1  ranked\\PIKACHU\\5d30f16a-a1cb-44c7-b815-e03724e...   11724             4   \n",
      "2  public\\PIKACHU\\c337441e-e286-4703-ae91-16c32d0...   11724             4   \n",
      "3  ranked\\PIKACHU\\d881f727-966a-44e1-a9c6-d4d37ee...    7650             2   \n",
      "4  ranked\\PIKACHU\\5b9fa78a-09a3-4c75-9901-3da6bed...   13746             5   \n",
      "\n",
      "    labels  encoded_labels  \n",
      "0  PIKACHU               0  \n",
      "1  PIKACHU               0  \n",
      "2  PIKACHU               0  \n",
      "3  PIKACHU               0  \n",
      "4  PIKACHU               0  \n"
     ]
    }
   ],
   "source": [
    "train_df, pikachu_test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, pikachu_test_df = dataset.all_segments_train_test_split_dataframes(3600, proportion_of_segments=1, test_ratio = .2, val = False)\n",
    "# porportion = .8\n",
    "# train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "# porportion = .05\n",
    "# pikachu_test_df = pikachu_test_df.sample(frac=porportion, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8408, 6)\n",
      "(2098, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>0</td>\n",
       "      <td>2978</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>0</td>\n",
       "      <td>5956</td>\n",
       "      <td>2</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>0</td>\n",
       "      <td>8934</td>\n",
       "      <td>3</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ranked\\PIKACHU\\f3d5e964-c520-45c5-b589-2eac95d...</td>\n",
       "      <td>PIKACHU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           player_inputs_np_sub_path   labels  encoded_labels  \\\n",
       "0  ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...  PIKACHU               0   \n",
       "1  ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...  PIKACHU               0   \n",
       "2  ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...  PIKACHU               0   \n",
       "3  ranked\\PIKACHU\\68fcf66a-c7ba-4a5d-9f96-bbe9cf8...  PIKACHU               0   \n",
       "4  ranked\\PIKACHU\\f3d5e964-c520-45c5-b589-2eac95d...  PIKACHU               0   \n",
       "\n",
       "   segment_start_index  segment_index  segment_length  \n",
       "0                    0              0            3600  \n",
       "1                 2978              1            3600  \n",
       "2                 5956              2            3600  \n",
       "3                 8934              3            3600  \n",
       "4                    0              0            3600  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(pikachu_test_df.shape)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PICHU    230\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/anomaly_detection_minute/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BATTLEFIELD</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PICHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PICHU\\36e5d441-a59c-411f-a381-c233d8b5e3...</td>\n",
       "      <td>7817</td>\n",
       "      <td>PICHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YOSHIS_STORY</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PICHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PICHU\\33ab85fd-cdf4-4fc1-8e09-9830156d11...</td>\n",
       "      <td>8924</td>\n",
       "      <td>PICHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BATTLEFIELD</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PICHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\PICHU\\6e1d9b21-c812-48a9-bbbe-f86432c909...</td>\n",
       "      <td>9863</td>\n",
       "      <td>PICHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PICHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>ranked\\PICHU\\0651785c-667e-4c03-ad6f-16315e25f...</td>\n",
       "      <td>1052</td>\n",
       "      <td>PICHU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BATTLEFIELD</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>PICHU</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>ranked\\PICHU\\0532f85a-bc4e-4c19-8c5f-aa767408e...</td>\n",
       "      <td>12718</td>\n",
       "      <td>PICHU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0         BATTLEFIELD            2       True                 PICHU   \n",
       "1        YOSHIS_STORY            2       True                 PICHU   \n",
       "2         BATTLEFIELD            2       True                 PICHU   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                 PICHU   \n",
       "4         BATTLEFIELD            2       True                 PICHU   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\PICHU\\36e5d441-a59c-411f-a381-c233d8b5e3...    7817  PICHU  \n",
       "1  mango\\PICHU\\33ab85fd-cdf4-4fc1-8e09-9830156d11...    8924  PICHU  \n",
       "2  mango\\PICHU\\6e1d9b21-c812-48a9-bbbe-f86432c909...    9863  PICHU  \n",
       "3  ranked\\PICHU\\0651785c-667e-4c03-ad6f-16315e25f...    1052  PICHU  \n",
       "4  ranked\\PICHU\\0532f85a-bc4e-4c19-8c5f-aa767408e...   12718  PICHU  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    'character_name': ['PICHU'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}\n",
    "\n",
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())\n",
    "dataset.dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Label  Count  Shift\n",
      "0  PICHU    227   3296\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(3600,500)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(563, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df, pichu_test_df = dataset.all_segments_train_test_split_dataframes(3600, proportion_of_segments=1, test_ratio = .99, val = False)\n",
    "# porportion = .8\n",
    "# train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "# porportion = .05\n",
    "# pichu_test_df = pichu_test_df.sample(frac=porportion, random_state = 42)\n",
    "print(pichu_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIKACHU    2098\n",
       "PICHU       563\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.concat([pichu_test_df,pikachu_test_df], ignore_index=True)\n",
    "test_df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,int(segment_start):int(segment_end)]\n",
    "        \n",
    "        # separate into positive and negative values\n",
    "        # if self.transform:\n",
    "        #     transformed = np.zeros((13,60))\n",
    "        #     transformed[0,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] > 0)\n",
    "        #     transformed[1,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] < 0)\n",
    "        #     transformed[2,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] > 0)\n",
    "        #     transformed[3,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] < 0)\n",
    "        #     transformed[4,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] > 0)\n",
    "        #     transformed[5,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] < 0)\n",
    "        #     transformed[6,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] > 0)\n",
    "        #     transformed[7,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] < 0)\n",
    "        #     transformed[8:,:] = segment[4:]\n",
    "        #     segment = transformed\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "        #     segment[0:4, :] -= .2875 * (segment[0:4, :] > 0)\n",
    "        #     segment[0:4, :] += .2875 * (segment[0:4, :] < 0)\n",
    "\n",
    "        #     # Scale inputs to be between -.5 and .5\n",
    "        #     segment[0:4, :] *= 1.40350877193 / 2\n",
    "        #     segment[0:4, :] += .5\n",
    "        segment[-5] = (segment[-5] > .5)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = np.zeros((9 + 5+4,60))\n",
    "            \n",
    "            # First 4 rows of transformed are the analog inputs transformed to have range [0,1]\n",
    "            # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            # Scale inputs to be between -.5 and .5\n",
    "            analog_transformed *= .5 / .725\n",
    "            # Add .5 to so final inputs are between 0 and 1\n",
    "            analog_transformed += .5\n",
    "            \n",
    "            transformed[0:4] = analog_transformed\n",
    "            # Next four rows are 1 if the corresponding analog input is 0\n",
    "            transformed[4:8] += (segment[:4] == 0)\n",
    "            \n",
    "            \n",
    "            prepend = np.expand_dims(segment[-5:, 0], axis=1)\n",
    "            transitions= np.abs(np.diff(segment[-5:], axis=1, prepend=prepend))\n",
    "            \n",
    "            transformed[8:13] += transitions\n",
    "            \n",
    "            \n",
    "\n",
    "            # Transform the Trigger so that it is 0 or 1\n",
    "            \n",
    "            \n",
    "            # Remaining rows are button inputs\n",
    "            transformed[-5:] += segment[-5:]\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(transformed).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,int(segment_start):int(segment_end)]\n",
    "        \n",
    "        # separate into positive and negative values\n",
    "        # if self.transform:\n",
    "        #     transformed = np.zeros((13,60))\n",
    "        #     transformed[0,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] > 0)\n",
    "        #     transformed[1,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] < 0)\n",
    "        #     transformed[2,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] > 0)\n",
    "        #     transformed[3,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] < 0)\n",
    "        #     transformed[4,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] > 0)\n",
    "        #     transformed[5,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] < 0)\n",
    "        #     transformed[6,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] > 0)\n",
    "        #     transformed[7,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] < 0)\n",
    "        #     transformed[8:,:] = segment[4:]\n",
    "        #     segment = transformed\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "        #     segment[0:4, :] -= .2875 * (segment[0:4, :] > 0)\n",
    "        #     segment[0:4, :] += .2875 * (segment[0:4, :] < 0)\n",
    "\n",
    "        #     # Scale inputs to be between -.5 and .5\n",
    "        #     segment[0:4, :] *= 1.40350877193 / 2\n",
    "        #     segment[0:4, :] += .5\n",
    "        segment[-5] = (segment[-5] > .5)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = np.zeros((9 + 5+4,3600))\n",
    "            \n",
    "            # First 4 rows of transformed are the analog inputs transformed to have range [0,1]\n",
    "            # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            # Scale inputs to be between -.5 and .5\n",
    "            analog_transformed *= .5 / .725\n",
    "            # Add .5 to so final inputs are between 0 and 1\n",
    "            analog_transformed += .5\n",
    "            \n",
    "            transformed[0:4] = analog_transformed\n",
    "            # Next four rows are 1 if the corresponding analog input is 0\n",
    "            transformed[4:8] += (segment[:4] == 0)\n",
    "            \n",
    "            \n",
    "            prepend = np.expand_dims(segment[-5:, 0], axis=1)\n",
    "            transitions= np.abs(np.diff(segment[-5:], axis=1, prepend=prepend))\n",
    "            \n",
    "            transformed[8:13] += transitions\n",
    "            \n",
    "            \n",
    "\n",
    "            # Transform the Trigger so that it is 0 or 1\n",
    "            \n",
    "            \n",
    "            # Remaining rows are button inputs\n",
    "            transformed[-5:] += segment[-5:]\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(transformed).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df,True)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df,True)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, criterion, optimizer, loaders, device, num_epochs=1):\n",
    "    # Initialize progress bar for the epochs\n",
    "    epoch_progress = tqdm(range(num_epochs), desc='Training Progress', unit='epoch')\n",
    "\n",
    "    for epoch in epoch_progress:\n",
    "        model.train()\n",
    "        epoch_loss_sum = 0\n",
    "        epoch_total = 0\n",
    "\n",
    "        for _, target_cpu in enumerate(loaders['train']):\n",
    "            # Move data to the appropriate device\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(output_gpu, target_gpu) / (18 * 3600 * target_cpu.size(0))\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients to avoid exploding gradients\n",
    "            # clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # Perform a single optimization step\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss sum for accurate average calculation\n",
    "            epoch_loss_sum += loss.item() * target_cpu.size(0)\n",
    "            epoch_total += target_cpu.size(0)\n",
    "\n",
    "        # Calculate average loss for the epoch\n",
    "        epoch_loss = epoch_loss_sum / epoch_total\n",
    "\n",
    "        # Update progress bar with the final loss of the epoch\n",
    "        epoch_progress.set_postfix(Loss=f'{epoch_loss * 100:.10f}')\n",
    "        print(epoch_loss* 100)\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, criterion, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = False\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loader, unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            if batch_number == 0:\n",
    "                eval_loss = criterion(output_gpu, target_gpu)\n",
    "            else:\n",
    "                eval_loss = torch.cat((eval_loss, criterion(output_gpu, target_gpu)),0)\n",
    "            \n",
    "            \n",
    "            # total += target_gpu.shape[0] / (32 * 16 * 4)\n",
    "            # eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.10f}') \n",
    "    \n",
    "    return eval_loss.to('cpu').numpy()\n",
    "            \n",
    "    # print(f'Evaluated Loss: {eval_loss / total:.10f}')=\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 64, 3600]           1,216\n",
      "       BatchNorm1d-2             [-1, 64, 3600]             128\n",
      "              ReLU-3             [-1, 64, 3600]               0\n",
      "            Conv1d-4             [-1, 64, 3600]          12,352\n",
      "       BatchNorm1d-5             [-1, 64, 3600]             128\n",
      "              ReLU-6             [-1, 64, 3600]               0\n",
      "            Conv1d-7            [-1, 256, 3600]          16,640\n",
      "       BatchNorm1d-8            [-1, 256, 3600]             512\n",
      "            Conv1d-9            [-1, 256, 3600]           4,864\n",
      "      BatchNorm1d-10            [-1, 256, 3600]             512\n",
      "             ReLU-11            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-12            [-1, 256, 3600]               0\n",
      "           Conv1d-13             [-1, 64, 3600]          16,448\n",
      "      BatchNorm1d-14             [-1, 64, 3600]             128\n",
      "             ReLU-15             [-1, 64, 3600]               0\n",
      "           Conv1d-16             [-1, 64, 3600]          12,352\n",
      "      BatchNorm1d-17             [-1, 64, 3600]             128\n",
      "             ReLU-18             [-1, 64, 3600]               0\n",
      "           Conv1d-19            [-1, 256, 3600]          16,640\n",
      "      BatchNorm1d-20            [-1, 256, 3600]             512\n",
      "             ReLU-21            [-1, 256, 3600]               0\n",
      "Encoder_Bottleneck-22            [-1, 256, 3600]               0\n",
      "           Conv1d-23            [-1, 128, 3600]          32,896\n",
      "      BatchNorm1d-24            [-1, 128, 3600]             256\n",
      "             ReLU-25            [-1, 128, 3600]               0\n",
      "           Conv1d-26            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-27            [-1, 128, 1800]             256\n",
      "             ReLU-28            [-1, 128, 1800]               0\n",
      "           Conv1d-29            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-30            [-1, 512, 1800]           1,024\n",
      "           Conv1d-31            [-1, 512, 1800]         131,584\n",
      "      BatchNorm1d-32            [-1, 512, 1800]           1,024\n",
      "             ReLU-33            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-34            [-1, 512, 1800]               0\n",
      "           Conv1d-35            [-1, 128, 1800]          65,664\n",
      "      BatchNorm1d-36            [-1, 128, 1800]             256\n",
      "             ReLU-37            [-1, 128, 1800]               0\n",
      "           Conv1d-38            [-1, 128, 1800]          49,280\n",
      "      BatchNorm1d-39            [-1, 128, 1800]             256\n",
      "             ReLU-40            [-1, 128, 1800]               0\n",
      "           Conv1d-41            [-1, 512, 1800]          66,048\n",
      "      BatchNorm1d-42            [-1, 512, 1800]           1,024\n",
      "             ReLU-43            [-1, 512, 1800]               0\n",
      "Encoder_Bottleneck-44            [-1, 512, 1800]               0\n",
      "           Conv1d-45            [-1, 256, 1800]         131,328\n",
      "      BatchNorm1d-46            [-1, 256, 1800]             512\n",
      "             ReLU-47            [-1, 256, 1800]               0\n",
      "           Conv1d-48             [-1, 256, 900]         196,864\n",
      "      BatchNorm1d-49             [-1, 256, 900]             512\n",
      "             ReLU-50             [-1, 256, 900]               0\n",
      "           Conv1d-51            [-1, 1024, 900]         263,168\n",
      "      BatchNorm1d-52            [-1, 1024, 900]           2,048\n",
      "           Conv1d-53            [-1, 1024, 900]         525,312\n",
      "      BatchNorm1d-54            [-1, 1024, 900]           2,048\n",
      "             ReLU-55            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-56            [-1, 1024, 900]               0\n",
      "           Conv1d-57             [-1, 256, 900]         262,400\n",
      "      BatchNorm1d-58             [-1, 256, 900]             512\n",
      "             ReLU-59             [-1, 256, 900]               0\n",
      "           Conv1d-60             [-1, 256, 900]         196,864\n",
      "      BatchNorm1d-61             [-1, 256, 900]             512\n",
      "             ReLU-62             [-1, 256, 900]               0\n",
      "           Conv1d-63            [-1, 1024, 900]         263,168\n",
      "      BatchNorm1d-64            [-1, 1024, 900]           2,048\n",
      "             ReLU-65            [-1, 1024, 900]               0\n",
      "Encoder_Bottleneck-66            [-1, 1024, 900]               0\n",
      "           Conv1d-67             [-1, 512, 900]         524,800\n",
      "      BatchNorm1d-68             [-1, 512, 900]           1,024\n",
      "             ReLU-69             [-1, 512, 900]               0\n",
      "           Conv1d-70             [-1, 512, 450]         786,944\n",
      "      BatchNorm1d-71             [-1, 512, 450]           1,024\n",
      "             ReLU-72             [-1, 512, 450]               0\n",
      "           Conv1d-73            [-1, 2048, 450]       1,050,624\n",
      "      BatchNorm1d-74            [-1, 2048, 450]           4,096\n",
      "           Conv1d-75            [-1, 2048, 450]       2,099,200\n",
      "      BatchNorm1d-76            [-1, 2048, 450]           4,096\n",
      "             ReLU-77            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-78            [-1, 2048, 450]               0\n",
      "           Conv1d-79             [-1, 512, 450]       1,049,088\n",
      "      BatchNorm1d-80             [-1, 512, 450]           1,024\n",
      "             ReLU-81             [-1, 512, 450]               0\n",
      "           Conv1d-82             [-1, 512, 450]         786,944\n",
      "      BatchNorm1d-83             [-1, 512, 450]           1,024\n",
      "             ReLU-84             [-1, 512, 450]               0\n",
      "           Conv1d-85            [-1, 2048, 450]       1,050,624\n",
      "      BatchNorm1d-86            [-1, 2048, 450]           4,096\n",
      "             ReLU-87            [-1, 2048, 450]               0\n",
      "Encoder_Bottleneck-88            [-1, 2048, 450]               0\n",
      "           Conv1d-89              [-1, 15, 225]          92,175\n",
      "      BatchNorm1d-90              [-1, 15, 225]              30\n",
      "             ReLU-91              [-1, 15, 225]               0\n",
      "           Linear-92                  [-1, 128]         432,128\n",
      "             ReLU-93                  [-1, 128]               0\n",
      "      BatchNorm1d-94                  [-1, 128]             256\n",
      "          Encoder-95                  [-1, 128]               0\n",
      "           Linear-96                 [-1, 3375]         435,375\n",
      "             ReLU-97                 [-1, 3375]               0\n",
      "      BatchNorm1d-98                 [-1, 3375]           6,750\n",
      "  ConvTranspose1d-99            [-1, 2048, 450]          94,208\n",
      "     BatchNorm1d-100            [-1, 2048, 450]           4,096\n",
      "            ReLU-101            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-102             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-103             [-1, 512, 450]           1,024\n",
      "            ReLU-104             [-1, 512, 450]               0\n",
      " ConvTranspose1d-105             [-1, 512, 450]         786,944\n",
      "     BatchNorm1d-106             [-1, 512, 450]           1,024\n",
      "            ReLU-107             [-1, 512, 450]               0\n",
      " ConvTranspose1d-108            [-1, 2048, 450]       1,050,624\n",
      "     BatchNorm1d-109            [-1, 2048, 450]           4,096\n",
      "            ReLU-110            [-1, 2048, 450]               0\n",
      "Decoder_Bottleneck-111            [-1, 2048, 450]               0\n",
      " ConvTranspose1d-112             [-1, 512, 450]       1,049,088\n",
      "     BatchNorm1d-113             [-1, 512, 450]           1,024\n",
      "            ReLU-114             [-1, 512, 450]               0\n",
      " ConvTranspose1d-115             [-1, 512, 900]         786,944\n",
      "     BatchNorm1d-116             [-1, 512, 900]           1,024\n",
      "            ReLU-117             [-1, 512, 900]               0\n",
      " ConvTranspose1d-118            [-1, 1024, 900]         525,312\n",
      "     BatchNorm1d-119            [-1, 1024, 900]           2,048\n",
      "        Upsample-120            [-1, 2048, 900]               0\n",
      " ConvTranspose1d-121            [-1, 1024, 900]       2,098,176\n",
      "     BatchNorm1d-122            [-1, 1024, 900]           2,048\n",
      "            ReLU-123            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-124            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-125             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-126             [-1, 256, 900]             512\n",
      "            ReLU-127             [-1, 256, 900]               0\n",
      " ConvTranspose1d-128             [-1, 256, 900]         196,864\n",
      "     BatchNorm1d-129             [-1, 256, 900]             512\n",
      "            ReLU-130             [-1, 256, 900]               0\n",
      " ConvTranspose1d-131            [-1, 1024, 900]         263,168\n",
      "     BatchNorm1d-132            [-1, 1024, 900]           2,048\n",
      "            ReLU-133            [-1, 1024, 900]               0\n",
      "Decoder_Bottleneck-134            [-1, 1024, 900]               0\n",
      " ConvTranspose1d-135             [-1, 256, 900]         262,400\n",
      "     BatchNorm1d-136             [-1, 256, 900]             512\n",
      "            ReLU-137             [-1, 256, 900]               0\n",
      " ConvTranspose1d-138            [-1, 256, 1800]         196,864\n",
      "     BatchNorm1d-139            [-1, 256, 1800]             512\n",
      "            ReLU-140            [-1, 256, 1800]               0\n",
      " ConvTranspose1d-141            [-1, 512, 1800]         131,584\n",
      "     BatchNorm1d-142            [-1, 512, 1800]           1,024\n",
      "        Upsample-143           [-1, 1024, 1800]               0\n",
      " ConvTranspose1d-144            [-1, 512, 1800]         524,800\n",
      "     BatchNorm1d-145            [-1, 512, 1800]           1,024\n",
      "            ReLU-146            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-147            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-148            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-149            [-1, 128, 1800]             256\n",
      "            ReLU-150            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-151            [-1, 128, 1800]          49,280\n",
      "     BatchNorm1d-152            [-1, 128, 1800]             256\n",
      "            ReLU-153            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-154            [-1, 512, 1800]          66,048\n",
      "     BatchNorm1d-155            [-1, 512, 1800]           1,024\n",
      "            ReLU-156            [-1, 512, 1800]               0\n",
      "Decoder_Bottleneck-157            [-1, 512, 1800]               0\n",
      " ConvTranspose1d-158            [-1, 128, 1800]          65,664\n",
      "     BatchNorm1d-159            [-1, 128, 1800]             256\n",
      "            ReLU-160            [-1, 128, 1800]               0\n",
      " ConvTranspose1d-161            [-1, 128, 3600]          49,280\n",
      "     BatchNorm1d-162            [-1, 128, 3600]             256\n",
      "            ReLU-163            [-1, 128, 3600]               0\n",
      " ConvTranspose1d-164            [-1, 256, 3600]          33,024\n",
      "     BatchNorm1d-165            [-1, 256, 3600]             512\n",
      "        Upsample-166            [-1, 512, 3600]               0\n",
      " ConvTranspose1d-167            [-1, 256, 3600]         131,328\n",
      "     BatchNorm1d-168            [-1, 256, 3600]             512\n",
      "            ReLU-169            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-170            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-171             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-172             [-1, 64, 3600]             128\n",
      "            ReLU-173             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-174             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-175             [-1, 64, 3600]             128\n",
      "            ReLU-176             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-177            [-1, 256, 3600]          16,640\n",
      "     BatchNorm1d-178            [-1, 256, 3600]             512\n",
      "            ReLU-179            [-1, 256, 3600]               0\n",
      "Decoder_Bottleneck-180            [-1, 256, 3600]               0\n",
      " ConvTranspose1d-181             [-1, 64, 3600]          16,448\n",
      "     BatchNorm1d-182             [-1, 64, 3600]             128\n",
      "            ReLU-183             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-184             [-1, 64, 3600]          12,352\n",
      "     BatchNorm1d-185             [-1, 64, 3600]             128\n",
      "            ReLU-186             [-1, 64, 3600]               0\n",
      " ConvTranspose1d-187             [-1, 18, 3600]           1,170\n",
      "         Decoder-188             [-1, 18, 3600]               0\n",
      "================================================================\n",
      "Total params: 20,566,860\n",
      "Trainable params: 20,566,860\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 785.13\n",
      "Params size (MB): 78.46\n",
      "Estimated Total Size (MB): 863.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "from Convolutional_Autoencoder_Model import ResNet_Autoencoder\n",
    "\n",
    "\n",
    "channels = 9 + 5 + 4\n",
    "\n",
    "# Build model\n",
    "model = ResNet_Autoencoder(channels)\n",
    "model.load_state_dict(torch.load('/workspace/melee_project_data/pikachu_convolutional_autoencoder_1_minute_bottlenecksize_15_64_2222_weights_3.pt'))\n",
    "model.to('cuda')\n",
    "# # With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(channels, 3600))\n",
    "\n",
    "# Check that the output shape and target shape match\n",
    "# training_example = torch.rand(9, 2 ** 12).to('cuda')\n",
    "# print('Target shape:', training_example.shape)\n",
    "# model.eval()\n",
    "# output = model(training_example)\n",
    "# print('Output shape:', output.shape)\n",
    "\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "\n",
    "\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 263/263 [00:04<00:00, 65.21batch/s]\n",
      "100%|| 71/71 [00:01<00:00, 57.03batch/s]\n"
     ]
    }
   ],
   "source": [
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "# Pepare data loaders\n",
    "batch_size =  8\n",
    "num_workers = 16\n",
    "loaders = prepare_data_loaders(train_df, pikachu_test_df, batch_size, num_workers)\n",
    "\n",
    "\n",
    "    \n",
    "class CustomLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLoss, self).__init__()\n",
    "        self.BCE = nn.BCEWithLogitsLoss(reduction='none')  # Consider using weighted BCE if needed\n",
    "        self.MSE = nn.MSELoss(reduction='none')\n",
    "        self.bin_threshold = 2\n",
    "        # Self.bin_threshold bins to the left and right should account for the barely close enough threshold\n",
    "        self.barely_close_enough = (.5 + self.bin_threshold) * 0.00862#\n",
    "        self.scale_factor = - math.log(.5) / self.barely_close_enough ** 2\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        # Calculating losses\n",
    "        mse_loss = self.MSE(torch.sigmoid(pred[:,0:4,:]), target[:,0:4,:]) \n",
    "        bce_loss = self.BCE(pred[:,4:,:], target[:,4:,:])\n",
    "        \n",
    "        # print(mse_loss.shape)\n",
    "        # print(bce_loss.shape)\n",
    "        return torch.cat((mse_loss, bce_loss / 100),1)\n",
    "    \n",
    "\n",
    "\n",
    "criterion = CustomLoss()\n",
    "\n",
    "pikachu_loss = evaluate_model(model, criterion, loaders['test'], 'cuda')\n",
    "\n",
    "loaders = prepare_data_loaders(train_df, pichu_test_df, batch_size, num_workers)\n",
    "\n",
    "pichu_loss = evaluate_model(model, criterion, loaders['test'], 'cuda')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009284254\n",
      "0.009430248\n",
      "-0.00014599413\n"
     ]
    }
   ],
   "source": [
    "pikachu_loss_mean = np.mean(pikachu_loss,axis=2)\n",
    "pikachu_loss_mean = np.mean(pikachu_loss_mean,axis=1)\n",
    "print(np.mean(pikachu_loss_mean))\n",
    "\n",
    "pichu_loss_mean = np.mean(pichu_loss,axis=2)\n",
    "pichu_loss_mean = np.mean(pichu_loss_mean,axis=1)\n",
    "print(np.mean(pichu_loss_mean))\n",
    "print(np.mean(pikachu_loss_mean) - np.mean(pichu_loss_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc pikachu 0.7354623450905624\n",
      "acc pichu 0.3552397868561279\n"
     ]
    }
   ],
   "source": [
    "threshold = (np.mean(pikachu_loss_mean) + np.mean(pichu_loss_mean)) / 2\n",
    "correct_pikachu = np.sum(pikachu_loss_mean < threshold)\n",
    "correct_pichu = np.sum(pichu_loss_mean > threshold)\n",
    "print('acc pikachu', correct_pikachu / pikachu_loss.shape[0])\n",
    "print('acc pichu', correct_pichu / pichu_loss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.3097741e-03  3.2034554e-03  1.5211781e-04  2.4693492e-03\n",
      "  6.3433778e-05  2.7790479e-04  5.7577388e-05  5.0649955e-04\n",
      "  5.7245023e-05  4.8944770e-05 -1.9644154e-05  2.3087166e-05\n",
      "  1.1915690e-04 -6.0697272e-04  8.7492226e-05 -4.3492764e-04\n",
      " -2.2687612e-04 -9.6115516e-05]\n",
      "0\n",
      "acc pikachu 0.008579599618684462\n",
      "acc pichu 0.0017761989342806395\n",
      "1\n",
      "acc pikachu 0.0076263107721639654\n",
      "acc pichu 0.0017761989342806395\n",
      "2\n",
      "acc pikachu 0.005243088655862726\n",
      "acc pichu 0.010657193605683837\n",
      "3\n",
      "acc pikachu 0.006196377502383222\n",
      "acc pichu 0.0053285968028419185\n",
      "4\n",
      "acc pikachu 0.00667302192564347\n",
      "acc pichu 0.003552397868561279\n",
      "5\n",
      "acc pikachu 0.006196377502383222\n",
      "acc pichu 0.0053285968028419185\n",
      "6\n",
      "acc pikachu 0.0014299332697807435\n",
      "acc pichu 0.02486678507992895\n",
      "7\n",
      "acc pikachu 0.0038131553860819827\n",
      "acc pichu 0.017761989342806393\n",
      "8\n",
      "acc pikachu 0.0023832221163012394\n",
      "acc pichu 0.021314387211367674\n",
      "9\n",
      "acc pikachu 0.0\n",
      "acc pichu 0.03019538188277087\n",
      "10\n",
      "acc pikachu 0.0023832221163012394\n",
      "acc pichu 0.02486678507992895\n",
      "11\n",
      "acc pikachu 0.00047664442326024784\n",
      "acc pichu 0.028419182948490232\n",
      "12\n",
      "acc pikachu 0.002859866539561487\n",
      "acc pichu 0.017761989342806393\n",
      "13\n",
      "acc pikachu 0.006196377502383222\n",
      "acc pichu 0.010657193605683837\n",
      "14\n",
      "acc pikachu 0.0009532888465204957\n",
      "acc pichu 0.02664298401420959\n",
      "15\n",
      "acc pikachu 0.004766444232602479\n",
      "acc pichu 0.015985790408525755\n",
      "16\n",
      "acc pikachu 0.0038131553860819827\n",
      "acc pichu 0.017761989342806393\n",
      "17\n",
      "acc pikachu 0.005243088655862726\n",
      "acc pichu 0.014209591474245116\n"
     ]
    }
   ],
   "source": [
    "pikachu_loss_mean = np.mean(pikachu_loss,axis=2)\n",
    "pikachu_loss_mean = np.mean(pikachu_loss_mean,axis=0)\n",
    "# print(pikachu_loss_mean)\n",
    "\n",
    "pichu_loss_mean = np.mean(pichu_loss,axis=2)\n",
    "pichu_loss_mean = np.mean(pichu_loss_mean,axis=0)\n",
    "# print(pichu_loss_mean)\n",
    "\n",
    "print(pikachu_loss_mean - pichu_loss_mean)\n",
    "for index in range(18):\n",
    "\n",
    "    threshold = (pikachu_loss_mean[index] + pichu_loss_mean[index]) / 2\n",
    "    print(index)\n",
    "    print('acc pikachu', np.sum(pikachu_loss_mean < threshold) / pikachu_loss.shape[0])\n",
    "    print('acc pichu', np.sum(pichu_loss_mean > threshold) / pichu_loss.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
