{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True],\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    # 'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOX               103069\n",
      "FALCO              90719\n",
      "MARTH              53728\n",
      "CAPTAIN_FALCON     38006\n",
      "SHEIK              27623\n",
      "PEACH              17438\n",
      "JIGGLYPUFF         16374\n",
      "SAMUS               9524\n",
      "ICE_CLIMBERS        6849\n",
      "GANONDORF           6655\n",
      "YOSHI               5725\n",
      "LUIGI               5230\n",
      "DR_MARIO            4202\n",
      "PIKACHU             4096\n",
      "LINK                2502\n",
      "NESS                2306\n",
      "DONKEY_KONG         2026\n",
      "GAME_AND_WATCH      1967\n",
      "MEWTWO              1775\n",
      "MARIO               1713\n",
      "YOUNG_LINK          1447\n",
      "ROY                 1272\n",
      "BOWSER               940\n",
      "KIRBY                556\n",
      "PICHU                230\n",
      "Name: labels, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage_name</th>\n",
       "      <th>num_players</th>\n",
       "      <th>conclusive</th>\n",
       "      <th>player_character_name</th>\n",
       "      <th>player_type_name</th>\n",
       "      <th>opposing_player_type_name</th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>length</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...</td>\n",
       "      <td>5606</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...</td>\n",
       "      <td>5754</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POKEMON_STADIUM</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...</td>\n",
       "      <td>6213</td>\n",
       "      <td>MARTH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOUNTAIN_OF_DREAMS</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FOX</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...</td>\n",
       "      <td>7621</td>\n",
       "      <td>FOX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINAL_DESTINATION</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>HUMAN</td>\n",
       "      <td>mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...</td>\n",
       "      <td>7840</td>\n",
       "      <td>FALCO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           stage_name  num_players conclusive player_character_name  \\\n",
       "0   FINAL_DESTINATION            2       True                 FALCO   \n",
       "1   FINAL_DESTINATION            2       True                 FALCO   \n",
       "2     POKEMON_STADIUM            2       True                 MARTH   \n",
       "3  FOUNTAIN_OF_DREAMS            2       True                   FOX   \n",
       "4   FINAL_DESTINATION            2       True                 FALCO   \n",
       "\n",
       "  player_type_name opposing_player_type_name  \\\n",
       "0            HUMAN                     HUMAN   \n",
       "1            HUMAN                     HUMAN   \n",
       "2            HUMAN                     HUMAN   \n",
       "3            HUMAN                     HUMAN   \n",
       "4            HUMAN                     HUMAN   \n",
       "\n",
       "                           player_inputs_np_sub_path  length labels  \n",
       "0  mango\\FALCO\\727e819f-8cb3-4c3f-bf0a-ceefa9e41c...    5606  FALCO  \n",
       "1  mango\\FALCO\\76fe3db5-60de-46bb-8f0d-80d48822a8...    5754  FALCO  \n",
       "2  mango\\MARTH\\7e6b417f-249d-4629-b6dc-2fe1d95d8f...    6213  MARTH  \n",
       "3  mango\\FOX\\32305eaf-71d8-46e5-a8a1-2c7c890a9baf...    7621    FOX  \n",
       "4  mango\\FALCO\\a5396c32-6f2c-4b88-8582-f8b875bb55...    7840  FALCO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())\n",
    "dataset.dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Label   Count   Shift\n",
      "0              FOX  103069  193497\n",
      "1            FALCO   90717  168117\n",
      "2            MARTH   53728  106569\n",
      "3   CAPTAIN_FALCON   38006   70125\n",
      "4            SHEIK   27623   59145\n",
      "5            PEACH   17438   39398\n",
      "6       JIGGLYPUFF   16374   35581\n",
      "7            SAMUS    9524   23031\n",
      "8     ICE_CLIMBERS    6849   15620\n",
      "9        GANONDORF    6655   12805\n",
      "10           YOSHI    5725   12226\n",
      "11           LUIGI    5230   11464\n",
      "12        DR_MARIO    4202    9062\n",
      "13         PIKACHU    4096    8991\n",
      "14            LINK    2502    5598\n",
      "15            NESS    2306    5812\n",
      "16     DONKEY_KONG    2026    4333\n",
      "17  GAME_AND_WATCH    1967    3693\n",
      "18          MEWTWO    1775    4511\n",
      "19           MARIO    1713    3824\n",
      "20      YOUNG_LINK    1447    3278\n",
      "21             ROY    1272    2685\n",
      "22          BOWSER     940    2196\n",
      "23           KIRBY     556    1237\n",
      "24           PICHU     230     491\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(60,5000)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           player_inputs_np_sub_path  length  num_segments  \\\n",
      "0  public\\FALCO\\bee06d45-fca6-437f-969a-901efa166...   28801             1   \n",
      "1  mango\\FALCO\\44e0962b-fdf7-4a16-acbe-61b5e5d609...   27200             1   \n",
      "2  ranked\\FALCO\\2f51bb81-4304-4c6d-ac53-960aba87c...   26024             1   \n",
      "3  ranked\\FALCO\\69cf9bb4-5f80-4e67-850d-ce0d7da1d...   25128             1   \n",
      "4  ranked\\FALCO\\04257d15-f02f-4001-a191-37b97d2ed...   24323             1   \n",
      "\n",
      "  labels  encoded_labels  \n",
      "0  FALCO               4  \n",
      "1  FALCO               4  \n",
      "2  FALCO               4  \n",
      "3  FALCO               4  \n",
      "4  FALCO               4  \n"
     ]
    }
   ],
   "source": [
    "train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(60, proportion_of_segments=1, test_ratio = .2, val = False)\n",
    "porportion = .8     \n",
    "train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "porportion = .05\n",
    "test_df = test_df.sample(frac=porportion, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42970042, 6)\n",
      "(671279, 6)\n",
      "0.015381729622712384\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18418491</th>\n",
       "      <td>ranked\\FOX\\555c5173-1750-4a33-b785-b38d0ff8aaa...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>8142</td>\n",
       "      <td>138</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25236203</th>\n",
       "      <td>ranked\\FOX\\cb87e4b2-2873-453d-b039-b0128a6cf86...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>5487</td>\n",
       "      <td>93</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25261750</th>\n",
       "      <td>ranked\\FOX\\804be79f-5a9f-47ca-bfda-ef5d2b8c06d...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>472</td>\n",
       "      <td>8</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23561687</th>\n",
       "      <td>ranked\\FOX\\8fee85f6-9cb4-4914-9324-87f8d8e9b5e...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>5</td>\n",
       "      <td>8909</td>\n",
       "      <td>151</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974957</th>\n",
       "      <td>public\\FALCO\\8ea4f120-ad37-40a4-91bb-1aa235e12...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>4</td>\n",
       "      <td>4956</td>\n",
       "      <td>84</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  player_inputs_np_sub_path labels  \\\n",
       "18418491  ranked\\FOX\\555c5173-1750-4a33-b785-b38d0ff8aaa...    FOX   \n",
       "25236203  ranked\\FOX\\cb87e4b2-2873-453d-b039-b0128a6cf86...    FOX   \n",
       "25261750  ranked\\FOX\\804be79f-5a9f-47ca-bfda-ef5d2b8c06d...    FOX   \n",
       "23561687  ranked\\FOX\\8fee85f6-9cb4-4914-9324-87f8d8e9b5e...    FOX   \n",
       "3974957   public\\FALCO\\8ea4f120-ad37-40a4-91bb-1aa235e12...  FALCO   \n",
       "\n",
       "          encoded_labels  segment_start_index  segment_index  segment_length  \n",
       "18418491               5                 8142            138              60  \n",
       "25236203               5                 5487             93              60  \n",
       "25261750               5                  472              8              60  \n",
       "23561687               5                 8909            151              60  \n",
       "3974957                4                 4956             84              60  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,int(segment_start):int(segment_end)]\n",
    "        \n",
    "        # separate into positive and negative values\n",
    "        # if self.transform:\n",
    "        #     transformed = np.zeros((13,60))\n",
    "        #     transformed[0,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] > 0)\n",
    "        #     transformed[1,:] = (np.abs(segment[0]) - .2875) * 1.40350877193 * (segment[0] < 0)\n",
    "        #     transformed[2,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] > 0)\n",
    "        #     transformed[3,:] = (np.abs(segment[1]) - .2875) * 1.40350877193 * (segment[1] < 0)\n",
    "        #     transformed[4,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] > 0)\n",
    "        #     transformed[5,:] = (np.abs(segment[2]) - .2875) * 1.40350877193 * (segment[2] < 0)\n",
    "        #     transformed[6,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] > 0)\n",
    "        #     transformed[7,:] = (np.abs(segment[3]) - .2875) * 1.40350877193 * (segment[3] < 0)\n",
    "        #     transformed[8:,:] = segment[4:]\n",
    "        #     segment = transformed\n",
    "        \n",
    "        # if self.transform:\n",
    "        #     # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "        #     segment[0:4, :] -= .2875 * (segment[0:4, :] > 0)\n",
    "        #     segment[0:4, :] += .2875 * (segment[0:4, :] < 0)\n",
    "\n",
    "        #     # Scale inputs to be between -.5 and .5\n",
    "        #     segment[0:4, :] *= 1.40350877193 / 2\n",
    "        #     segment[0:4, :] += .5\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = np.zeros((13,60))\n",
    "            \n",
    "            # First 4 rows of transformed are the analog inputs transformed to have range [0,1]\n",
    "            # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875\n",
    "            # Scale inputs to be between -.5 and .5\n",
    "            analog_transformed *= 1.40350877193 / 2\n",
    "            # Add .5 to so final inputs are between 0 and 1\n",
    "            analog_transformed += .5\n",
    "            \n",
    "            transformed[0:4] = analog_transformed\n",
    "            # Next four rows are 0 if the corresponding analog input is 0\n",
    "            transformed[4:8] += 1 - (segment[:4] == 0)\n",
    "            \n",
    "            # Transform the Trigger so that it is 0 or 1\n",
    "            transformed[8] += (segment[-5] > .5)\n",
    "            \n",
    "            # Remaining rows are button inputs\n",
    "            transformed[-4:] += segment[-4:]\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(transformed).float()\n",
    "        # label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor#, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df,True)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df,True)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(model, criterion, optimizer, loaders, device, num_epochs=1, rolling_loss_number=100, patience=99):\n",
    "#     scaler = GradScaler()\n",
    "#     best_loss = float('inf')\n",
    "#     best_model = None\n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "#         rolling_loss = deque(maxlen=rolling_loss_number)\n",
    "#         rolling_total = deque(maxlen=rolling_loss_number)\n",
    "        \n",
    "#         for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "#             target_gpu = target_cpu.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             with autocast():\n",
    "#                 output_gpu = model(target_gpu)\n",
    "#                 loss = criterion(output_gpu, target_gpu) / (9 * 60 * target_cpu.size(0))\n",
    "            \n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.unscale_(optimizer)\n",
    "#             torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "#             if any(torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "#                 print(\"Warning: NaN values in gradients!\")\n",
    "#                 bad_targets = check_for_bad_targets(model, criterion, optimizer, target_gpu)\n",
    "#                 # return bad_targets\n",
    "#                 continue  # Consider whether to skip or handle differently\n",
    "                \n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "            \n",
    "#             batch_total = target_gpu.size(0)\n",
    "#             rolling_total.append(batch_total)\n",
    "#             current_batch_loss = loss.item()\n",
    "#             rolling_loss.append(current_batch_loss * target_cpu.size(0))\n",
    "#             evaluated_rolling_loss = sum(rolling_loss) / sum(rolling_total)\n",
    "#             train_loader_tqdm.set_postfix(loss=f'{evaluated_rolling_loss:.10f}')\n",
    "            \n",
    "#             # if evaluated_rolling_loss < best_loss:\n",
    "#             #     best_loss = evaluated_rolling_loss\n",
    "#             #     best_model = model.state_dict()  # Save the best model state\n",
    "            \n",
    "#             # if patience <= 0:\n",
    "#             #     print('Early Stopping.')\n",
    "#             #     model.load_state_dict(best_model)  # Load the best model state\n",
    "#             #     return \n",
    "            \n",
    "#             # patience -= 1 if evaluated_rolling_loss >= best_loss else patience  # Only decrement if no improvement\n",
    "\n",
    "    # return \n",
    "            \n",
    "def train_model_with_virtual_epochs(model, criterion, optimizer, loaders, device, num_epochs=1):\n",
    "    scaler = GradScaler()\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1)\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    vepoch_total = 0\n",
    "    vepoch_loss_sum = 0\n",
    "    best_vepoch_loss = float('inf')\n",
    "\n",
    "    early_stopping_patience = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        virtual_epoch_start_time = time.time()\n",
    "     \n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(train_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                output_gpu = model(target_gpu)\n",
    "                loss = criterion(output_gpu, target_gpu) / (13 * 60 * target_cpu.size(0))\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.unscale_(optimizer)\n",
    "            \n",
    "            \n",
    "            if any(torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                print(\"Warning: NaN values in gradients!\")\n",
    "                bad_targets = check_for_bad_targets(model, criterion, optimizer, target_gpu)\n",
    "                continue\n",
    "                \n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            vepoch_total += target_cpu.size(0)\n",
    "            vepoch_loss_sum += loss.item() * target_cpu.size(0)\n",
    "            \n",
    "            if time.time() - virtual_epoch_start_time > 60:\n",
    "                vepoch_loss = vepoch_loss_sum / vepoch_total\n",
    "                \n",
    "                if best_vepoch_loss > vepoch_loss:\n",
    "                    best_vepoch_loss = vepoch_loss\n",
    "                else:\n",
    "                    early_stopping_patience += 1\n",
    "                    \n",
    "                train_loader_tqdm.set_postfix(Best=f'{best_vepoch_loss:.10f}', Vepoch=f'{vepoch_loss:.10f}',patience=early_stopping_patience)\n",
    "                scheduler.step(vepoch_loss)\n",
    "\n",
    "                # if early_stopping_patience == 0:\n",
    "                #     return\n",
    "                    \n",
    "                virtual_epoch_start_time = time.time()\n",
    "                vepoch_total = 0\n",
    "                vepoch_loss_sum = 0\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def check_for_bad_targets(model, criterion, optimizer, targets_gpu):\n",
    "    model.train()\n",
    "    scaler = GradScaler()\n",
    "    bad_targets = []\n",
    "    \n",
    "    try: \n",
    "        for i in range(targets_gpu.size(0)):  # Assuming the first dimension is the batch size\n",
    "            single_target_gpu = targets_gpu[i].unsqueeze(0)  # Maintain batch dimension\n",
    "            \n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward and loss\n",
    "            with autocast():\n",
    "                output_gpu = model(single_target_gpu)\n",
    "                loss = criterion(output_gpu, single_target_gpu) / (13 * 60)\n",
    "            \n",
    "            # Backward\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # Check for NaNs in gradients\n",
    "            if any(torch.isnan(p.grad).any() for p in model.parameters() if p.grad is not None):\n",
    "                bad_targets.append(single_target_gpu.cpu().numpy())  # Move tensor to CPU and convert to numpy\n",
    "        \n",
    "        if bad_targets:\n",
    "            print(f'There were {len(bad_targets)} bad target(s).')\n",
    "            return bad_targets\n",
    "        else:\n",
    "            print('There were no bad targets.')\n",
    "        return None   \n",
    "     \n",
    "    except:\n",
    "        print('There was a problem evaluating the model on a single target.')\n",
    "        return targets_gpu\n",
    "            \n",
    "\n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu, target_gpu) / ((32 * 16 * 4) * 13 * 60)\n",
    "            \n",
    "            \n",
    "            total += target_gpu.shape[0] / (32 * 16 * 4)\n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (total):.10f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / total:.10f}')\n",
    "    \n",
    "def evaluate_model(model, criterion, loaders, loader, device):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit = 'batch')\n",
    "        \n",
    "        for batch_number, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            \n",
    "            eval_loss += criterion(output_gpu, target_gpu) \n",
    "            \n",
    "            \n",
    "            \n",
    "            eval_loader_tqdm.set_postfix(loss=f'{eval_loss / (batch_number + 1):.10f}') \n",
    "            \n",
    "    print(f'Evaluated Loss: {eval_loss / (batch_number + 1):.10f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 64, 60]             896\n",
      "       BatchNorm1d-2               [-1, 64, 60]             128\n",
      "               ELU-3               [-1, 64, 60]               0\n",
      "            Conv1d-4               [-1, 64, 60]          12,352\n",
      "       BatchNorm1d-5               [-1, 64, 60]             128\n",
      "               ELU-6               [-1, 64, 60]               0\n",
      "            Conv1d-7              [-1, 256, 60]          16,640\n",
      "       BatchNorm1d-8              [-1, 256, 60]             512\n",
      "            Conv1d-9              [-1, 256, 60]           3,584\n",
      "      BatchNorm1d-10              [-1, 256, 60]             512\n",
      "              ELU-11              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-12              [-1, 256, 60]               0\n",
      "           Conv1d-13               [-1, 64, 60]          16,448\n",
      "      BatchNorm1d-14               [-1, 64, 60]             128\n",
      "              ELU-15               [-1, 64, 60]               0\n",
      "           Conv1d-16               [-1, 64, 60]          12,352\n",
      "      BatchNorm1d-17               [-1, 64, 60]             128\n",
      "              ELU-18               [-1, 64, 60]               0\n",
      "           Conv1d-19              [-1, 256, 60]          16,640\n",
      "      BatchNorm1d-20              [-1, 256, 60]             512\n",
      "              ELU-21              [-1, 256, 60]               0\n",
      "Encoder_Bottleneck-22              [-1, 256, 60]               0\n",
      "           Conv1d-23              [-1, 128, 60]          32,896\n",
      "      BatchNorm1d-24              [-1, 128, 60]             256\n",
      "              ELU-25              [-1, 128, 60]               0\n",
      "           Conv1d-26              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-27              [-1, 128, 30]             256\n",
      "              ELU-28              [-1, 128, 30]               0\n",
      "           Conv1d-29              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-30              [-1, 512, 30]           1,024\n",
      "           Conv1d-31              [-1, 512, 30]         131,584\n",
      "      BatchNorm1d-32              [-1, 512, 30]           1,024\n",
      "              ELU-33              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-34              [-1, 512, 30]               0\n",
      "           Conv1d-35              [-1, 128, 30]          65,664\n",
      "      BatchNorm1d-36              [-1, 128, 30]             256\n",
      "              ELU-37              [-1, 128, 30]               0\n",
      "           Conv1d-38              [-1, 128, 30]          49,280\n",
      "      BatchNorm1d-39              [-1, 128, 30]             256\n",
      "              ELU-40              [-1, 128, 30]               0\n",
      "           Conv1d-41              [-1, 512, 30]          66,048\n",
      "      BatchNorm1d-42              [-1, 512, 30]           1,024\n",
      "              ELU-43              [-1, 512, 30]               0\n",
      "Encoder_Bottleneck-44              [-1, 512, 30]               0\n",
      "           Conv1d-45              [-1, 256, 30]         131,328\n",
      "      BatchNorm1d-46              [-1, 256, 30]             512\n",
      "              ELU-47              [-1, 256, 30]               0\n",
      "           Conv1d-48              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-49              [-1, 256, 15]             512\n",
      "              ELU-50              [-1, 256, 15]               0\n",
      "           Conv1d-51             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-52             [-1, 1024, 15]           2,048\n",
      "           Conv1d-53             [-1, 1024, 15]         525,312\n",
      "      BatchNorm1d-54             [-1, 1024, 15]           2,048\n",
      "              ELU-55             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-56             [-1, 1024, 15]               0\n",
      "           Conv1d-57              [-1, 256, 15]         262,400\n",
      "      BatchNorm1d-58              [-1, 256, 15]             512\n",
      "              ELU-59              [-1, 256, 15]               0\n",
      "           Conv1d-60              [-1, 256, 15]         196,864\n",
      "      BatchNorm1d-61              [-1, 256, 15]             512\n",
      "              ELU-62              [-1, 256, 15]               0\n",
      "           Conv1d-63             [-1, 1024, 15]         263,168\n",
      "      BatchNorm1d-64             [-1, 1024, 15]           2,048\n",
      "              ELU-65             [-1, 1024, 15]               0\n",
      "Encoder_Bottleneck-66             [-1, 1024, 15]               0\n",
      "           Conv1d-67              [-1, 512, 15]         524,800\n",
      "      BatchNorm1d-68              [-1, 512, 15]           1,024\n",
      "              ELU-69              [-1, 512, 15]               0\n",
      "           Conv1d-70               [-1, 512, 8]         786,944\n",
      "      BatchNorm1d-71               [-1, 512, 8]           1,024\n",
      "              ELU-72               [-1, 512, 8]               0\n",
      "           Conv1d-73              [-1, 2048, 8]       1,050,624\n",
      "      BatchNorm1d-74              [-1, 2048, 8]           4,096\n",
      "           Conv1d-75              [-1, 2048, 8]       2,099,200\n",
      "      BatchNorm1d-76              [-1, 2048, 8]           4,096\n",
      "              ELU-77              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-78              [-1, 2048, 8]               0\n",
      "           Conv1d-79               [-1, 512, 8]       1,049,088\n",
      "      BatchNorm1d-80               [-1, 512, 8]           1,024\n",
      "              ELU-81               [-1, 512, 8]               0\n",
      "           Conv1d-82               [-1, 512, 8]         786,944\n",
      "      BatchNorm1d-83               [-1, 512, 8]           1,024\n",
      "              ELU-84               [-1, 512, 8]               0\n",
      "           Conv1d-85              [-1, 2048, 8]       1,050,624\n",
      "      BatchNorm1d-86              [-1, 2048, 8]           4,096\n",
      "              ELU-87              [-1, 2048, 8]               0\n",
      "Encoder_Bottleneck-88              [-1, 2048, 8]               0\n",
      "           Linear-89                   [-1, 64]       1,048,640\n",
      "              ELU-90                   [-1, 64]               0\n",
      "           Linear-91                   [-1, 64]           4,160\n",
      "           Linear-92                   [-1, 64]           4,160\n",
      "              ELU-93                   [-1, 64]               0\n",
      "           Linear-94                [-1, 16384]       1,064,960\n",
      "              ELU-95                [-1, 16384]               0\n",
      "  ConvTranspose1d-96               [-1, 512, 8]       1,049,088\n",
      "      BatchNorm1d-97               [-1, 512, 8]           1,024\n",
      "              ELU-98               [-1, 512, 8]               0\n",
      "  ConvTranspose1d-99               [-1, 512, 8]         786,944\n",
      "     BatchNorm1d-100               [-1, 512, 8]           1,024\n",
      "             ELU-101               [-1, 512, 8]               0\n",
      " ConvTranspose1d-102              [-1, 2048, 8]       1,050,624\n",
      "     BatchNorm1d-103              [-1, 2048, 8]           4,096\n",
      "             ELU-104              [-1, 2048, 8]               0\n",
      "Decoder_Bottleneck-105              [-1, 2048, 8]               0\n",
      " ConvTranspose1d-106               [-1, 512, 8]       1,049,088\n",
      "     BatchNorm1d-107               [-1, 512, 8]           1,024\n",
      "             ELU-108               [-1, 512, 8]               0\n",
      " ConvTranspose1d-109              [-1, 512, 15]         786,944\n",
      "     BatchNorm1d-110              [-1, 512, 15]           1,024\n",
      "             ELU-111              [-1, 512, 15]               0\n",
      " ConvTranspose1d-112             [-1, 1024, 15]         525,312\n",
      "     BatchNorm1d-113             [-1, 1024, 15]           2,048\n",
      " ConvTranspose1d-114             [-1, 1024, 15]       2,098,176\n",
      "     BatchNorm1d-115             [-1, 1024, 15]           2,048\n",
      "             ELU-116             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-117             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-118              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-119              [-1, 256, 15]             512\n",
      "             ELU-120              [-1, 256, 15]               0\n",
      " ConvTranspose1d-121              [-1, 256, 15]         196,864\n",
      "     BatchNorm1d-122              [-1, 256, 15]             512\n",
      "             ELU-123              [-1, 256, 15]               0\n",
      " ConvTranspose1d-124             [-1, 1024, 15]         263,168\n",
      "     BatchNorm1d-125             [-1, 1024, 15]           2,048\n",
      "             ELU-126             [-1, 1024, 15]               0\n",
      "Decoder_Bottleneck-127             [-1, 1024, 15]               0\n",
      " ConvTranspose1d-128              [-1, 256, 15]         262,400\n",
      "     BatchNorm1d-129              [-1, 256, 15]             512\n",
      "             ELU-130              [-1, 256, 15]               0\n",
      " ConvTranspose1d-131              [-1, 256, 30]         196,864\n",
      "     BatchNorm1d-132              [-1, 256, 30]             512\n",
      "             ELU-133              [-1, 256, 30]               0\n",
      " ConvTranspose1d-134              [-1, 512, 30]         131,584\n",
      "     BatchNorm1d-135              [-1, 512, 30]           1,024\n",
      " ConvTranspose1d-136              [-1, 512, 30]         524,800\n",
      "     BatchNorm1d-137              [-1, 512, 30]           1,024\n",
      "             ELU-138              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-139              [-1, 512, 30]               0\n",
      " ConvTranspose1d-140              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-141              [-1, 128, 30]             256\n",
      "             ELU-142              [-1, 128, 30]               0\n",
      " ConvTranspose1d-143              [-1, 128, 30]          49,280\n",
      "     BatchNorm1d-144              [-1, 128, 30]             256\n",
      "             ELU-145              [-1, 128, 30]               0\n",
      " ConvTranspose1d-146              [-1, 512, 30]          66,048\n",
      "     BatchNorm1d-147              [-1, 512, 30]           1,024\n",
      "             ELU-148              [-1, 512, 30]               0\n",
      "Decoder_Bottleneck-149              [-1, 512, 30]               0\n",
      " ConvTranspose1d-150              [-1, 128, 30]          65,664\n",
      "     BatchNorm1d-151              [-1, 128, 30]             256\n",
      "             ELU-152              [-1, 128, 30]               0\n",
      " ConvTranspose1d-153              [-1, 128, 60]          49,280\n",
      "     BatchNorm1d-154              [-1, 128, 60]             256\n",
      "             ELU-155              [-1, 128, 60]               0\n",
      " ConvTranspose1d-156              [-1, 256, 60]          33,024\n",
      "     BatchNorm1d-157              [-1, 256, 60]             512\n",
      " ConvTranspose1d-158              [-1, 256, 60]         131,328\n",
      "     BatchNorm1d-159              [-1, 256, 60]             512\n",
      "             ELU-160              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-161              [-1, 256, 60]               0\n",
      " ConvTranspose1d-162               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-163               [-1, 64, 60]             128\n",
      "             ELU-164               [-1, 64, 60]               0\n",
      " ConvTranspose1d-165               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-166               [-1, 64, 60]             128\n",
      "             ELU-167               [-1, 64, 60]               0\n",
      " ConvTranspose1d-168              [-1, 256, 60]          16,640\n",
      "     BatchNorm1d-169              [-1, 256, 60]             512\n",
      "             ELU-170              [-1, 256, 60]               0\n",
      "Decoder_Bottleneck-171              [-1, 256, 60]               0\n",
      " ConvTranspose1d-172               [-1, 64, 60]          16,448\n",
      "     BatchNorm1d-173               [-1, 64, 60]             128\n",
      "             ELU-174               [-1, 64, 60]               0\n",
      " ConvTranspose1d-175               [-1, 64, 60]          12,352\n",
      "     BatchNorm1d-176               [-1, 64, 60]             128\n",
      "             ELU-177               [-1, 64, 60]               0\n",
      " ConvTranspose1d-178               [-1, 13, 60]             845\n",
      "================================================================\n",
      "Total params: 21,621,837\n",
      "Trainable params: 21,621,837\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 12.41\n",
      "Params size (MB): 82.48\n",
      "Estimated Total Size (MB): 94.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from ResNet_Autoencoder_Model_Baseline_2 import ResNet_Autoencoder\n",
    "\n",
    "channels = 13\n",
    "\n",
    "# Build model\n",
    "model = ResNet_Autoencoder(channels)\n",
    "model.load_state_dict(torch.load('../../melee_project_data/baseline_2_60s_autoencoder_weights.pt'))\n",
    "model.to('cuda')\n",
    "# # With the size of an input we can get a model summary.\n",
    "summary(model, input_size=(channels, 60))\n",
    "\n",
    "# Check that the output shape and target shape match\n",
    "# training_example = torch.rand(9, 2 ** 12).to('cuda')\n",
    "# print('Target shape:', training_example.shape)\n",
    "# model.eval()\n",
    "# output = model(training_example)\n",
    "# print('Output shape:', output.shape)\n",
    "\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "# Pepare data loaders\n",
    "batch_size =  32 * 16 * 4\n",
    "num_workers = 22\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "\n",
    "# class CustomLoss2(nn.Module):\n",
    "    # def __init__(self, weight_analog=1.0, weight_digital=1.0):\n",
    "    #     super(CustomLoss2, self).__init__()\n",
    "    #     self.BCE = nn.BCEWithLogitsLoss(reduction='sum')  # Consider using weighted BCE if needed\n",
    "    #     self.MSE = nn.MSELoss(reduction='sum')\n",
    "    #     self.weight_analog = weight_analog\n",
    "    #     self.weight_digital = weight_digital\n",
    "\n",
    "    # def forward(self, pred, target):\n",
    "    #     # Applying sigmoid to analog outputs to ensure they are in [0, 1]\n",
    "    #     pred_analog = torch.sigmoid(pred[:4])\n",
    "    #     target_analog = target[:4]\n",
    "        \n",
    "    #     # Calculating losses\n",
    "    #     mse_loss = self.MSE(pred_analog, target_analog) * self.weight_analog\n",
    "    #     bce_loss = self.BCE(pred[4:], target[4:]) * self.weight_digital\n",
    "        \n",
    "    #     # Total loss\n",
    "    #     return mse_loss + bce_loss\n",
    "    \n",
    "# class CustomLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CustomLoss, self).__init__()\n",
    "#         self.BCE = nn.BCEWithLogitsLoss(reduction='sum')  # Consider using weighted BCE if needed\n",
    "#         self.MSE = nn.MSELoss(reduction='sum')\n",
    "\n",
    "#     def forward(self, pred, target):\n",
    "#         # Calculating losses\n",
    "#         mse_loss = self.MSE(torch.sigmoid(pred[0:4]), target[0:4]) \n",
    "#         bce_loss = self.BCE(pred[4:13], target[4:13])\n",
    "        \n",
    "#         # Total loss\n",
    "#         return mse_loss + bce_loss\n",
    "    \n",
    "# class LpLoss(nn.Module):\n",
    "#     def __init__(self, p):\n",
    "#         super(LpLoss, self).__init__()\n",
    "#         self.p = p\n",
    "#     def forward(self, pred, target):\n",
    "#         return torch.sum(torch.abs(torch.sigmoid(pred) - target) ** self.p)\n",
    "    \n",
    "criterion = nn.MSELoss(reduction = 'sum')\n",
    "# criterion = CustomLoss()\n",
    "# \n",
    "# criterion = nn.MSELoss(reduction = 'sum')\n",
    "# criterion = CustomLoss(batch_size)\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs = 5\n",
    "\n",
    "# This seems to sometimes help\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Train the model\n",
    "# start_time = time.time()\n",
    "# train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# print(f'Batch Size: {batch_size}, Training time: {time.time() - start_time:.2f}')\n",
    "\n",
    "# Again, this sometimes seems to help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# Evaluate the trained model\n",
    "# evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "# num_epochs = 10\n",
    "\n",
    "# # This seems to sometimes help\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "# # Train the model\n",
    "# # start_time = time.time()\n",
    "# # train_model(model, criterion, optimizer, loaders, 'cuda', num_epochs)\n",
    "# train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), '../../melee_project_data/baseline_2_complicated_2_60s_autoencoder_weights.pt')\n",
    "# torch.save(model, '../../melee_project_data/baseline_2_complicated_2_60s_autoencoder_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(model, criterion, loaders, 'test', 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, loaders, loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        eval_loader_tqdm = tqdm(loaders[loader], unit='batch')\n",
    "        \n",
    "        for _, target_cpu in enumerate(eval_loader_tqdm):\n",
    "            target_gpu = target_cpu.to(device)\n",
    "            output_gpu = model(target_gpu)\n",
    "            # output_gpu = torch.sigmoid(output_gpu)\n",
    "            \n",
    "            predictions.append(output_gpu.cpu().numpy())\n",
    "            targets.append(target_cpu.numpy())\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    targets = np.concatenate(targets, axis=0)\n",
    "    \n",
    "    \n",
    "\n",
    "    return predictions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:57<00:00,  5.71batch/s]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pred, target = predict(model, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       TRIGGER_LOGICAL_first_frame_target  TRIGGER_LOGICAL_first_frame_pred  \\\n",
      "count                       671279.000000                     671279.000000   \n",
      "mean                             0.166922                          0.167579   \n",
      "std                              0.372906                          0.373492   \n",
      "min                              0.000000                          0.000000   \n",
      "25%                              0.000000                          0.000000   \n",
      "50%                              0.000000                          0.000000   \n",
      "75%                              0.000000                          0.000000   \n",
      "max                              1.000000                          1.000000   \n",
      "\n",
      "       TRIGGER_LOGICAL_last_frame_target  TRIGGER_LOGICAL_last_frame_pred  \\\n",
      "count                      671279.000000                    671279.000000   \n",
      "mean                            0.167255                         0.167382   \n",
      "std                             0.373204                         0.373317   \n",
      "min                             0.000000                         0.000000   \n",
      "25%                             0.000000                         0.000000   \n",
      "50%                             0.000000                         0.000000   \n",
      "75%                             0.000000                         0.000000   \n",
      "max                             1.000000                         1.000000   \n",
      "\n",
      "       TRIGGER_LOGICAL_num_presses_target  TRIGGER_LOGICAL_num_presses_pred  \\\n",
      "count                       671279.000000                     671279.000000   \n",
      "mean                             0.758769                          0.752237   \n",
      "std                              0.763937                          0.755201   \n",
      "min                              0.000000                          0.000000   \n",
      "25%                              0.000000                          0.000000   \n",
      "50%                              1.000000                          1.000000   \n",
      "75%                              1.000000                          1.000000   \n",
      "max                              9.000000                          7.000000   \n",
      "\n",
      "       Z_first_frame_target  Z_first_frame_pred  Z_last_frame_target  \\\n",
      "count         671279.000000       671279.000000        671279.000000   \n",
      "mean               0.009174            0.007082             0.009218   \n",
      "std                0.095338            0.083856             0.095568   \n",
      "min                0.000000            0.000000             0.000000   \n",
      "25%                0.000000            0.000000             0.000000   \n",
      "50%                0.000000            0.000000             0.000000   \n",
      "75%                0.000000            0.000000             0.000000   \n",
      "max                1.000000            1.000000             1.000000   \n",
      "\n",
      "       Z_last_frame_pred  ...  B_last_frame_target  B_last_frame_pred  \\\n",
      "count      671279.000000  ...        671279.000000      671279.000000   \n",
      "mean            0.008484  ...             0.044804           0.044098   \n",
      "std             0.091716  ...             0.206874           0.205313   \n",
      "min             0.000000  ...             0.000000           0.000000   \n",
      "25%             0.000000  ...             0.000000           0.000000   \n",
      "50%             0.000000  ...             0.000000           0.000000   \n",
      "75%             0.000000  ...             0.000000           0.000000   \n",
      "max             1.000000  ...             1.000000           1.000000   \n",
      "\n",
      "       B_num_presses_target  B_num_presses_pred  X_or_Y_first_frame_target  \\\n",
      "count         671279.000000       671279.000000              671279.000000   \n",
      "mean               0.319398            0.303976                   0.098758   \n",
      "std                0.726779            0.694384                   0.298337   \n",
      "min                0.000000            0.000000                   0.000000   \n",
      "25%                0.000000            0.000000                   0.000000   \n",
      "50%                0.000000            0.000000                   0.000000   \n",
      "75%                0.000000            0.000000                   0.000000   \n",
      "max               16.000000           11.000000                   1.000000   \n",
      "\n",
      "       X_or_Y_first_frame_pred  X_or_Y_last_frame_target  \\\n",
      "count            671279.000000             671279.000000   \n",
      "mean                  0.088564                  0.098536   \n",
      "std                   0.284113                  0.298038   \n",
      "min                   0.000000                  0.000000   \n",
      "25%                   0.000000                  0.000000   \n",
      "50%                   0.000000                  0.000000   \n",
      "75%                   0.000000                  0.000000   \n",
      "max                   1.000000                  1.000000   \n",
      "\n",
      "       X_or_Y_last_frame_pred  X_or_Y_num_presses_target  \\\n",
      "count           671279.000000              671279.000000   \n",
      "mean                 0.080321                   0.902845   \n",
      "std                  0.271790                   0.926216   \n",
      "min                  0.000000                   0.000000   \n",
      "25%                  0.000000                   0.000000   \n",
      "50%                  0.000000                   1.000000   \n",
      "75%                  0.000000                   1.000000   \n",
      "max                  1.000000                  12.000000   \n",
      "\n",
      "       X_or_Y_num_presses_pred  \n",
      "count            671279.000000  \n",
      "mean                  0.878355  \n",
      "std                   0.914485  \n",
      "min                   0.000000  \n",
      "25%                   0.000000  \n",
      "50%                   1.000000  \n",
      "75%                   1.000000  \n",
      "max                  10.000000  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "def predicted_button_analysis(pred, target):\n",
    "    buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "    \n",
    "    # Create dictionary to hold the data\n",
    "    data = {}\n",
    "    \n",
    "    # Process for first frame and last frame for both target and pred\n",
    "    for index, button in enumerate(buttons):\n",
    "        data[f'{button}_first_frame_target'] = (target[:, -5+index, 0] > .5).astype(int)\n",
    "        data[f'{button}_first_frame_pred'] = (pred[:, -5+index, 0] > .5).astype(int)\n",
    "        data[f'{button}_last_frame_target'] = (target[:, -5+index, -1] > .5).astype(int)\n",
    "        data[f'{button}_last_frame_pred'] = (pred[:, -5+index, -1] > .5).astype(int)\n",
    "        \n",
    "        # Ensure that the dimensions match for prepend operation\n",
    "        prepend_target = np.expand_dims(target[:, -5+index, 0], axis=1)\n",
    "        prepend_pred = np.expand_dims(pred[:, -5+index, 0], axis=1)\n",
    "\n",
    "        transitions_target = np.diff(target[:, -5+index, :], axis=1, prepend=prepend_target)\n",
    "        transitions_pred = np.diff(pred[:, -5+index, :], axis=1, prepend=prepend_pred)\n",
    "        \n",
    "        count_0_to_1_target = np.sum(transitions_target > .5, axis=1)\n",
    "        count_0_to_1_target += target[:,-5+index,0] > .5\n",
    "        count_0_to_1_pred = np.sum(transitions_pred > .5, axis=1)\n",
    "        count_0_to_1_pred += pred[:,-5+index,0] > .5\n",
    "        \n",
    "        data[f'{button}_num_presses_target'] = count_0_to_1_target\n",
    "        data[f'{button}_num_presses_pred'] = count_0_to_1_pred\n",
    "        \n",
    "    # Create DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# Assuming 'pred' and 'target' are defined and appropriate for this function\n",
    "df = predicted_button_analysis(pred, target)\n",
    "print(df.describe())\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TRIGGER_LOGICAL -----\n",
      "\n",
      "Pressed 0 times\n",
      "    Count\n",
      "0  281867\n",
      "1      18\n",
      "Accuracy: 0.9999\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "     Count\n",
      "-1     865\n",
      " 0  281480\n",
      " 1     118\n",
      "Accuracy: 0.9965\n",
      "Under-prediction rate: 0.8800\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2     71\n",
      "-1   1896\n",
      " 0  93067\n",
      " 1     70\n",
      " 2      1\n",
      "Accuracy: 0.9786\n",
      "Under-prediction rate: 0.9652\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3     10\n",
      "-2     82\n",
      "-1    886\n",
      " 0   9840\n",
      " 1     17\n",
      "Accuracy: 0.9082\n",
      "Under-prediction rate: 0.9829\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-4      3\n",
      "-3     21\n",
      "-2     55\n",
      "-1    176\n",
      " 0    585\n",
      " 1      1\n",
      "Accuracy: 0.6956\n",
      "Under-prediction rate: 0.9961\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-5      1\n",
      "-4      7\n",
      "-3     15\n",
      "-2     24\n",
      "-1     25\n",
      " 0     38\n",
      "Accuracy: 0.3455\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-6      2\n",
      "-5      4\n",
      "-4      4\n",
      "-3      4\n",
      "-2      5\n",
      "-1      6\n",
      " 0      4\n",
      "Accuracy: 0.1379\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "----- Z -----\n",
      "\n",
      "Pressed 0 times\n",
      "    Count\n",
      "0  624151\n",
      "1     124\n",
      "2       2\n",
      "Accuracy: 0.9998\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "    Count\n",
      "-1   3492\n",
      " 0  35927\n",
      " 1     35\n",
      "Accuracy: 0.9106\n",
      "Under-prediction rate: 0.9901\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2    144\n",
      "-1    943\n",
      " 0   4008\n",
      " 1      6\n",
      "Accuracy: 0.7857\n",
      "Under-prediction rate: 0.9945\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3     25\n",
      "-2     90\n",
      "-1    342\n",
      " 0   1016\n",
      " 1      3\n",
      "Accuracy: 0.6883\n",
      "Under-prediction rate: 0.9935\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-4      7\n",
      "-3     14\n",
      "-2     46\n",
      "-1    139\n",
      " 0    397\n",
      " 1      2\n",
      "Accuracy: 0.6562\n",
      "Under-prediction rate: 0.9904\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-5      3\n",
      "-4      2\n",
      "-3      9\n",
      "-2     18\n",
      "-1     51\n",
      " 0    108\n",
      "Accuracy: 0.5654\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-5      4\n",
      "-4      6\n",
      "-3      3\n",
      "-2      9\n",
      "-1     19\n",
      " 0     56\n",
      "Accuracy: 0.5773\n",
      "Under-prediction rate: 1.0000\n",
      "\n",
      "----- A -----\n",
      "\n",
      "Pressed 0 times\n",
      "    Count\n",
      "0  446246\n",
      "1      71\n",
      "Accuracy: 0.9998\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "     Count\n",
      "-1    5852\n",
      " 0  140407\n",
      " 1     240\n",
      " 2       4\n",
      "Accuracy: 0.9584\n",
      "Under-prediction rate: 0.9600\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2    179\n",
      "-1   3412\n",
      " 0  46440\n",
      " 1     94\n",
      " 2      1\n",
      "Accuracy: 0.9265\n",
      "Under-prediction rate: 0.9742\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3     41\n",
      "-2    226\n",
      "-1   1739\n",
      " 0  15423\n",
      " 1     33\n",
      " 2      3\n",
      "Accuracy: 0.8831\n",
      "Under-prediction rate: 0.9824\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-4     17\n",
      "-3     66\n",
      "-2    150\n",
      "-1    843\n",
      " 0   5699\n",
      " 1     13\n",
      "Accuracy: 0.8396\n",
      "Under-prediction rate: 0.9881\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-5     11\n",
      "-4     42\n",
      "-3     50\n",
      "-2     88\n",
      "-1    370\n",
      " 0   1822\n",
      " 1      3\n",
      "Accuracy: 0.7636\n",
      "Under-prediction rate: 0.9947\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-6      7\n",
      "-5     19\n",
      "-4     23\n",
      "-3     32\n",
      "-2     50\n",
      "-1    148\n",
      " 0    716\n",
      " 1      1\n",
      "Accuracy: 0.7189\n",
      "Under-prediction rate: 0.9964\n",
      "\n",
      "----- B -----\n",
      "\n",
      "Pressed 0 times\n",
      "    Count\n",
      "0  519471\n",
      "1     203\n",
      "2       1\n",
      "Accuracy: 0.9996\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "     Count\n",
      "-1    4387\n",
      " 0  107043\n",
      " 1     504\n",
      " 2      11\n",
      " 3       1\n",
      "Accuracy: 0.9562\n",
      "Under-prediction rate: 0.8948\n",
      "\n",
      "Pressed 2 times\n",
      "    Count\n",
      "-2    321\n",
      "-1   1767\n",
      " 0  24064\n",
      " 1    129\n",
      " 2      3\n",
      "Accuracy: 0.9155\n",
      "Under-prediction rate: 0.9405\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3    171\n",
      "-2    168\n",
      "-1    782\n",
      " 0   6862\n",
      " 1     28\n",
      "Accuracy: 0.8566\n",
      "Under-prediction rate: 0.9756\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-4     86\n",
      "-3     57\n",
      "-2     70\n",
      "-1    313\n",
      " 0   2515\n",
      " 1     16\n",
      " 2      1\n",
      "Accuracy: 0.8224\n",
      "Under-prediction rate: 0.9687\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-5     50\n",
      "-4     27\n",
      "-3     20\n",
      "-2     37\n",
      "-1    145\n",
      " 0    933\n",
      " 1      3\n",
      "Accuracy: 0.7679\n",
      "Under-prediction rate: 0.9894\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-6     32\n",
      "-5     13\n",
      "-4      4\n",
      "-3     16\n",
      "-2     18\n",
      "-1     85\n",
      " 0    414\n",
      " 1      3\n",
      "Accuracy: 0.7077\n",
      "Under-prediction rate: 0.9825\n",
      "\n",
      "----- X_or_Y -----\n",
      "\n",
      "Pressed 0 times\n",
      "    Count\n",
      "0  257016\n",
      "1      87\n",
      "2       1\n",
      "Accuracy: 0.9997\n",
      "Under-prediction rate: 0.0000\n",
      "\n",
      "Pressed 1 times\n",
      "     Count\n",
      "-1    8482\n",
      " 0  253922\n",
      " 1    3622\n",
      " 2     243\n",
      " 3      12\n",
      "Accuracy: 0.9536\n",
      "Under-prediction rate: 0.6863\n",
      "\n",
      "Pressed 2 times\n",
      "     Count\n",
      "-2     281\n",
      "-1    8494\n",
      " 0  107066\n",
      " 1    1623\n",
      " 2      51\n",
      " 3       2\n",
      "Accuracy: 0.9111\n",
      "Under-prediction rate: 0.8396\n",
      "\n",
      "Pressed 3 times\n",
      "    Count\n",
      "-3     22\n",
      "-2    246\n",
      "-1   2455\n",
      " 0  19333\n",
      " 1    261\n",
      " 2     10\n",
      " 3      1\n",
      "Accuracy: 0.8659\n",
      "Under-prediction rate: 0.9092\n",
      "\n",
      "Pressed 4 times\n",
      "    Count\n",
      "-4      5\n",
      "-3     22\n",
      "-2    114\n",
      "-1    618\n",
      " 0   4008\n",
      " 1     27\n",
      "Accuracy: 0.8360\n",
      "Under-prediction rate: 0.9656\n",
      "\n",
      "Pressed 5 times\n",
      "    Count\n",
      "-5      2\n",
      "-4     10\n",
      "-3     21\n",
      "-2     78\n",
      "-1    215\n",
      " 0   1423\n",
      " 1     10\n",
      "Accuracy: 0.8090\n",
      "Under-prediction rate: 0.9702\n",
      "\n",
      "Pressed 6 times\n",
      "    Count\n",
      "-5      3\n",
      "-4     11\n",
      "-3     13\n",
      "-2     41\n",
      "-1    130\n",
      " 0    707\n",
      " 1      2\n",
      "Accuracy: 0.7795\n",
      "Under-prediction rate: 0.9900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "# buttons = ['X_or_Y']\n",
    "\n",
    "\n",
    "summary_df = pd.DataFrame(np.arange(7,dtype=np.int16),columns=['Target Pressed'])\n",
    "# print(summary_df)\n",
    "\n",
    "\n",
    "for index, button in enumerate(buttons):\n",
    "    print('-----', button, '-----')\n",
    "    example_data = []\n",
    "    accuracy_data = []\n",
    "    under_predicted_data = []\n",
    "    for i in range(7):\n",
    "        print()\n",
    "        print(f'Pressed {i} times')\n",
    "        df_button_is_pressed = df[df[f'{button}_num_presses_target'] == i]\n",
    "        columns = [\n",
    "                    f'{button}_first_frame_target',\n",
    "                    f'{button}_first_frame_pred',\n",
    "                    f'{button}_last_frame_target',\n",
    "                    f'{button}_last_frame_pred',\n",
    "                    f'{button}_num_presses_target',\n",
    "                    f'{button}_num_presses_pred']    \n",
    "        df_button_is_pressed = df_button_is_pressed[columns]\n",
    "        \n",
    "        # print(f'Target was pressed {i} time(s): < 0 means under predicting')\n",
    "        df_button_is_pressed['Off by'] = df_button_is_pressed[f'{button}_num_presses_pred'] - df_button_is_pressed[f'{button}_num_presses_target']\n",
    "        counts = df_button_is_pressed['Off by'].value_counts().sort_index().to_frame(name='Count')\n",
    "\n",
    "        # Calculating accuracy\n",
    "        total_presses = counts['Count'].sum()\n",
    "        correct_predictions = counts.loc[0, 'Count'] if 0 in counts.index else 0\n",
    "        accuracy = correct_predictions / total_presses if total_presses > 0 else 0\n",
    "        print(counts)\n",
    "        print('Accuracy:', \"{:.4f}\".format(accuracy))\n",
    "        accuracy_data += [accuracy]\n",
    "        \n",
    "                # Calculating under-prediction rate among non-zero predictions\n",
    "        under_predicted = counts[counts.index < 0]['Count'].sum() if any(counts.index < 0) else 0\n",
    "        non_zero_predictions = total_presses - (counts.loc[0, 'Count'] if 0 in counts.index else 0)\n",
    "        under_prediction_rate = under_predicted / non_zero_predictions if non_zero_predictions > 0 else 0\n",
    "        print(f'Under-prediction rate: {under_prediction_rate:.4f}')\n",
    "        under_predicted_data += [under_prediction_rate]\n",
    "        \n",
    "        example_data += [df_button_is_pressed.shape[0] / df.shape[0]]\n",
    "        \n",
    "    print()\n",
    "        \n",
    "    summary_df[f'{button} Examples'] = example_data\n",
    "    summary_df[f'{button} Correct'] = accuracy_data\n",
    "    summary_df[f'{button} Under'] = under_predicted_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table shows:\n",
      "- The percentage of test examples that were actually pressed n times.\n",
      "- Accuracy of the prediction given the button was pressed n times.\n",
      "- Under prediction rate of an incorrect prediction given the button was pressed n times.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Pressed</th>\n",
       "      <th>TRIGGER_LOGICAL Examples</th>\n",
       "      <th>TRIGGER_LOGICAL Correct</th>\n",
       "      <th>TRIGGER_LOGICAL Under</th>\n",
       "      <th>Z Examples</th>\n",
       "      <th>Z Correct</th>\n",
       "      <th>Z Under</th>\n",
       "      <th>A Examples</th>\n",
       "      <th>A Correct</th>\n",
       "      <th>A Under</th>\n",
       "      <th>B Examples</th>\n",
       "      <th>B Correct</th>\n",
       "      <th>B Under</th>\n",
       "      <th>X_or_Y Examples</th>\n",
       "      <th>X_or_Y Correct</th>\n",
       "      <th>X_or_Y Under</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.419922</td>\n",
       "      <td>0.999936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.929981</td>\n",
       "      <td>0.999798</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.664876</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.774156</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.383006</td>\n",
       "      <td>0.999658</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.420783</td>\n",
       "      <td>0.996520</td>\n",
       "      <td>0.879959</td>\n",
       "      <td>0.058774</td>\n",
       "      <td>0.910605</td>\n",
       "      <td>0.990077</td>\n",
       "      <td>0.218245</td>\n",
       "      <td>0.958390</td>\n",
       "      <td>0.959974</td>\n",
       "      <td>0.166765</td>\n",
       "      <td>0.956202</td>\n",
       "      <td>0.894758</td>\n",
       "      <td>0.396677</td>\n",
       "      <td>0.953587</td>\n",
       "      <td>0.686301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.141677</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>0.007599</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>0.994511</td>\n",
       "      <td>0.074672</td>\n",
       "      <td>0.926465</td>\n",
       "      <td>0.974227</td>\n",
       "      <td>0.039155</td>\n",
       "      <td>0.915538</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.175064</td>\n",
       "      <td>0.911068</td>\n",
       "      <td>0.839633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.016141</td>\n",
       "      <td>0.908168</td>\n",
       "      <td>0.982915</td>\n",
       "      <td>0.002199</td>\n",
       "      <td>0.688347</td>\n",
       "      <td>0.993478</td>\n",
       "      <td>0.026017</td>\n",
       "      <td>0.883080</td>\n",
       "      <td>0.982370</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.856572</td>\n",
       "      <td>0.975631</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.865863</td>\n",
       "      <td>0.909182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.695600</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.656198</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.010112</td>\n",
       "      <td>0.839570</td>\n",
       "      <td>0.988062</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.822433</td>\n",
       "      <td>0.968692</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.836045</td>\n",
       "      <td>0.965649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.565445</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.763621</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.808982</td>\n",
       "      <td>0.970238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.718876</td>\n",
       "      <td>0.996429</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.779493</td>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target Pressed  TRIGGER_LOGICAL Examples  TRIGGER_LOGICAL Correct  \\\n",
       "0               0                  0.419922                 0.999936   \n",
       "1               1                  0.420783                 0.996520   \n",
       "2               2                  0.141677                 0.978571   \n",
       "3               3                  0.016141                 0.908168   \n",
       "4               4                  0.001253                 0.695600   \n",
       "5               5                  0.000164                 0.345455   \n",
       "6               6                  0.000043                 0.137931   \n",
       "\n",
       "   TRIGGER_LOGICAL Under  Z Examples  Z Correct   Z Under  A Examples  \\\n",
       "0               0.000000    0.929981   0.999798  0.000000    0.664876   \n",
       "1               0.879959    0.058774   0.910605  0.990077    0.218245   \n",
       "2               0.965162    0.007599   0.785728  0.994511    0.074672   \n",
       "3               0.982915    0.002199   0.688347  0.993478    0.026017   \n",
       "4               0.996094    0.000901   0.656198  0.990385    0.010112   \n",
       "5               1.000000    0.000285   0.565445  1.000000    0.003554   \n",
       "6               1.000000    0.000145   0.577320  1.000000    0.001484   \n",
       "\n",
       "   A Correct   A Under  B Examples  B Correct   B Under  X_or_Y Examples  \\\n",
       "0   0.999841  0.000000    0.774156   0.999607  0.000000         0.383006   \n",
       "1   0.958390  0.959974    0.166765   0.956202  0.894758         0.396677   \n",
       "2   0.926465  0.974227    0.039155   0.915538  0.940541         0.175064   \n",
       "3   0.883080  0.982370    0.011934   0.856572  0.975631         0.033262   \n",
       "4   0.839570  0.988062    0.004555   0.822433  0.968692         0.007142   \n",
       "5   0.763621  0.994681    0.001810   0.767901  0.989362         0.002620   \n",
       "6   0.718876  0.996429    0.000871   0.707692  0.982456         0.001351   \n",
       "\n",
       "   X_or_Y Correct  X_or_Y Under  \n",
       "0        0.999658      0.000000  \n",
       "1        0.953587      0.686301  \n",
       "2        0.911068      0.839633  \n",
       "3        0.865863      0.909182  \n",
       "4        0.836045      0.965649  \n",
       "5        0.808982      0.970238  \n",
       "6        0.779493      0.990000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Table shows:')\n",
    "print('- The percentage of test examples that were actually pressed n times.')\n",
    "print('- Accuracy of the prediction given the button was pressed n times.')\n",
    "print('- Under prediction rate of an incorrect prediction given the button was pressed n times.')           \n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table shows:\n",
      "- Percentage of test examples where the button was not pressed on the first or last frame\n",
      "- Given the button was pressed or not on the first or last frame, what was the accuracy of the prediction.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Button</th>\n",
       "      <th>Ratio target[0]==0</th>\n",
       "      <th>Acc target[0]==0</th>\n",
       "      <th>Acc target[0]==1</th>\n",
       "      <th>Ratio target[-1]==0</th>\n",
       "      <th>Acc target[-1]==0</th>\n",
       "      <th>Acc target[-1]==1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRIGGER_LOGICAL</td>\n",
       "      <td>0.833078</td>\n",
       "      <td>0.998709</td>\n",
       "      <td>0.997492</td>\n",
       "      <td>0.832745</td>\n",
       "      <td>0.998825</td>\n",
       "      <td>0.994905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z</td>\n",
       "      <td>0.990826</td>\n",
       "      <td>0.999904</td>\n",
       "      <td>0.761611</td>\n",
       "      <td>0.990782</td>\n",
       "      <td>0.999902</td>\n",
       "      <td>0.909825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.937960</td>\n",
       "      <td>0.999500</td>\n",
       "      <td>0.888225</td>\n",
       "      <td>0.937503</td>\n",
       "      <td>0.999498</td>\n",
       "      <td>0.940934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.955071</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.839224</td>\n",
       "      <td>0.955196</td>\n",
       "      <td>0.999312</td>\n",
       "      <td>0.969577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>X_or_Y</td>\n",
       "      <td>0.901242</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.891649</td>\n",
       "      <td>0.901464</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.810311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Button  Ratio target[0]==0  Acc target[0]==0  Acc target[0]==1  \\\n",
       "0  TRIGGER_LOGICAL            0.833078          0.998709          0.997492   \n",
       "1                Z            0.990826          0.999904          0.761611   \n",
       "2                A            0.937960          0.999500          0.888225   \n",
       "3                B            0.955071          0.999819          0.839224   \n",
       "4           X_or_Y            0.901242          0.999438          0.891649   \n",
       "\n",
       "   Ratio target[-1]==0  Acc target[-1]==0  Acc target[-1]==1  \n",
       "0             0.832745           0.998825           0.994905  \n",
       "1             0.990782           0.999902           0.909825  \n",
       "2             0.937503           0.999498           0.940934  \n",
       "3             0.955196           0.999312           0.969577  \n",
       "4             0.901464           0.999471           0.810311  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "\n",
    "first_and_last_df = pd.DataFrame(buttons, columns=['Button'])\n",
    "for index, button in enumerate(buttons):\n",
    "    first_frame_0 = (df[f'{button}_first_frame_target'] == 0)\n",
    "    last_frame_0 = (df[f'{button}_last_frame_target'] == 0)\n",
    "    \n",
    "    first_and_last_df.loc[index, 'Ratio target[0]==0'] = first_frame_0.mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[0]==0'] = 1 - df.loc[first_frame_0, f'{button}_first_frame_pred'].mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[0]==1'] = df.loc[~first_frame_0, f'{button}_first_frame_pred'].mean()\n",
    "    \n",
    "    first_and_last_df.loc[index, 'Ratio target[-1]==0'] = last_frame_0.mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[-1]==0'] = 1-df.loc[last_frame_0, f'{button}_last_frame_pred'].mean()\n",
    "    first_and_last_df.loc[index, 'Acc target[-1]==1'] = df.loc[~last_frame_0, f'{button}_last_frame_pred'].mean()\n",
    "    \n",
    "print('Table shows:')\n",
    "print('- Percentage of test examples where the button was not pressed on the first or last frame')\n",
    "print('- Given the button was pressed or not on the first or last frame, what was the accuracy of the prediction.')\n",
    "\n",
    "first_and_last_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the target button was pressed once and the prediction was pressed once. How big was the difference in length of the button press. TO DO: further restrict to the prediction being pressed for the same number of frames and seeing if it was pressed at the exact same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIGGER_LOGICAL\n",
      "[[    -5      1]\n",
      " [    -4      1]\n",
      " [    -3      2]\n",
      " [    -2     85]\n",
      " [    -1   8953]\n",
      " [     0 270835]\n",
      " [     1   1568]\n",
      " [     2     18]\n",
      " [     3      9]\n",
      " [     4      6]\n",
      " [     5      2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z\n",
      "[[   -4     4]\n",
      " [   -3    12]\n",
      " [   -2   294]\n",
      " [   -1  3292]\n",
      " [    0 32033]\n",
      " [    1   257]\n",
      " [    2    27]\n",
      " [    4     1]\n",
      " [    5     2]\n",
      " [    7     2]\n",
      " [   15     1]\n",
      " [   19     1]\n",
      " [   26     1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[  -11     1]\n",
      " [   -7     3]\n",
      " [   -5     1]\n",
      " [   -4     6]\n",
      " [   -3    32]\n",
      " [   -2  6808]\n",
      " [   -1 33319]\n",
      " [    0 99820]\n",
      " [    1   385]\n",
      " [    2    19]\n",
      " [    3     2]\n",
      " [    4     4]\n",
      " [    5     1]\n",
      " [   19     1]\n",
      " [   21     1]\n",
      " [   22     1]\n",
      " [   28     1]\n",
      " [   32     1]\n",
      " [   36     1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n",
      "[[   -7     1]\n",
      " [   -6     2]\n",
      " [   -5    11]\n",
      " [   -4    25]\n",
      " [   -3    73]\n",
      " [   -2  2089]\n",
      " [   -1 20877]\n",
      " [    0 82653]\n",
      " [    1  1249]\n",
      " [    2    23]\n",
      " [    3    10]\n",
      " [    4     6]\n",
      " [    5     1]\n",
      " [    6     4]\n",
      " [    7     2]\n",
      " [    8     1]\n",
      " [    9     2]\n",
      " [   13     1]\n",
      " [   14     1]\n",
      " [   17     1]\n",
      " [   25     2]\n",
      " [   27     1]\n",
      " [   28     1]\n",
      " [   31     2]\n",
      " [   34     1]\n",
      " [   35     1]\n",
      " [   36     1]\n",
      " [   43     1]\n",
      " [   55     1]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_or_Y\n",
      "[[    -5      1]\n",
      " [    -4      4]\n",
      " [    -3     44]\n",
      " [    -2   7102]\n",
      " [    -1  67535]\n",
      " [     0 178454]\n",
      " [     1    731]\n",
      " [     2     18]\n",
      " [     3      4]\n",
      " [     4      3]\n",
      " [     5      5]\n",
      " [     6      1]\n",
      " [    10      1]\n",
      " [    12      1]\n",
      " [    13      1]\n",
      " [    14      2]\n",
      " [    15      2]\n",
      " [    18      2]\n",
      " [    22      1]\n",
      " [    24      1]\n",
      " [    25      1]\n",
      " [    27      1]\n",
      " [    28      1]\n",
      " [    29      1]\n",
      " [    34      1]\n",
      " [    42      1]\n",
      " [    59      3]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buttons = ['TRIGGER_LOGICAL', 'Z', 'A', 'B', 'X_or_Y']\n",
    "results = []\n",
    "\n",
    "for index, button in enumerate(buttons):\n",
    "    button_is_pressed_once = (df[f'{button}_num_presses_target'] == 1) & (df[f'{button}_num_presses_pred'] == 1)\n",
    "    \n",
    "    \n",
    "    # Filtering rows where the button was pressed exactly once in both target and prediction\n",
    "    target_button_is_pressed_once = target[button_is_pressed_once, -5+index, :]\n",
    "    pred_button_is_pressed_once = pred[button_is_pressed_once, -5+index, :]\n",
    "    \n",
    "    # Calculating indices for the first and last button press in the target and prediction for each example\n",
    "    index_of_first_1_target = np.argmax(target_button_is_pressed_once > 0.5, axis=1)\n",
    "    index_of_first_1_pred = np.argmax(pred_button_is_pressed_once > 0.5, axis=1)\n",
    "    index_of_last_1_target = (target_button_is_pressed_once.shape[1] - np.argmax(target_button_is_pressed_once[:, ::-1] > 0.5, axis=1))\n",
    "    index_of_last_1_pred = (pred_button_is_pressed_once.shape[1] - np.argmax(pred_button_is_pressed_once[:, ::-1] > 0.5, axis=1))\n",
    "\n",
    "    length_of_target_press = index_of_last_1_target - index_of_first_1_target\n",
    "    length_of_pred_press = index_of_last_1_pred - index_of_first_1_pred\n",
    "    \n",
    "    unique, count = np.unique(length_of_pred_press - length_of_target_press, return_counts=True)\n",
    "    print(button)\n",
    "    print(np.array([unique,count]).T)\n",
    "\n",
    "    plt.bar(unique,np.log(count+1))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the differece in the angle of the joystick and c-stick.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Transform the target back to the the standard stick input. \n",
    "# # 9 channels\n",
    "# target_no_transform = target[:, :4, :] - .5\n",
    "# target_no_transform[0:4, :] /= 1.40350877193 / 2\n",
    "# target_no_transform -= .2875 * (target_no_transform[:, 0:4, :] < 0)\n",
    "# target_no_transform += .2875 * (target_no_transform[:, 0:4, :] > 0)\n",
    "# target_no_transform *= target[:,4:8,:]\n",
    " \n",
    "# predicted_no_transform = pred[:, :4, :] - .5\n",
    "# predicted_no_transform[0:4, :] /= 1.40350877193 / 2\n",
    "# predicted_no_transform -= .2875 * (predicted_no_transform[:, 0:4, :] < 0)\n",
    "# predicted_no_transform += .2875 * (predicted_no_transform[:, 0:4, :] > 0)\n",
    "# predicted_no_transform *= pred[:,4:8,:]\n",
    "\n",
    "# target_angle_JSTICK = np.arctan2(target_no_transform[:,0,:], target_no_transform[:,1,:]) * 180 / np.pi\n",
    "# predicted_angle_JSTICK = np.arctan2(predicted_no_transform[:,0,:], predicted_no_transform[:,1,:]) * 180 / np.pi\n",
    "\n",
    "# target_radius_JSTICK = np.sqrt(target_no_transform[:,0,:] ** 2 + target_no_transform[:,1,:] ** 2)\n",
    "# pred_radius_JSTICK = np.sqrt(predicted_no_transform[:,0,:] ** 2 + predicted_no_transform[:,1,:] ** 2)\n",
    "\n",
    "# print(target_no_transform[:,0,:])\n",
    "# # # print(target_no_transform[:,1,:])\n",
    "# print()\n",
    "\n",
    "# print(predicted_no_transform[:,0,:])\n",
    "# # # print(predicted_no_transform[:,1,:])\n",
    "# # print()\n",
    "\n",
    "# # print(target_angle_JSTICK)\n",
    "# # print(predicted_angle_JSTICK)\n",
    "# # print()\n",
    "\n",
    "# # print(target_radius_JSTICK)\n",
    "# # print(pred_radius_JSTICK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasform the stick predictions back to the original inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSTICK average angle 2.735158\n",
      "CSTICK average angle 0.4362916\n",
      "JSTICK average radius 0.03758354\n",
      "CSTICK average radius 0.0048903665\n"
     ]
    }
   ],
   "source": [
    "target_sticks_no_transform = target[:, :4] - .5\n",
    "target_sticks_no_transform /= 1.40350877193 / 2\n",
    "target_sticks_no_transform[target_sticks_no_transform < 0] -= .2875 \n",
    "target_sticks_no_transform[target_sticks_no_transform < 0] += .2875\n",
    " \n",
    "predicted_sticks_no_transform = pred[:, :4] - .5\n",
    "predicted_sticks_no_transform /= 1.40350877193 / 2\n",
    "predicted_sticks_no_transform[predicted_sticks_no_transform < 0] -= .2875 \n",
    "predicted_sticks_no_transform[predicted_sticks_no_transform < 0] += .2875\n",
    "\n",
    "# Multiply by 0 where the model predicted the stick input to be 0\n",
    "predicted_sticks_no_transform *= (pred[:,4:8] > .5)\n",
    "predicted_sticks_no_transform = np.where(predicted_sticks_no_transform == 0.0, 0.0, predicted_sticks_no_transform)\n",
    "\n",
    "target_angle_JSTICK = np.arctan2(target_sticks_no_transform[:,[1,3]], target_sticks_no_transform[:,[0,2]]) * 180 / np.pi\n",
    "predicted_angle_JSTICK = np.arctan2(predicted_sticks_no_transform[:,[1,3]], predicted_sticks_no_transform[:,[0,2]]) * 180 / np.pi\n",
    "\n",
    "angle_difference_no_transform = (predicted_angle_JSTICK - target_angle_JSTICK) \n",
    "smallest_angle_difference_no_transform = (angle_difference_no_transform + 180) % 360 - 180\n",
    "\n",
    "target_radius_squared_no_transform = target_sticks_no_transform[:,[0,2]] ** 2 + target_sticks_no_transform[:,[1,3]] ** 2\n",
    "pred_radius_squared_no_transform = predicted_sticks_no_transform[:,[0,2]] ** 2 + predicted_sticks_no_transform[:,[1,3]] ** 2\n",
    "\n",
    "radius_difference_no_trasform = target_radius_squared_no_transform - pred_radius_squared_no_transform\n",
    "\n",
    "print('JSTICK average angle', np.average(np.abs(smallest_angle_difference_no_transform[:,0])))\n",
    "print('CSTICK average angle', np.average(np.abs(smallest_angle_difference_no_transform[:,1])))\n",
    "\n",
    "print('JSTICK average radius', np.average(np.abs(radius_difference_no_trasform[:,0])))\n",
    "print('CSTICK average radius', np.average(np.abs(radius_difference_no_trasform[:,1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how accurately the model predicted model predicted each analog input being zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of JSTICK_X = 0: 99.72284251406643\n",
      "Accuracy of JSTICK_Y = 0: 99.674983625785\n",
      "Accuracy of CSTICK_X = 0: 99.85515709563386\n",
      "Accuracy of JSTICK_Y = 0: 99.86762583069037\n"
     ]
    }
   ],
   "source": [
    "correct_zero_stick = (pred[:,4:8] == target[:,4:8])\n",
    "print('Accuracy of JSTICK_X = 0:', np.sum(correct_zero_stick[:,0]) / np.product(pred[:,0].shape) * 100)\n",
    "print('Accuracy of JSTICK_Y = 0:', np.sum(correct_zero_stick[:,1]) / np.product(pred[:,0].shape) * 100)\n",
    "print('Accuracy of CSTICK_X = 0:', np.sum(correct_zero_stick[:,2]) / np.product(pred[:,0].shape) * 100)\n",
    "print('Accuracy of JSTICK_Y = 0:', np.sum(correct_zero_stick[:,3]) / np.product(pred[:,0].shape) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  90.         90.         90.         90.         90.         90.\n",
      "   90.         90.         90.         90.         90.         90.\n",
      "   90.         92.20259    99.09027   104.03623   109.17901   110.69545\n",
      "  110.69545   111.8014    105.15406    90.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.         90.         90.         90.         90.         90.\n",
      "   90.         90.         90.         92.20259    93.301865  101.534615\n",
      "  123.69006   143.61565  -151.29404  -133.2643   -133.2643   -129.80557\n",
      " -128.08878  -122.00537  -113.35556  -101.534615  -93.301865  -90.\n",
      "  -90.        -90.        -90.          0.          0.          0.      ]\n",
      "[  90.         90.         90.         90.         90.         90.\n",
      "   90.         90.         90.         90.         90.         90.\n",
      "   90.         91.2913     95.845436  100.03944   102.635956  105.87255\n",
      "  108.3744    106.48276    95.608246   90.          0.          0.\n",
      "    0.          0.          0.          0.          0.          0.\n",
      "    0.         90.         90.         90.         90.         90.\n",
      "   90.         90.         93.710556  100.5087    105.95462   116.15061\n",
      "  129.9866   -170.62874  -136.20842  -133.50436  -132.61781  -129.43378\n",
      " -130.1502   -127.97756  -123.901024 -114.73182   -96.22061   -90.\n",
      "  -90.        -90.        -90.          0.          0.         90.      ]\n",
      "[  0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.          -0.9112854   -3.2448425\n",
      "  -3.9967957   -6.5430603   -4.8229065   -2.321045    -5.318634\n",
      "  -9.545807     0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           3.710556     8.306107\n",
      "  12.652756    14.615997     6.2965393   45.755615    15.085617\n",
      "  -0.24006653   0.6464844    0.37179565  -2.061432    -5.9721985\n",
      " -10.545471   -13.197205    -2.918747     0.           0.\n",
      "   0.           0.           0.           0.          90.        ]\n"
     ]
    }
   ],
   "source": [
    "target_angle_JSTICK = np.arctan2(target_sticks_no_transform[:,0,:], target_sticks_no_transform[:,1,:]) * 180 / np.pi\n",
    "predicted_angle_JSTICK = np.arctan2(predicted_sticks_no_transform[:,0,:], predicted_sticks_no_transform[:,1,:]) * 180 / np.pi\n",
    "\n",
    "# values= np.unique(target_angle_JSTICK)\n",
    "# print(values)\n",
    "\n",
    "JSTICK_angle_difference = (predicted_angle_JSTICK - target_angle_JSTICK) \n",
    "smallest_JSTICK_angle_difference = (JSTICK_angle_difference + 180) % 360 - 180\n",
    "n = 1\n",
    "# print(target_sticks_no_transform[n,0])\n",
    "# print(target_sticks_no_transform[n,1])\n",
    "# print(1 - (target[n,4] == 1) * (target[n,5] == 1))\n",
    "# print(target_angle_JSTICK[n])\n",
    "# print()\n",
    "# # print(predicted_sticks_no_transform[n,0])\n",
    "# # print(predicted_sticks_no_transform[n,1])\n",
    "# print(1 - (pred[n,4] == 1) * (pred[n,5] == 1))\n",
    "# print(predicted_angle_JSTICK[n])\n",
    "# print()\n",
    "# print(JSTICK_angle_difference[n])\n",
    "# target_radius_JSTICK = np.sqrt(target_no_transform[:,0,:] ** 2 + target_no_transform[:,1,:] ** 2)\n",
    "# pred_radius_JSTICK = np.sqrt(predicted_no_transform[:,0,:] ** 2 + predicted_no_transform[:,1,:] ** 2)\n",
    "\n",
    "# print(smallest_JSTICK_angle_difference[n])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:46<00:00,  7.13batch/s]\n"
     ]
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pred, target = predict(model, loaders, 'test','cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input 0\n",
      "MSE 0.0025101246\n",
      "\n",
      "input 1\n",
      "MSE 0.0016928131\n",
      "\n",
      "input 2\n",
      "MSE 0.0005146101\n",
      "\n",
      "input 3\n",
      "MSE 0.0006452597\n",
      "\n",
      "input 4\n",
      "BCE 0.0254044934258363\n",
      "MSE 0.0030596177\n",
      "\n",
      "input 5\n",
      "BCE 0.018148900799287555\n",
      "MSE 0.0027572268\n",
      "\n",
      "input 6\n",
      "BCE 0.01185297787910739\n",
      "MSE 0.0013353667\n",
      "\n",
      "input 7\n",
      "BCE 0.00623941025660493\n",
      "MSE 0.0011063458\n",
      "\n",
      "input 8\n",
      "BCE 0.011352076268913205\n",
      "MSE 0.000841106\n",
      "\n",
      "input 9\n",
      "BCE 0.003146740100034065\n",
      "MSE 0.0004005649\n",
      "\n",
      "input 10\n",
      "BCE 0.019349793211912127\n",
      "MSE 0.002679755\n",
      "\n",
      "input 11\n",
      "BCE 0.010163735801211961\n",
      "MSE 0.0016366695\n",
      "\n",
      "input 12\n",
      "BCE 0.03219717230195465\n",
      "MSE 0.0054070363\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for i in range(4):\n",
    "    # bce = log_loss(target[:,i,:].flatten(),pred[:,i,:].flatten())\n",
    "    mse = mean_squared_error(target[:,i,:].flatten(),pred[:,i,:].flatten())\n",
    "    print('input',i)\n",
    "    # print('BCE', bce)\n",
    "    print('MSE', mse)\n",
    "    print()\n",
    "    \n",
    "for i in range(4,13):\n",
    "    bce = log_loss(target[:,i,:].flatten(),pred[:,i,:].flatten())\n",
    "    mse = mean_squared_error(target[:,i,:].flatten(),pred[:,i,:].flatten())\n",
    "    print('input',i)\n",
    "    print('BCE', bce)\n",
    "    print('MSE', mse)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSTICK average angle 0.31938794\n",
      "CSTICK average angle 0.5064823\n"
     ]
    }
   ],
   "source": [
    "target_angle = np.arctan2((target[:,[0,2]] - .5) * 2, (target[:,[1,3]] - .5) * 2) #* 180 / np.pi\n",
    "predicted_angle = np.arctan2((pred[:,[0,2]] - .5) * 2, (pred[:,[1,3]] - .5) * 2) #* 180 / np.pi\n",
    "# predicted_angle = np.arctan2(pred[:,[0,2]], pred[:,[1,3]]) * 180 / np.pi\n",
    "\n",
    "angle_difference = (predicted_angle - target_angle) # between -2pi and 2pi\n",
    "smallest_angle_difference = (angle_difference + np.pi) % (2 * np.pi) - np.pi\n",
    "# smallest_angle_difference = (angle_difference + 180) % 360 - 180=\n",
    "\n",
    "# n,i = 4,0\n",
    "# print(target_angle[n,i])\n",
    "# print()\n",
    "# print(predicted_angle[n,i])\n",
    "# print()\n",
    "# print(smallest_angle_difference[n,i])\n",
    "\n",
    "print('JSTICK average angle', np.average(np.abs(smallest_angle_difference[:,0])))\n",
    "print('CSTICK average angle', np.average(np.abs(smallest_angle_difference[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSTICK average angle 0.31938794\n",
      "CSTICK average angle 0.5064823\n"
     ]
    }
   ],
   "source": [
    "target_angle = np.arctan2((target[:,[0,2]] - .5) * 2, (target[:,[1,3]] - .5) * 2) * 180 / np.pi\n",
    "predicted_angle = np.arctan2((pred[:,[0,2]] - .5) * 2, (pred[:,[1,3]] - .5) * 2) * 180 / np.pi\n",
    "# predicted_angle = np.arctan2(pred[:,[0,2]], pred[:,[1,3]]) * 180 / np.pi\n",
    "\n",
    "angle_difference = (predicted_angle - target_angle) # between -2pi and 2pi\n",
    "# smallest_angle_difference = (angle_difference + np.pi) % (2 * np.pi) - np.pi\n",
    "smallest_angle_difference = (angle_difference + 180) % 360 - 180\n",
    "smallest_angle_difference *= (np.pi / 180)\n",
    "\n",
    "# n,i = 4,0\n",
    "# print(target_angle[n,i])\n",
    "# print()\n",
    "# print(predicted_angle[n,i])\n",
    "# print()\n",
    "# print(smallest_angle_difference[n,i])\n",
    "\n",
    "print('JSTICK average angle', np.average(np.abs(smallest_angle_difference[:,0])))\n",
    "print('CSTICK average angle', np.average(np.abs(smallest_angle_difference[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSTICK average angle 0.31938794\n",
      "CSTICK average angle 0.5064823\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSTICK average radius 0.04023463\n",
      "CSTICK average radius 0.022831393\n"
     ]
    }
   ],
   "source": [
    "target_radius_squared = target[:,[0,2]] ** 2 + target[:,[1,3]] ** 2\n",
    "pred_radius_squared = pred[:,[0,2]] ** 2 + pred[:,[1,3]] ** 2\n",
    "\n",
    "radius_difference = target_radius_squared - pred_radius_squared\n",
    "\n",
    "print('JSTICK average radius', np.average(np.abs(radius_difference[:,0])))\n",
    "print('CSTICK average radius', np.average(np.abs(radius_difference[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115,)\n",
      "[0.01754379 0.01754391 0.01754391 0.01754379 0.01754391 0.01754379\n",
      " 0.01754391 0.01754391 0.01754373 0.01754397 0.01754373 0.01754391\n",
      " 0.01754397 0.01754373 0.01754391 0.01754379 0.01754391 0.01754391\n",
      " 0.01754379 0.01754385 0.01754385 0.01754385 0.01754391 0.01754385\n",
      " 0.01754385 0.01754385 0.01754385 0.01754391 0.01754379 0.01754391\n",
      " 0.01754379 0.01754385 0.01754397 0.01754379 0.01754385 0.01754385\n",
      " 0.01754385 0.01754391 0.01754385 0.01754379 0.01754391 0.01754385\n",
      " 0.01754385 0.01754391 0.01754379 0.01754385 0.01754391 0.01754385\n",
      " 0.01754385 0.01754385 0.01754385 0.01754385 0.01754385 0.01754391\n",
      " 0.01754385 0.01754379 0.01754391 0.01754391 0.01754379 0.01754391\n",
      " 0.01754379 0.01754391 0.01754391 0.01754379 0.01754379 0.01754391\n",
      " 0.01754391 0.01754379 0.01754391 0.01754379 0.01754391 0.01754379\n",
      " 0.01754391 0.01754391 0.01754379 0.01754379 0.01754403 0.01754379\n",
      " 0.01754379 0.01754391 0.01754379 0.01754391 0.01754391 0.01754379\n",
      " 0.01754391 0.01754379 0.01754391 0.01754391 0.01754379 0.01754379\n",
      " 0.01754391 0.01754391 0.01754379 0.01754391 0.01754391 0.01754379\n",
      " 0.01754379 0.01754403 0.01754379 0.01754379 0.01754379 0.01754403\n",
      " 0.01754379 0.01754379 0.01754403 0.01754367 0.01754391 0.01754391\n",
      " 0.01754379 0.01754391 0.01754379 0.01754391 0.01754391 0.01754379]\n"
     ]
    }
   ],
   "source": [
    "unique_values = np.unique((target[:,0] - .5) * 2)\n",
    "print(unique_values.shape)\n",
    "print(np.diff(unique_values))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11023848621446584\n",
      "0.15590076229997707\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print((2 * np.pi) * .017545)\n",
    "print((2 * np.pi) * .017545 * math.sqrt(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5904,)\n",
      "[0.00036263 0.00037694 0.0003922  ... 0.00037694 0.00036263 0.01886582]\n",
      "0.0010612095\n"
     ]
    }
   ],
   "source": [
    "unique_values = np.unique(np.arctan2((target[:,[0,2]] - .5) * 2, (target[:,[1,3]] - .5) * 2))\n",
    "print(unique_values.shape)\n",
    "print(np.diff(unique_values))\n",
    "print(np.average(np.diff(unique_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115,)\n",
      "[0.01249993 0.01250005 0.01250005 0.01249993 0.01250005 0.01249993\n",
      " 0.01250005 0.01250005 0.01249993 0.01250005 0.01249993 0.01250005\n",
      " 0.01250005 0.01249993 0.01250005 0.01249993 0.01250005 0.01250002\n",
      " 0.01249993 0.01250005 0.01249999 0.01249999 0.01250005 0.01249999\n",
      " 0.01249999 0.01249999 0.01249999 0.01250005 0.01249993 0.01250005\n",
      " 0.01249999 0.01249999 0.01250005 0.01249999 0.01249999 0.01249999\n",
      " 0.01249999 0.01250005 0.01249999 0.01249999 0.01249999 0.01250002\n",
      " 0.01249999 0.01250002 0.01249999 0.01249999 0.01250002 0.01250002\n",
      " 0.01249999 0.01249999 0.01249999 0.01249999 0.01250002 0.01250002\n",
      " 0.01250002 0.01249993 0.01250005 0.01250004 0.01249995 0.01250004\n",
      " 0.01249995 0.01250004 0.01250004 0.01249995 0.01249995 0.01250004\n",
      " 0.01250003 0.01249996 0.01250003 0.01249996 0.01250003 0.01249996\n",
      " 0.01250003 0.01250003 0.01249996 0.01249994 0.01250012 0.01249996\n",
      " 0.01249996 0.01250002 0.01249996 0.01250005 0.01250002 0.01249996\n",
      " 0.01250005 0.01249996 0.01250002 0.01250005 0.01249996 0.01249996\n",
      " 0.01250002 0.01250005 0.01249996 0.01250002 0.01250005 0.01249996\n",
      " 0.01249996 0.01250014 0.01249993 0.01249993 0.01249999 0.01250011\n",
      " 0.01249993 0.01249999 0.01250011 0.01249987 0.01250005 0.01250005\n",
      " 0.01249993 0.01250005 0.01249993 0.01250005 0.01250005 0.01249993]\n",
      "0.012499999\n"
     ]
    }
   ],
   "source": [
    "unique_values = np.unique(target_sticks_no_transform)\n",
    "print(unique_values.shape)\n",
    "print(np.diff(unique_values))\n",
    "print(np.average(np.diff(unique_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".017343 / 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
