{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torchsummary import summary\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch_tensorrt\n",
    "\n",
    "import numpy as np\n",
    "import gzip\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from slp_package.slp_functions import create_merged_game_data_df\n",
    "from slp_package.input_dataset import InputDataSet\n",
    "import slp_package.pytorch_functions as slp_pytorch_functions\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using CUDA\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_merged_game_data_df(['ranked','mango','public'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'source_path_prefix', 'source_path_suffix', 'length',\n",
       "       'num_players', 'is_teams', 'player_1_port', 'player_1_character_name',\n",
       "       'player_1_type_name', 'player_1_stocks', 'player_1_costume',\n",
       "       'player_1_team_value', 'player_1_ucf_shield_drop_name', 'player_1_tag',\n",
       "       'player_1_display_name', 'player_2_port', 'player_2_character_name',\n",
       "       'player_2_type_name', 'player_2_stocks', 'player_2_costume',\n",
       "       'player_2_team_value', 'player_2_ucf_shield_drop_name', 'player_2_tag',\n",
       "       'player_2_display_name', 'random_seed', 'slippi', 'stage_name',\n",
       "       'is_pal', 'is_frozen_ps', 'end_method_name', 'lras_initiator',\n",
       "       'conclusive', 'winning_player', 'date', 'duration', 'platform',\n",
       "       'player_1_netplay_code', 'player_1_netplay_name',\n",
       "       'player_2_netplay_code', 'player_2_netplay_name', 'console_name',\n",
       "       'all_data_df_common_path', 'inputs_df_common_path',\n",
       "       'inputs_np_common_path', 'player_1_all_data_df_sub_path',\n",
       "       'player_1_all_data_df_save_path', 'player_1_inputs_df_sub_path',\n",
       "       'player_1_inputs_df_save_path', 'player_1_inputs_np_sub_path',\n",
       "       'player_1_inputs_np_save_path', 'player_2_all_data_df_sub_path',\n",
       "       'player_2_all_data_df_save_path', 'player_2_inputs_df_sub_path',\n",
       "       'player_2_inputs_df_save_path', 'player_2_inputs_np_sub_path',\n",
       "       'player_2_inputs_np_save_path', 'player_1_win', 'player_2_win'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   99186\n",
       "Platinum Player    47335\n",
       "Master Player      39195\n",
       "Diamond Player     29613\n",
       "mang               14142\n",
       "                   ...  \n",
       "AV                     1\n",
       "Zuppy                  1\n",
       "tk                     1\n",
       "DawsonTruu             1\n",
       "Bink                   1\n",
       "Name: player_1_display_name, Length: 257, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['player_1_display_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41459841.06666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['length'].sum() / (60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asses_model(model_name, y_pred, y_test, labels_order):\n",
    "    print()\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_pred, y_test)\n",
    "\n",
    "    # Print accuracy and Cohen Kappa score with explanations\n",
    "    print(f'Accuracy of {model_name}: {accuracy:.4f}')\n",
    "    print(f'Cohen Kappa Score of {model_name}: {kappa:.4f}')\n",
    "\n",
    "    # Calculate the normalized predicted label count\n",
    "    unique_pred, counts_pred = np.unique(y_pred, return_counts=True)\n",
    "    unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "    normalized_counts_pred = {k: v / counts_test[np.where(unique_test == k)[0][0]] for k, v in zip(unique_pred, counts_pred)}\n",
    "    \n",
    "    # Calculate the percent the model over or under predicted the labels using the specified label order\n",
    "    sorted_values = [normalized_counts_pred[k] - 1 if k in normalized_counts_pred else 0 for k in labels_order]\n",
    "\n",
    "    # Plotting the percent the model over or under predicted the labels\n",
    "    plt.figure(figsize=(2*len(labels_order), 4))\n",
    "    plt.bar(labels_order, sorted_values, color=['green' if x > 0 else 'blue' for x in sorted_values])\n",
    "    plt.title(f'Percent Model {model_name} Over or Under Predicted Labels')\n",
    "    plt.xlabel('Labels')\n",
    "    plt.ylabel('Percent Over/Under Prediction')\n",
    "    \n",
    "    # Center y-axis and set equal extension above and below\n",
    "    max_extent = max(abs(min(sorted_values)), abs(max(sorted_values))) * 1.05\n",
    "    plt.ylim(-max_extent, max_extent)\n",
    "    plt.axhline(y=0, color='gray', linewidth=0.8)\n",
    "    plt.show()\n",
    "\n",
    "    # Display each confusion matrix on its own row\n",
    "    for norm in [None, 'true', 'pred']:\n",
    "        plt.figure(figsize=(len(labels_order)+5, len(labels_order)+5))\n",
    "        ax = plt.gca()\n",
    "        ConfusionMatrixDisplay.from_predictions(\n",
    "            y_test, y_pred, normalize=norm, ax=ax,\n",
    "            xticks_rotation='vertical', labels=labels_order\n",
    "        )\n",
    "        ax.title.set_text(f'{model_name} Confusion Matrix ({\"Not Normalized\" if norm is None else \"Normalized by \" + norm})')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = ['ranked','public','mango']\n",
    "\n",
    "general_features = {\n",
    "    'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "    'num_players': [2],\n",
    "    'conclusive': [True]\n",
    "}\n",
    "player_features = {\n",
    "    # 'netplay_code': ['MANG#0'],\n",
    "    # 'character_name': ['FALCO'],\n",
    "    'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'MARIO', 'PEACH', 'ROY', 'LUIGI', 'YOUNG_LINK', 'DONKEY_KONG', 'PICHU', 'KIRBY'],\n",
    "    # 'character_name': ['FOX', 'CAPTAIN_FALCON', 'SHEIK', 'FALCO', 'GAME_AND_WATCH', 'MARTH', 'LINK', 'ICE_CLIMBERS', 'SAMUS', 'GANONDORF', 'BOWSER', 'MEWTWO', 'YOSHI', 'PIKACHU', 'JIGGLYPUFF', 'NESS', 'DR_MARIO', 'PEACH', 'LUIGI', 'DONKEY_KONG'],\n",
    "    'type_name': ['HUMAN']\n",
    "    \n",
    "}\n",
    "opposing_player_features = {\n",
    "    # 'character_name': ['MARTH'],\n",
    "    # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "    'type_name': ['HUMAN']\n",
    "}\n",
    "label_info = {\n",
    "    'source': ['player'], # Can be 'general', 'player\n",
    "    # 'feature': ['netplay_code']\n",
    "    'feature': ['character_name']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_data = ['ranked','public']\n",
    "\n",
    "# general_features = {\n",
    "#     'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "#     'num_players': [2],\n",
    "#     'conclusive': [True]\n",
    "# }\n",
    "# player_features = {\n",
    "#     # 'netplay_code': ['MANG#0'],\n",
    "#     # 'character_name': ['PICHU'],\n",
    "#     # 'character_name': ['PIKACHU'],\n",
    "#     # 'character_name': ['PIKACHU','PICHU'],\n",
    "#     # 'character_name': ['FOX','FALCO'],\n",
    "#     'character_name': ['FOX','FALCO','PIKACHU','PICHU'],\n",
    "#     # 'display_name': ['Platinum Player','Master Player', 'Diamond Player']\n",
    "\n",
    "    \n",
    "# }\n",
    "# opposing_player_features = {\n",
    "#     # 'character_name': ['MARTH'],\n",
    "#     # 'netplay_code': ['KOD#0', 'ZAIN#0']\n",
    "#     'type_name': ['HUMAN']\n",
    "# }\n",
    "# label_info = {\n",
    "#     'source': ['player'], # Can be 'general', 'player\n",
    "#     # 'feature': ['netplay_code']\n",
    "#     'feature': ['character_name']\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We classify opponent's characters on competitive stages\n",
    "\n",
    "# source_data = ['ranked']\n",
    "\n",
    "# general_features = {\n",
    "#     'stage_name': ['FOUNTAIN_OF_DREAMS','FINAL_DESTINATION','BATTLEFIELD','YOSHIS_STORY','POKEMON_STADIUM','DREAMLAND'],\n",
    "#     'num_players': [2],\n",
    "#     'conclusive': [True]\n",
    "# }\n",
    "# player_features = {\n",
    "#     # 'netplay_code': ['MANG#0'],\n",
    "#     'character_name': ['FOX'],\n",
    "#     'type_name': ['HUMAN']\n",
    "    \n",
    "# }\n",
    "# opposing_player_features = {\n",
    "#     'character_name': ['FOX', 'FALCO', 'MARTH', 'CAPTAIN_FALCON', 'SHEIK'],\n",
    "#     # 'netplay_code': ['KOD#0', 'ZAIN#0'],\n",
    "#     'type_name': ['HUMAN']\n",
    "# }\n",
    "# label_info = {\n",
    "#     'source': ['opposing_player'], # Can be 'general', 'player', 'opposing_player'\n",
    "#     # 'feature': ['netplay_code']\n",
    "#     'feature': ['character_name']\n",
    "# }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/slp_jaspar/autoencoder_classify/../slp_package/input_dataset.py:95: FutureWarning: In a future version, object-dtype columns with all-bool values will not be included in reductions with bool_only=True. Explicitly cast to bool dtype instead.\n",
      "  processed_df = pd.concat([player_1_df, player_2_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOX               103069\n",
      "FALCO              90719\n",
      "MARTH              53728\n",
      "CAPTAIN_FALCON     38006\n",
      "SHEIK              27623\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset = InputDataSet(source_data, general_features, player_features, opposing_player_features, label_info)\n",
    "\n",
    "print(dataset.dataset['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "            Label   Count  Shift\n",
      "0             FOX  102551  15075\n",
      "1           FALCO   90263  12994\n",
      "2           MARTH   53538   8570\n",
      "3  CAPTAIN_FALCON   37820   5406\n",
      "4           SHEIK   27536   4950\n"
     ]
    }
   ],
   "source": [
    "labels_order =  dataset.number_of_segments_per_game(3600,40000)\n",
    "print(2**10)\n",
    "print(labels_order)\n",
    "labels_order = labels_order['Label'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           player_inputs_np_sub_path  length  num_segments  \\\n",
      "0  public\\FALCO\\c4923e7a-eb2b-4d7a-844d-0642caa17...   16592             1   \n",
      "1  ranked\\FALCO\\34c40adf-7386-4603-9c9e-ee2f8e2ba...   16590             1   \n",
      "2  ranked\\FALCO\\db3afa43-f3cf-4cba-94ce-105f6670b...   16569             1   \n",
      "3  ranked\\FALCO\\e7d480eb-7a28-4741-b49e-917544a11...   16564             1   \n",
      "4  public\\FALCO\\9f3fda37-6f5f-4db7-aeee-516bc89e8...   16540             1   \n",
      "\n",
      "  labels  encoded_labels  \n",
      "0  FALCO               1  \n",
      "1  FALCO               1  \n",
      "2  FALCO               1  \n",
      "3  FALCO               1  \n",
      "4  FALCO               1  \n"
     ]
    }
   ],
   "source": [
    "train_df, test_df  = dataset.train_test_split_dataframes(test_ratio = .20, val = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(542672, 6)\n",
      "(6783, 6)\n",
      "0.012344960005823953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_inputs_np_sub_path</th>\n",
       "      <th>labels</th>\n",
       "      <th>encoded_labels</th>\n",
       "      <th>segment_start_index</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>segment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351084</th>\n",
       "      <td>ranked\\FOX\\1e2a5e72-2de8-46d6-b2e9-d4a53da8227...</td>\n",
       "      <td>FOX</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215852</th>\n",
       "      <td>ranked\\MARTH\\52e795fc-d615-420f-8115-556fd2bf8...</td>\n",
       "      <td>MARTH</td>\n",
       "      <td>3</td>\n",
       "      <td>2605</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119316</th>\n",
       "      <td>ranked\\FALCO\\2b24c6dd-06a0-438b-a5bd-7b2440b13...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>1</td>\n",
       "      <td>5580</td>\n",
       "      <td>2</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526796</th>\n",
       "      <td>mango\\SHEIK\\53ccce5e-4093-4231-aed1-2ea15c93cb...</td>\n",
       "      <td>SHEIK</td>\n",
       "      <td>4</td>\n",
       "      <td>2600</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14671</th>\n",
       "      <td>ranked\\FALCO\\89abf765-69d7-4bc1-8d48-560773217...</td>\n",
       "      <td>FALCO</td>\n",
       "      <td>1</td>\n",
       "      <td>2540</td>\n",
       "      <td>1</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                player_inputs_np_sub_path labels  \\\n",
       "351084  ranked\\FOX\\1e2a5e72-2de8-46d6-b2e9-d4a53da8227...    FOX   \n",
       "215852  ranked\\MARTH\\52e795fc-d615-420f-8115-556fd2bf8...  MARTH   \n",
       "119316  ranked\\FALCO\\2b24c6dd-06a0-438b-a5bd-7b2440b13...  FALCO   \n",
       "526796  mango\\SHEIK\\53ccce5e-4093-4231-aed1-2ea15c93cb...  SHEIK   \n",
       "14671   ranked\\FALCO\\89abf765-69d7-4bc1-8d48-560773217...  FALCO   \n",
       "\n",
       "        encoded_labels  segment_start_index  segment_index  segment_length  \n",
       "351084               2                    0              0            3600  \n",
       "215852               3                 2605              1            3600  \n",
       "119316               1                 5580              2            3600  \n",
       "526796               4                 2600              1            3600  \n",
       "14671                1                 2540              1            3600  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df = dataset.all_segments_train_test_split_dataframes(3600, proportion_of_segments=1, test_ratio = .2, val = False)\n",
    "porportion = 1\n",
    "train_df = train_df.sample(frac=porportion, random_state = 42)\n",
    "porportion = .05\n",
    "test_df = test_df.sample(frac=porportion, random_state = 42)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "print(test_df.shape[0] / (train_df.shape[0] + test_df.shape[0]))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'FOX', 3: 'MARTH', 1: 'FALCO', 4: 'SHEIK', 0: 'CAPTAIN_FALCON'}\n"
     ]
    }
   ],
   "source": [
    "labels_unique = train_df['labels'].unique()\n",
    "encoded_labels_unique = train_df['encoded_labels'].unique()\n",
    "label_decoder = zip(labels_unique, encoded_labels_unique)\n",
    "label_decoder = dict(zip(encoded_labels_unique, labels_unique)) \n",
    "print(label_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset for loading game segments from compressed numpy files.\n",
    "    \"\"\"\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.file_paths = df['player_inputs_np_sub_path'].to_numpy()\n",
    "        self.encoded_labels = df['encoded_labels'].to_numpy()\n",
    "        self.segment_start_index = df['segment_start_index'].to_numpy()\n",
    "        # self.segment_index = df['segment_index'].to_numpy()\n",
    "        self.segment_length = df['segment_length'].to_numpy()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Loads and returns a sample from the dataset at the specified index.\"\"\"\n",
    "        with gzip.open('/workspace/melee_project_data/input_np/' + self.file_paths[idx].replace('\\\\','/'), 'rb') as f:\n",
    "            segment = np.load(f)\n",
    "        \n",
    "        # Start and end of the segment\n",
    "        segment_start = self.segment_start_index[idx]\n",
    "        segment_end = self.segment_start_index[idx] + self.segment_length[idx]\n",
    "        \n",
    "        segment = segment[:,int(segment_start):int(segment_end)]\n",
    "        \n",
    "\n",
    "        segment[-5] = (segment[-5] > .5)\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = np.zeros((9 + 5+4,3600))\n",
    "            \n",
    "            # First 4 rows of transformed are the analog inputs transformed to have range [0,1]\n",
    "            # Shift inputs: adjusting so that positives are reduced and negatives are increased\n",
    "            analog_transformed = np.copy(segment[0:4])\n",
    "            analog_transformed[analog_transformed > 0] -= 0.2875 + 0.0125\n",
    "            analog_transformed[analog_transformed < 0] += 0.2875 - 0.0125\n",
    "            # Scale inputs to be between -.5 and .5\n",
    "            analog_transformed *= .5 / .725\n",
    "            # Add .5 to so final inputs are between 0 and 1\n",
    "            analog_transformed += .5\n",
    "            \n",
    "            transformed[0:4] = analog_transformed\n",
    "            # Next four rows are 1 if the corresponding analog input is 0\n",
    "            transformed[4:8] += (segment[:4] == 0)\n",
    "            \n",
    "            \n",
    "            prepend = np.expand_dims(segment[-5:, 0], axis=1)\n",
    "            transitions= np.abs(np.diff(segment[-5:], axis=1, prepend=prepend))\n",
    "            \n",
    "            transformed[8:13] += transitions\n",
    "            \n",
    "            \n",
    "\n",
    "            # Transform the Trigger so that it is 0 or 1\n",
    "            \n",
    "            \n",
    "            # Remaining rows are button inputs\n",
    "            transformed[-5:] += segment[-5:]\n",
    "            \n",
    "            \n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        segment_tensor = torch.from_numpy(transformed).float()\n",
    "        label_tensor = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return segment_tensor, label_tensor\n",
    "    \n",
    "def prepare_data_loaders(train_df, test_df, batch_size, num_workers):\n",
    "    # Initialize datasets\n",
    "    train_dataset = TrainingDataset(train_df,True)\n",
    "    # val_dataset = TrainingDataset(file_paths_val, labels_val)\n",
    "    test_dataset = TrainingDataset(test_df,True)\n",
    "\n",
    "    # Initialize data loaders\n",
    "    loaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=True,persistent_workers=True, drop_last=True),\n",
    "        'test': DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True, drop_last=True),\n",
    "        # 'val': DataLoader(val_dataset, batch_size=2**9, num_workers=num_workers, shuffle=False, pin_memory=True,persistent_workers=True)\n",
    "    }\n",
    "    return loaders\n",
    "\n",
    "\n",
    "\n",
    "# ''' Get a batch of data to see the size if we want that information. ''' \n",
    "# data_loader_iterator = iter(loaders['train'])\n",
    "# first_batch = next(data_loader_iterator)\n",
    "# print(first_batch.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def split_batches_of_minute_segments(batch):\n",
    "    num_channels = 18\n",
    "    chunks = torch.split(batch, 1, 0)\n",
    "    list0 = [torch.stack(torch.split(chunk.view(num_channels, 3600), 60, 1), dim=0) for chunk in chunks]\n",
    "    new_batch = torch.cat(list0,dim=0)\n",
    "    # print('new_batch',new_batch.shape)\n",
    "    return new_batch\n",
    "\n",
    "@torch.jit.script\n",
    "def merge_seconds_to_minute(encoded):\n",
    "    # batch_size = 16\n",
    "    # print(encoded.shape)\n",
    "    # chunks = torch.split(encoded, 1, 0)\n",
    "    # print('chunks[0].shape',chunks[0].shape)\n",
    "    # print('len(chunks)',len(chunks))\n",
    "    # list = [torch.stack(chunks[i*60: i*60 + 60]) for i in range(batch_size)]\n",
    "    # print('list[0].shape',list[0].shape)\n",
    "    # encoded_batch = torch.cat(list, dim=0)\n",
    "    # print('encoded_batch.shape',encoded_batch.shape)\n",
    "    chunks = torch.split(encoded,1,0)\n",
    "    list0 = []\n",
    "    # print(chunks[0].shape)\n",
    "    for chunk in chunks:\n",
    "        chunk = chunk.view(chunk.size(1), chunk.size(2))\n",
    "        # print(chunk.shape)\n",
    "        list0.append(chunk)\n",
    "    list1=[]\n",
    "    # print(len(list0))\n",
    "    # print(list0[0].size)\n",
    "    for i in range(16):\n",
    "        list1.append(torch.cat(list0[i*60:i*60+60],dim=1))\n",
    "    # print(len(list1))\n",
    "    # print(list1[0].shape)\n",
    "    final = torch.stack(list1)    \n",
    "    # print(final.shape)\n",
    "    return final\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model_with_virtual_epochs(model, criterion, optimizer, loaders, device, encoder, num_epochs=1):\n",
    "    # print(0)\n",
    "    scaler = GradScaler()\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    \n",
    "    vepoch_total = 0\n",
    "    vepoch_loss_sum = 0\n",
    "    best_vepoch_loss = float('inf')\n",
    "    early_stopping_patience = 0\n",
    "    encoder.eval()\n",
    "    # print(1)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loader_tqdm = tqdm(loaders['train'], desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch')\n",
    "        virtual_epoch_start_time = time.time()\n",
    "\n",
    "        # Initialize variables for tracking gradient and parameter stats\n",
    "        grad_max = float('-inf')\n",
    "        grad_min = float('inf')\n",
    "        param_max = float('-inf')\n",
    "        param_min = float('inf')\n",
    "        # print(2)\n",
    "        for inputs_cpu, labels in train_loader_tqdm:\n",
    "            optimizer.zero_grad()\n",
    "            batch_to_encode = split_batches_of_minute_segments(inputs_cpu)\n",
    "            batch_to_encode_gpu = batch_to_encode.to(device)\n",
    "            encoded_gpu = encoder(batch_to_encode_gpu)\n",
    "            encoded_inputs_gpu = merge_seconds_to_minute(encoded_gpu)\n",
    "\n",
    "            \n",
    "            \n",
    "            # optimizer.zero_grad()\n",
    "            # print(encoded_inputs_gpu.shape)\n",
    "            output_gpu = model(encoded_inputs_gpu)\n",
    "            # output_gpu = model(inputs_cpu.to(device))\n",
    "            # print(output_gpu.shape)\n",
    "            loss = criterion(output_gpu, labels.to(device)) \n",
    "            # print(output_gpu)\n",
    "            # print(labels)\n",
    "            # print(loss)\n",
    "            loss.backward()\n",
    "            # scaler.scale(loss).backward()\n",
    "\n",
    "            # Track max and min of gradients\n",
    "            batch_grad_max = max((p.grad.max().item() for p in model.parameters() if p.grad is not None), default=grad_max)\n",
    "            batch_grad_min = min((p.grad.min().item() for p in model.parameters() if p.grad is not None), default=grad_min)\n",
    "            grad_max = max(grad_max, batch_grad_max)\n",
    "            grad_min = min(grad_min, batch_grad_min)\n",
    "\n",
    "            clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            # scaler.step(optimizer)\n",
    "            # scaler.update()\n",
    "\n",
    "            vepoch_total += 1\n",
    "            vepoch_loss_sum += loss.item()\n",
    "\n",
    "            if time.time() - virtual_epoch_start_time > 15:\n",
    "                vepoch_loss = vepoch_loss_sum / vepoch_total\n",
    "                if best_vepoch_loss > vepoch_loss:\n",
    "                    best_vepoch_loss = vepoch_loss\n",
    "                else:\n",
    "                    early_stopping_patience += 1\n",
    "\n",
    "                # Calculate max and min of model parameters at the end of the virtual epoch\n",
    "                param_max = max(p.data.max().item() for p in model.parameters())\n",
    "                param_min = min(p.data.min().item() for p in model.parameters())\n",
    "\n",
    "                train_loader_tqdm.set_postfix(\n",
    "                    Best=f'{best_vepoch_loss:.10f}',\n",
    "                    Vepoch=f'{vepoch_loss:.10f}',\n",
    "                    patience=early_stopping_patience,\n",
    "                    Grad_Max=grad_max,\n",
    "                    Grad_Min=grad_min,\n",
    "                    Param_Max=param_max,\n",
    "                    Param_Min=param_min\n",
    "                )\n",
    "                # print('Grad Max:', grad_max, ' Grad Min:', grad_min)\n",
    "                virtual_epoch_start_time = time.time()\n",
    "                vepoch_total = 0\n",
    "                vepoch_loss_sum = 0\n",
    "                grad_max = float('-inf')  # Reset for next virtual epoch\n",
    "                grad_min = float('inf')   # Reset for next virtual epoch\n",
    "            # break\n",
    "\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Encoder(\n",
       "    (layer1): Sequential(\n",
       "      (0): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(18, 64, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (i_downsample): Sequential(\n",
       "          (0): Conv1d(18, 256, kernel_size=(1,), stride=(1,))\n",
       "          (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (i_downsample): Sequential(\n",
       "          (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,))\n",
       "          (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (i_downsample): Sequential(\n",
       "          (0): Conv1d(512, 1024, kernel_size=(1,), stride=(2,))\n",
       "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (i_downsample): Sequential(\n",
       "          (0): Conv1d(1024, 2048, kernel_size=(1,), stride=(2,))\n",
       "          (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Encoder_Bottleneck(\n",
       "        (conv1): Conv1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (reduce): Sequential(\n",
       "      (0): Conv1d(2048, 15, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "      (1): BatchNorm1d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (expand): Sequential(\n",
       "      (0): ConvTranspose1d(15, 2048, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "      (1): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (layer5): Sequential(\n",
       "      (0): Decoder_Bottleneck(\n",
       "        (conv1): ConvTranspose1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvTranspose1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvTranspose1d(512, 2048, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Decoder_Bottleneck(\n",
       "        (conv1): ConvTranspose1d(2048, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvTranspose1d(512, 512, kernel_size=(3,), stride=(2,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvTranspose1d(512, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (i_upsample): Sequential(\n",
       "          (0): Upsample(size=15, mode='nearest')\n",
       "          (1): ConvTranspose1d(2048, 1024, kernel_size=(1,), stride=(1,))\n",
       "          (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer6): Sequential(\n",
       "      (0): Decoder_Bottleneck(\n",
       "        (conv1): ConvTranspose1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvTranspose1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvTranspose1d(256, 1024, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Decoder_Bottleneck(\n",
       "        (conv1): ConvTranspose1d(1024, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvTranspose1d(256, 256, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvTranspose1d(256, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (i_upsample): Sequential(\n",
       "          (0): Upsample(size=30, mode='nearest')\n",
       "          (1): ConvTranspose1d(1024, 512, kernel_size=(1,), stride=(1,))\n",
       "          (2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer7): Sequential(\n",
       "      (0): Decoder_Bottleneck(\n",
       "        (conv1): ConvTranspose1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvTranspose1d(128, 512, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): Decoder_Bottleneck(\n",
       "        (conv1): ConvTranspose1d(512, 128, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), output_padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvTranspose1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (i_upsample): Sequential(\n",
       "          (0): Upsample(size=60, mode='nearest')\n",
       "          (1): ConvTranspose1d(512, 256, kernel_size=(1,), stride=(1,))\n",
       "          (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (layer8): Sequential(\n",
       "      (0): Decoder_Bottleneck(\n",
       "        (conv1): ConvTranspose1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (batch_norm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): ConvTranspose1d(64, 256, kernel_size=(1,), stride=(1,))\n",
       "        (batch_norm3): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (lastblock): Sequential(\n",
       "      (0): ConvTranspose1d(256, 64, kernel_size=(1,), stride=(1,))\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "      (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU()\n",
       "      (6): ConvTranspose1d(64, 18, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from Encode_ResNet_Model import ResNet50, ResNet101\n",
    "from Simple_Test_Model import Model\n",
    "from autoencoder_classify.Convolutional_Encoder_Model import ResNet_Encoder\n",
    "\n",
    "channels = 18\n",
    "batch_size = 16\n",
    "num_classes = 5\n",
    "# model = ResNet50(num_classes=5, channels=15).to('cuda')\n",
    "\n",
    "model = Model()\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "model.to('cuda')\n",
    "\n",
    "\n",
    "channels = 9 + 5 + 4\n",
    "# Build model\n",
    "encoder = ResNet_Encoder(channels)\n",
    "encoder.load_state_dict(torch.load('../../melee_project_data/convolutional_autoencode_bottlenecksize_15_weights_2.pt'))\n",
    "encoder.to('cuda')\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "\n",
    "# Optimize the loaded model with Torch-TensorRT\n",
    "# encoder = torch_tensorrt.compile(\n",
    "#     encoder,\n",
    "#     inputs=[torch_tensorrt.Input((batch_size * 60, channels, 60))],\n",
    "#     enabled_precisions={torch.float}  # Use torch.half for FP16 precision if needed\n",
    "# )\n",
    "## Optionally compile the model\n",
    "# import torch_tensorrt\n",
    "# model = torch.compile(model, mode = 'default')\n",
    "# model = torch.compile(model,mode = 'max-autotune')\n",
    "\n",
    "\n",
    "# encoder = torch.compile(encoder, backend=\"torch_tensorrt\")\n",
    "# model = torch.compile(model, backend=\"torch_tensorrt\",mode = 'max-autotune')\n",
    "\n",
    "# Move the optimized model to GPU\n",
    "# trt_encoder = trt_encoder.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1:   4%|â–Ž         | 1196/33917 [01:27<40:02, 13.62batch/s, Best=1.4047853617, Grad_Max=0.848, Grad_Min=-0.864, Param_Max=0.185, Param_Min=-0.234, Vepoch=1.4047853617, patience=0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 29\u001b[0m\n\u001b[1;32m     27\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# print(5)\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mtrain_model_with_virtual_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 46\u001b[0m, in \u001b[0;36mtrain_model_with_virtual_epochs\u001b[0;34m(model, criterion, optimizer, loaders, device, encoder, num_epochs)\u001b[0m\n\u001b[1;32m     42\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# scaler.scale(loss).backward()\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Track max and min of gradients\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m batch_grad_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m batch_grad_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), default\u001b[38;5;241m=\u001b[39mgrad_min)\n\u001b[1;32m     48\u001b[0m grad_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(grad_max, batch_grad_max)\n",
      "Cell \u001b[0;32mIn[17], line 46\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# scaler.scale(loss).backward()\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Track max and min of gradients\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m batch_grad_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m((\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), default\u001b[38;5;241m=\u001b[39mgrad_max)\n\u001b[1;32m     47\u001b[0m batch_grad_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m((p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m), default\u001b[38;5;241m=\u001b[39mgrad_min)\n\u001b[1;32m     48\u001b[0m grad_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(grad_max, batch_grad_max)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# torch.autograd.set_detect_anomaly(False)\n",
    "# Pepare data loaders\n",
    "batch_size =  16\n",
    "num_workers = 16\n",
    "# print(1)\n",
    "loaders = prepare_data_loaders(train_df, test_df, batch_size, num_workers)\n",
    "# print(2)\n",
    "optimizer = Adam(model.parameters(), lr=0.0005)\n",
    "# print(3)\n",
    "criterion = nn.CrossEntropyLoss() # All our batches will be the same.\n",
    "\n",
    "# print(4)\n",
    "num_epochs = 1\n",
    "\n",
    "# def initialize_parameters(model):\n",
    "#     for m in model.modules():\n",
    "#         if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "#             torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
    "#             if m.bias is not None:\n",
    "#                 torch.nn.init.constant_(m.bias, 0)\n",
    "\n",
    "# # Initialize model parameters\n",
    "# initialize_parameters(model)\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# print(5)\n",
    "train_model_with_virtual_epochs(model, criterion, optimizer, loaders, 'cuda', encoder, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asses_model('ResNet-50', np.array([label_decoder.get(item, \"Unknown\") for item in y_pred]), np.array(test_df['labels']), labels_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n"
     ]
    }
   ],
   "source": [
    "x = [3, 4, 4]\n",
    "plus = 3 + 2\n",
    "multiplier = 4\n",
    "for val in x:\n",
    "    plus += multiplier * val\n",
    "    multiplier *= 2\n",
    "print(1 + 2 * plus)\n",
    "    \n",
    "# print(1 + 2 * (x[0] * 4 + x[1] * 8 + x[2] * 16 + x[3] * 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:   0%|          | 0/27133 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27133/27133 [01:41<00:00, 266.40batch/s, accuracy=75.8, loss=0.038] \n",
      "Epoch 2/2:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16649/27133 [01:01<00:38, 271.70batch/s, accuracy=82.2, loss=0.03]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mslp_pytorch_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m slp_pytorch_functions\u001b[38;5;241m.\u001b[39mpredict(model, loaders[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m )\n\u001b[1;32m      3\u001b[0m asses_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResNet-50\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39marray([label_decoder\u001b[38;5;241m.\u001b[39mget(item, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m y_pred]), np\u001b[38;5;241m.\u001b[39marray(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]), labels_order)\n",
      "File \u001b[0;32m/workspace/slp_jaspar/autoencoder_classify/../slp_package/pytorch_functions.py:139\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, loaders, device, num_epochs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)  \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Scales loss and calls backward() to create scaled gradients\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# scaler.step() first unscales the gradients of the optimizer's assigned params.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# If these gradients do not contain infs or NaNs, optimizer.step() is then called,\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# otherwise, optimizer.step() is skipped.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py:524\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    516\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    517\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    522\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    523\u001b[0m     )\n\u001b[0;32m--> 524\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:740\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_engine_run_backward\u001b[39m(t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 740\u001b[0m     attach_logging_hooks \u001b[38;5;241m=\u001b[39m \u001b[43mlog\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetEffectiveLevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mDEBUG\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n\u001b[1;32m    742\u001b[0m         unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n",
      "File \u001b[0;32m/usr/lib/python3.10/logging/__init__.py:1710\u001b[0m, in \u001b[0;36mLogger.getEffectiveLevel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1706\u001b[0m             sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo handlers could be found for logger\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1707\u001b[0m                              \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1708\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanager\u001b[38;5;241m.\u001b[39memittedNoHandlerWarning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1710\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetEffectiveLevel\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1711\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;124;03m    Get the effective level for this logger.\u001b[39;00m\n\u001b[1;32m   1713\u001b[0m \n\u001b[1;32m   1714\u001b[0m \u001b[38;5;124;03m    Loop through this logger and its parents in the logger hierarchy,\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;124;03m    looking for a non-zero logging level. Return the first one found.\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m     logger \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "slp_pytorch_functions.train_model(model, criterion,optimizer, loaders, 'cuda', 2 )\n",
    "y_pred = slp_pytorch_functions.predict(model, loaders['test'], 'cuda' )\n",
    "asses_model('ResNet-50', np.array([label_decoder.get(item, \"Unknown\") for item in y_pred]), np.array(test_df['labels']), labels_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_pytorch_functions.train_model(model, criterion,optimizer, loaders, 'cuda', 2 )\n",
    "y_pred = slp_pytorch_functions.predict(model, loaders['test'], 'cuda' )\n",
    "asses_model('ResNet-50', np.array([label_decoder.get(item, \"Unknown\") for item in y_pred]), np.array(test_df['labels']), labels_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_pytorch_functions.train_model(model, criterion,optimizer, loaders, 'cuda', 2 )\n",
    "y_pred = slp_pytorch_functions.predict(model, loaders['test'], 'cuda' )\n",
    "asses_model('ResNet-50', np.array([label_decoder.get(item, \"Unknown\") for item in y_pred]), np.array(test_df['labels']), labels_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asses_model('ResNet-50', np.array([label_decoder.get(item, \"Unknown\") for item in y_pred]), np.array(test_df['labels']), labels_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.1, 0.2],\n",
       "       [1. , 1.1, 1.2],\n",
       "       [2. , 2.1, 2.2],\n",
       "       [3. , 3.1, 3.2]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = np.array([[0,0.1,0.2],[1,1.1,1.2], [2,2.1,2.2],[3,3.1,3.2]])\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0. ],\n",
       "        [0.1],\n",
       "        [0.2]],\n",
       "\n",
       "       [[1. ],\n",
       "        [1.1],\n",
       "        [1.2]],\n",
       "\n",
       "       [[2. ],\n",
       "        [2.1],\n",
       "        [2.2]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(array,(3,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'arrange'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marrange\u001b[49m(\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# array = # a 14x3600 arary\u001b[39;00m\n\u001b[1;32m      4\u001b[0m new_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'arrange'"
     ]
    }
   ],
   "source": [
    "array = np.array([[0,0.1,0.2],[1,1.1,1.2], [2,2.1,2.2], [3,3.1,3.2]])\n",
    "# array = # a 14x3600 arary\n",
    "new_array = np.zeros((3,4,1))\n",
    "for i in range(3):\n",
    "    segment = array[:, i]\n",
    "    segment = np.reshape(segment,(-1,1))\n",
    "    # print(segment.shape)\n",
    "    new_array[i] += segment\n",
    "    # print(segment)\n",
    "print(new_array)\n",
    "\n",
    "tensor = torch.from_numpy(array)\n",
    "tensor = tensor.view(3,1,4)\n",
    "torch.transpose(tensor,2,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000],\n",
      "         [1.0000],\n",
      "         [2.0000],\n",
      "         [3.0000]],\n",
      "\n",
      "        [[0.1000],\n",
      "         [1.1000],\n",
      "         [2.1000],\n",
      "         [3.1000]],\n",
      "\n",
      "        [[0.2000],\n",
      "         [1.2000],\n",
      "         [2.2000],\n",
      "         [3.2000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array).transpose(0, 1)\n",
    "# Assuming the original shape is (4, 3), transposing will make it (3, 4)\n",
    "# Then reshape it to (3, 4, 1) to match your numpy operation\n",
    "reshaped_tensor = tensor.view(3, 4, 1)\n",
    "print(reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4 5 6 7 8 9]\n",
      " [0 1 2 3 4 5 6 7 8 9]\n",
      " [0 1 2 3 4 5 6 7 8 9]]\n",
      "(3, 10)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "a = a.reshape(1,-1)\n",
    "a = np.repeat(a,3,0)\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4 5 6 7 8 9]\n",
      " [0 1 2 3 4 5 6 7 8 9]\n",
      " [0 1 2 3 4 5 6 7 8 9]]\n",
      "[[[0 1]\n",
      "  [0 1]\n",
      "  [0 1]]\n",
      "\n",
      " [[2 3]\n",
      "  [2 3]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [4 5]\n",
      "  [4 5]]\n",
      "\n",
      " [[6 7]\n",
      "  [6 7]\n",
      "  [6 7]]\n",
      "\n",
      " [[8 9]\n",
      "  [8 9]\n",
      "  [8 9]]]\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "transformed_a = np.array([a[:,i*2:i*2+2] for i in range(5)])\n",
    "print(transformed_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1]\n",
      "  [0 1]\n",
      "  [0 1]]\n",
      "\n",
      " [[2 3]\n",
      "  [2 3]\n",
      "  [2 3]]\n",
      "\n",
      " [[4 5]\n",
      "  [4 5]\n",
      "  [4 5]]\n",
      "\n",
      " [[6 7]\n",
      "  [6 7]\n",
      "  [6 7]]\n",
      "\n",
      " [[8 9]\n",
      "  [8 9]\n",
      "  [8 9]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "# Define the original array\n",
    "a = np.array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "\n",
    "# Define parameters for the transformation\n",
    "n_rows, n_cols = a.shape\n",
    "window_width = 2\n",
    "n_windows = n_cols // window_width\n",
    "\n",
    "# Create a view with as_strided\n",
    "new_shape = (n_windows, n_rows, window_width)\n",
    "new_strides = (a.strides[1] * window_width, a.strides[0], a.strides[1])\n",
    "\n",
    "transformed_a = as_strided(a, shape=new_shape, strides=new_strides)\n",
    "\n",
    "print(transformed_a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.Tensor([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "              [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 1.0000],\n",
      "          [0.0000, 1.0000],\n",
      "          [0.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[2.0000, 3.0000],\n",
      "          [2.0000, 3.0000],\n",
      "          [2.0000, 3.0000]]],\n",
      "\n",
      "\n",
      "        [[[4.0000, 5.0000],\n",
      "          [4.0000, 5.0000],\n",
      "          [4.0000, 5.0000]]],\n",
      "\n",
      "\n",
      "        [[[6.0000, 7.0000],\n",
      "          [6.0000, 7.0000],\n",
      "          [6.0000, 7.0000]]],\n",
      "\n",
      "\n",
      "        [[[8.0000, 9.0000],\n",
      "          [8.0000, 9.0000],\n",
      "          [8.0000, 9.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1000, 1.1000],\n",
      "          [0.1000, 1.1000],\n",
      "          [0.1000, 1.1000]]],\n",
      "\n",
      "\n",
      "        [[[2.1000, 3.1000],\n",
      "          [2.1000, 3.1000],\n",
      "          [2.1000, 3.1000]]],\n",
      "\n",
      "\n",
      "        [[[4.1000, 5.1000],\n",
      "          [4.1000, 5.1000],\n",
      "          [4.1000, 5.1000]]],\n",
      "\n",
      "\n",
      "        [[[6.1000, 7.1000],\n",
      "          [6.1000, 7.1000],\n",
      "          [6.1000, 7.1000]]],\n",
      "\n",
      "\n",
      "        [[[8.1000, 9.1000],\n",
      "          [8.1000, 9.1000],\n",
      "          [8.1000, 9.1000]]]])\n"
     ]
    }
   ],
   "source": [
    "# rewrite this using list comprehension for the loops\n",
    "import torch\n",
    "\n",
    "# Define the original tensor\n",
    "for _ in range(100000):\n",
    "    b = torch.Tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                    [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
    "    # Add 0.1 to the second row of each batch\n",
    "    b[1, :, :] += 0.1\n",
    "\n",
    "    # print(b)\n",
    "    chunks = torch.split(b,1,0)\n",
    "    # print(chunks[0].view(3,10).shape)\n",
    "\n",
    "    # print(chunks)\n",
    "    list = []\n",
    "    for chunk in chunks:\n",
    "        # print(chunk.shape)\n",
    "        list.append(torch.stack(torch.split(chunk.view(3,10),2,1),dim=0))\n",
    "\n",
    "    # print(list)\n",
    "    # print(list[0].shape)\n",
    "    new = torch.cat(list,dim=0)\n",
    "    # print(new.shape)\n",
    "    # print(new)\n",
    "\n",
    "    batch_chunks = torch.split(new,1,0)\n",
    "    # print(batch_chunks[0:1])\n",
    "    list = []\n",
    "    for i in range(2):\n",
    "        list.append(torch.stack(batch_chunks[i*5:i*5 + 5]))\n",
    "    # print(list)\n",
    "    final = torch.cat(list,dim=0)\n",
    "print(final)\n",
    "# batch = torch.stack(chunks, dim=0)\n",
    "# print(batch)\n",
    "# batch_chunks = torch.split(batch,1,0)\n",
    "# print(batch_chunks)\n",
    "# original_b = torch.cat(batch_chunks,dim=2)\n",
    "# print(original_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000, 1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000, 7.0000,\n",
      "          8.0000, 9.0000],\n",
      "         [0.0000, 1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000, 7.0000,\n",
      "          8.0000, 9.0000],\n",
      "         [0.0000, 1.0000, 2.0000, 3.0000, 4.0000, 5.0000, 6.0000, 7.0000,\n",
      "          8.0000, 9.0000]],\n",
      "\n",
      "        [[0.1000, 1.1000, 2.1000, 3.1000, 4.1000, 5.1000, 6.1000, 7.1000,\n",
      "          8.1000, 9.1000],\n",
      "         [0.1000, 1.1000, 2.1000, 3.1000, 4.1000, 5.1000, 6.1000, 7.1000,\n",
      "          8.1000, 9.1000],\n",
      "         [0.1000, 1.1000, 2.1000, 3.1000, 4.1000, 5.1000, 6.1000, 7.1000,\n",
      "          8.1000, 9.1000]],\n",
      "\n",
      "        [[0.2000, 1.2000, 2.2000, 3.2000, 4.2000, 5.2000, 6.2000, 7.2000,\n",
      "          8.2000, 9.2000],\n",
      "         [0.2000, 1.2000, 2.2000, 3.2000, 4.2000, 5.2000, 6.2000, 7.2000,\n",
      "          8.2000, 9.2000],\n",
      "         [0.2000, 1.2000, 2.2000, 3.2000, 4.2000, 5.2000, 6.2000, 7.2000,\n",
      "          8.2000, 9.2000]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "b = torch.Tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
    "# Add 0.1 to the second row of each batch\n",
    "b[1, :, :] += 0.1\n",
    "b[2, :, :] += 0.2\n",
    "\n",
    "# print(b)\n",
    "chunks = torch.split(b,1,0)\n",
    "# print(chunks[0].view(3,10).shape)\n",
    "\n",
    "# print(chunks)\n",
    "list = []\n",
    "for chunk in chunks:\n",
    "    # print(chunk.shape)\n",
    "    list.append(torch.stack(torch.split(chunk.view(3,10),2,1),dim=0))\n",
    "\n",
    "# print(list[0])\n",
    "# print(list[1])\n",
    "# print(list[2])\n",
    "# print(list[0].shape)\n",
    "new = torch.cat(list,dim=0)\n",
    "# print(new.shape)\n",
    "# print(new)\n",
    "\n",
    "chunks = torch.split(new,1,0)\n",
    "# print(len(chunks))\n",
    "# print(chunks[0].shape)\n",
    "# print(chunks[5])\n",
    "list = []\n",
    "for chunk in chunks:\n",
    "    list.append(chunk.view(3,2))\n",
    "# print(len(list))\n",
    "# print(list[0].shape)\n",
    "# print(list[0])\n",
    "list1=[]\n",
    "for i in range(3):\n",
    "    list1.append(torch.cat(list[i*5:i*5+5],dim=1))\n",
    "# print(list1[0].shape)\n",
    "final = torch.stack(list1)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0000, 1.0000],\n",
      "          [2.0000, 3.0000],\n",
      "          [4.0000, 5.0000]],\n",
      "\n",
      "         [[6.0000, 7.0000],\n",
      "          [8.0000, 9.0000],\n",
      "          [0.0000, 1.0000]],\n",
      "\n",
      "         [[2.0000, 3.0000],\n",
      "          [4.0000, 5.0000],\n",
      "          [6.0000, 7.0000]]],\n",
      "\n",
      "\n",
      "        [[[8.0000, 9.0000],\n",
      "          [0.0000, 1.0000],\n",
      "          [2.0000, 3.0000]],\n",
      "\n",
      "         [[4.0000, 5.0000],\n",
      "          [6.0000, 7.0000],\n",
      "          [8.0000, 9.0000]],\n",
      "\n",
      "         [[0.1000, 1.1000],\n",
      "          [2.1000, 3.1000],\n",
      "          [4.1000, 5.1000]]],\n",
      "\n",
      "\n",
      "        [[[6.1000, 7.1000],\n",
      "          [8.1000, 9.1000],\n",
      "          [0.1000, 1.1000]],\n",
      "\n",
      "         [[2.1000, 3.1000],\n",
      "          [4.1000, 5.1000],\n",
      "          [6.1000, 7.1000]],\n",
      "\n",
      "         [[8.1000, 9.1000],\n",
      "          [0.1000, 1.1000],\n",
      "          [2.1000, 3.1000]]],\n",
      "\n",
      "\n",
      "        [[[4.1000, 5.1000],\n",
      "          [6.1000, 7.1000],\n",
      "          [8.1000, 9.1000]],\n",
      "\n",
      "         [[0.2000, 1.2000],\n",
      "          [2.2000, 3.2000],\n",
      "          [4.2000, 5.2000]],\n",
      "\n",
      "         [[6.2000, 7.2000],\n",
      "          [8.2000, 9.2000],\n",
      "          [0.2000, 1.2000]]],\n",
      "\n",
      "\n",
      "        [[[2.2000, 3.2000],\n",
      "          [4.2000, 5.2000],\n",
      "          [6.2000, 7.2000]],\n",
      "\n",
      "         [[8.2000, 9.2000],\n",
      "          [0.2000, 1.2000],\n",
      "          [2.2000, 3.2000]],\n",
      "\n",
      "         [[4.2000, 5.2000],\n",
      "          [6.2000, 7.2000],\n",
      "          [8.2000, 9.2000]]]])\n"
     ]
    }
   ],
   "source": [
    "b = torch.Tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
    "# Add 0.1 to the second row of each batch\n",
    "b[1, :, :] += 0.1\n",
    "b[2, :, :] += 0.2\n",
    "\n",
    "print(b.view(-1, 3, 3, 2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TorchScript time: 2.962586 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the function to be compiled with TorchScript\n",
    "@torch.jit.script\n",
    "def manipulate_tensor(b):\n",
    "\n",
    "    # Add 0.1 to the second row of each batch\n",
    "    b[:, 1, :] += 0.1\n",
    "\n",
    "    # Split tensor into chunks of size 1 along the first dimension\n",
    "    chunks = torch.split(b, 1, 0)\n",
    "\n",
    "    # Stack and reshape chunks into the desired format\n",
    "    list1 = [torch.stack(torch.split(chunk.view(3, 10), 2, 1), dim=0) for chunk in chunks]\n",
    "\n",
    "    # Concatenate the list into a single tensor\n",
    "    new = torch.cat(list1, dim=0)\n",
    "\n",
    "    # Split the concatenated tensor into chunks\n",
    "    batch_chunks = torch.split(new, 1, 0)\n",
    "\n",
    "    # Create the final list of stacked tensors\n",
    "    list2 = [torch.stack([batch_chunks[i*5 + j].view(3,2) for j in range(5)]) for i in range(2)]\n",
    "\n",
    "    # Concatenate the final list into a single tensor\n",
    "    final = torch.cat(list2, dim=0)\n",
    "    \n",
    "    return final\n",
    "b = torch.Tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                    [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]])\n",
    "\n",
    "# Call the compiled function\n",
    "final = manipulate_tensor(b)\n",
    "# Main loop with timing\n",
    "start_time = time.time()\n",
    "\n",
    "for _ in range(100000):\n",
    "    # Call the compiled function\n",
    "    final = manipulate_tensor(b)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"TorchScript time: {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 3, 2]\n",
      "tensor([[[[0.0000, 1.0000],\n",
      "          [0.0000, 1.0000],\n",
      "          [0.0000, 1.0000]]],\n",
      "\n",
      "\n",
      "        [[[2.0000, 3.0000],\n",
      "          [2.0000, 3.0000],\n",
      "          [2.0000, 3.0000]]],\n",
      "\n",
      "\n",
      "        [[[4.0000, 5.0000],\n",
      "          [4.0000, 5.0000],\n",
      "          [4.0000, 5.0000]]],\n",
      "\n",
      "\n",
      "        [[[6.0000, 7.0000],\n",
      "          [6.0000, 7.0000],\n",
      "          [6.0000, 7.0000]]],\n",
      "\n",
      "\n",
      "        [[[8.0000, 9.0000],\n",
      "          [8.0000, 9.0000],\n",
      "          [8.0000, 9.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.1000, 1.1000],\n",
      "          [0.1000, 1.1000],\n",
      "          [0.1000, 1.1000]]],\n",
      "\n",
      "\n",
      "        [[[2.1000, 3.1000],\n",
      "          [2.1000, 3.1000],\n",
      "          [2.1000, 3.1000]]],\n",
      "\n",
      "\n",
      "        [[[4.1000, 5.1000],\n",
      "          [4.1000, 5.1000],\n",
      "          [4.1000, 5.1000]]],\n",
      "\n",
      "\n",
      "        [[[6.1000, 7.1000],\n",
      "          [6.1000, 7.1000],\n",
      "          [6.1000, 7.1000]]],\n",
      "\n",
      "\n",
      "        [[[8.1000, 9.1000],\n",
      "          [8.1000, 9.1000],\n",
      "          [8.1000, 9.1000]]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Define the function to be compiled with TorchScript\n",
    "@torch.jit.script\n",
    "def manipulate_tensor(b):\n",
    "\n",
    "    # Add 0.1 to the second row of each batch\n",
    "    b[1, :, :] += 0.1\n",
    "\n",
    "    # print(b)\n",
    "    chunks = torch.split(b,1,0)\n",
    "    # print(chunks[0].view(3,10).shape)\n",
    "\n",
    "    # print(chunks)\n",
    "    list = []\n",
    "    for chunk in chunks:\n",
    "        # print(chunk.shape)\n",
    "        list.append(torch.stack(torch.split(chunk.view(3,10),2,1),dim=0))\n",
    "\n",
    "    # print(list)\n",
    "    # print(list[0].shape)\n",
    "    new = torch.cat(list,dim=0)\n",
    "    print(new.shape)\n",
    "    # print(new)\n",
    "\n",
    "    batch_chunks = torch.split(new,1,0)\n",
    "    # print(batch_chunks[0:1])\n",
    "    list = []\n",
    "    for i in range(2):\n",
    "        list.append(torch.stack(batch_chunks[i*5:i*5 + 5]))\n",
    "    # print(list)\n",
    "    final = torch.cat(list,dim=0)\n",
    "    \n",
    "    return final\n",
    "b = torch.Tensor([[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]],\n",
    "                    [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "                    [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]]).to('cuda')\n",
    "\n",
    "# Call the compiled function\n",
    "final = manipulate_tensor(b)\n",
    "print(final)\n",
    "# Main loop with timing\n",
    "# start_time = time.time()\n",
    "\n",
    "# for _ in range(100000):\n",
    "#     # Call the compiled function\n",
    "#     final = manipulate_tensor(b)\n",
    "\n",
    "# end_time = time.time()\n",
    "# print(f\"TorchScript time: {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, encoder, resnet):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.encoder = encoder  # Assuming encoder is a pre-trained model accepting (batch_size, 18, 60)\n",
    "        self.resnet = resnet    # CNN model that will process the encoded output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 18, 3600)\n",
    "        # Reshape x to (batch_size, 60, 18, 60) where each 18x60 block is 1 second of data\n",
    "        x = torch.split(x,60,1)\n",
    "\n",
    "        x = self.encoder(x)  # Expecting encoder output of shape (batch_size * 60, 15, 4)\n",
    "        \n",
    "        x = torch.cat(x,1)\n",
    "        \n",
    "\n",
    "        # Pass through ResNet or another CNN\n",
    "        x = self.resnet(x)  # Ensure that self.resnet is designed to take this shape\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
