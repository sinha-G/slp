{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Detecting Whether the Inputs are a Sheik </h1>\n",
    "\n",
    "We want to train a binary classifier to accurately predict whether a multi-channel time series (representing a Super Smash Bros. Melee player's inputs) was produced by a Sheik player. We first load our required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in c:\\users\\jaspa\\.conda\\envs\\slp\\lib\\site-packages (0.58.1)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\users\\jaspa\\.conda\\envs\\slp\\lib\\site-packages (from numba) (0.41.1)\n",
      "Requirement already satisfied: numpy<1.27,>=1.22 in c:\\users\\jaspa\\.conda\\envs\\slp\\lib\\site-packages (from numba) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install numba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import slippi as slp\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "from numba import jit, njit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preliminary Functions </h2>\n",
    "\n",
    "We use these functions to one-hot encode the button bitmask and get the frame data for a given port number and frames object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of time steps in the model inputs\n",
    "frames_per_input = 60 * 12     # 12 seconds of gameplay\n",
    "\n",
    "# @jit()\n",
    "def one_hot_encode(bitmask):\n",
    "    labels = ['DPAD_LEFT', 'DPAD_RIGHT', 'DPAD_DOWN', 'DPAD_UP', 'Z', 'R', 'L', 'A', 'B', 'X', 'Y', 'START']\n",
    "    encoded_values = [1, 2, 4, 8, 16, 32, 64, 256, 512, 1024, 2048, 4096]\n",
    "\n",
    "    # Create a dictionary mapping labels to their encoded values\n",
    "    label_to_value = dict(zip(labels, encoded_values))\n",
    "\n",
    "    # Initialize a list to store the one-hot encoded values\n",
    "    one_hot_encoded = [0] * len(labels)\n",
    "\n",
    "    # Iterate through labels and set the corresponding one-hot encoded value\n",
    "    for label, value in label_to_value.items():\n",
    "        if bitmask & value:\n",
    "            one_hot_encoded[labels.index(label)] = 1\n",
    "\n",
    "    return one_hot_encoded\n",
    "# @jit()\n",
    "def get_frame_data(frames, port):\n",
    "    sheik_inputs = np.empty((0, 18))  # Initialize an empty NumPy array\n",
    "\n",
    "    for i, frame in enumerate(frames[300: 300 + frames_per_input]):   # Take frames_per_input frames. skips first 5 seconds.\n",
    "        buttons = one_hot_encode(frame.ports[port].leader.pre.buttons.physical.value)\n",
    "        j_x = frame.ports[port].leader.pre.joystick.x\n",
    "        j_y = frame.ports[port].leader.pre.joystick.y\n",
    "        c_x = frame.ports[port].leader.pre.cstick.x\n",
    "        c_y = frame.ports[port].leader.pre.cstick.y\n",
    "        t_l = frame.ports[port].leader.pre.triggers.physical.l\n",
    "        t_r = frame.ports[port].leader.pre.triggers.physical.r\n",
    "\n",
    "        frame_data = np.array(buttons + [j_x, j_y, c_x, c_y, t_l, t_r]).reshape(1, -1)\n",
    "        sheik_inputs = np.vstack((sheik_inputs, frame_data))\n",
    "\n",
    "    return sheik_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data Loading </h2>\n",
    "\n",
    "We begin by iterating through the Slippi Public Dataset, extracting replays of Sheik-Fox games:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Using backend LokyBackend with 24 concurrent workers.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    0.4s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed:    1.0s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  97 tasks      | elapsed:    1.5s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 114 tasks      | elapsed:    1.7s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 133 tasks      | elapsed:    2.0s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 152 tasks      | elapsed:    2.2s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed:    2.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 194 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:    3.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 240 tasks      | elapsed:    3.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 265 tasks      | elapsed:    4.0s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 290 tasks      | elapsed:    4.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 317 tasks      | elapsed:    4.7s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 344 tasks      | elapsed:    5.1s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 373 tasks      | elapsed:    5.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 402 tasks      | elapsed:    6.0s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 433 tasks      | elapsed:    6.5s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 464 tasks      | elapsed:    7.1s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 497 tasks      | elapsed:    7.8s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 530 tasks      | elapsed:    8.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 565 tasks      | elapsed:    8.9s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 600 tasks      | elapsed:    9.7s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 637 tasks      | elapsed:   10.5s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 674 tasks      | elapsed:   11.2s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 713 tasks      | elapsed:   12.0s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 752 tasks      | elapsed:   12.8s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 793 tasks      | elapsed:   13.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 834 tasks      | elapsed:   14.4s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 877 tasks      | elapsed:   15.2s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 920 tasks      | elapsed:   15.8s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 965 tasks      | elapsed:   16.7s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1010 tasks      | elapsed:   17.5s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1057 tasks      | elapsed:   18.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1104 tasks      | elapsed:   18.9s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1153 tasks      | elapsed:   19.7s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1202 tasks      | elapsed:   20.4s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1253 tasks      | elapsed:   21.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1304 tasks      | elapsed:   22.0s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1357 tasks      | elapsed:   22.8s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1410 tasks      | elapsed:   23.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1465 tasks      | elapsed:   24.4s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1520 tasks      | elapsed:   25.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1577 tasks      | elapsed:   26.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1634 tasks      | elapsed:   27.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1693 tasks      | elapsed:   28.2s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1752 tasks      | elapsed:   29.2s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1813 tasks      | elapsed:   30.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1874 tasks      | elapsed:   31.3s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 1937 tasks      | elapsed:   32.4s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 2000 tasks      | elapsed:   33.5s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 2065 tasks      | elapsed:   34.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 2130 tasks      | elapsed:   35.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 2197 tasks      | elapsed:   36.6s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A[Parallel(n_jobs=-1)]: Done 2264 tasks      | elapsed:   38.0s\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████| 2362/2362 [00:38<00:00, 60.71it/s]\n",
      "[Parallel(n_jobs=-1)]: Done 2362 out of 2362 | elapsed:   40.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             TimeSeries  Label  \\\n",
      "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...      1   \n",
      "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "...                                                 ...    ...   \n",
      "4511  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "4512  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "4513  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "4514  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      1   \n",
      "4515  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      0   \n",
      "\n",
      "                                                  FName  \n",
      "0               02_29_27.272Z Sheik + [C2] Fox (YS).slp  \n",
      "1                         10_33_38 Sheik + Fox (DL).slp  \n",
      "2     01_01_39.822Z [EASY] Fox + [LUST] Sheik (FoD).slp  \n",
      "3                        10_37_27 Sheik + Fox (FoD).slp  \n",
      "4      01_04_11.432Z [EASY] Fox + [LUST] Sheik (PS).slp  \n",
      "...                                                 ...  \n",
      "4511  Sheik vs Fox [YS] Game_001AE988861E_20200307T1...  \n",
      "4512         Sheik vs Fox [YS] Game_20200307T173010.slp  \n",
      "4513         Sheik vs Fox [YS] Game_20200307T173010.slp  \n",
      "4514         Sheik vs Fox [YS] Game_20200304T220922.slp  \n",
      "4515         Sheik vs Fox [YS] Game_20200304T220922.slp  \n",
      "\n",
      "[4516 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import slp\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from multiprocessing import Manager\n",
    "\n",
    "# Function to process a single SLP file and append to shared lists\n",
    "def process_slp_file(slp_file, dataset_path, time_series_list, label_list, ids):\n",
    "    try:\n",
    "        file_path = os.path.join(dataset_path, slp_file)\n",
    "        game = slp.Game(file_path)\n",
    "        frames = game.frames\n",
    "\n",
    "        if len(frames) < 300 + frames_per_input:  # Ignore games that are <3600 frames (i.e. <60 seconds)\n",
    "            return\n",
    "\n",
    "        # List occupied ports\n",
    "        occupied_ports = [i for i, port in enumerate(game.start.players) if port is not None]\n",
    "        port_1 = occupied_ports[0]\n",
    "        port_2 = occupied_ports[1]\n",
    "\n",
    "        if len(occupied_ports) > 2:  # Ignore games that aren't singles\n",
    "            return\n",
    "\n",
    "        # Determine characters playing\n",
    "        port_1_character = game.start.players[port_1].character.name\n",
    "        port_2_character = game.start.players[port_2].character.name\n",
    "\n",
    "        frame_data = get_frame_data(frames, port_1)\n",
    "        time_series_list.append(frame_data)\n",
    "        label_list.append(1 if port_1_character == 'SHEIK' else 0)\n",
    "        ids.append(slp_file)\n",
    "        frame_data = get_frame_data(frames, port_2)\n",
    "        time_series_list.append(frame_data)\n",
    "        label_list.append(1 if port_2_character == 'SHEIK' else 0)\n",
    "        ids.append(slp_file)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {slp_file}: {str(e)}\")\n",
    "\n",
    "# Set your dataset_path and frames_per_input\n",
    "dataset_path = './Slippi_Public_Dataset_v3/'\n",
    "# frames_per_input = ...\n",
    "\n",
    "slp_files = [file for file in os.listdir(dataset_path) if file.endswith('.slp') and 'Sheik' in file and 'Fox' in file]\n",
    "print(len(slp_files))\n",
    "\n",
    "# Create shared lists to store results\n",
    "manager = Manager()\n",
    "time_series_list = manager.list()\n",
    "label_list = manager.list()\n",
    "ids = manager.list()\n",
    "\n",
    "# Use joblib to parallelize processing of SLP files\n",
    "Parallel(n_jobs=-1, verbose=10)(delayed(process_slp_file)(slp_file, dataset_path, time_series_list, label_list, ids) for slp_file in tqdm.tqdm(slp_files))\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "df = pd.DataFrame({\"TimeSeries\": list(time_series_list), \"Label\": list(label_list), \"FName\": list(ids)})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             TimeSeries  Label  \\\n",
      "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "1     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "2     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "3     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,...      1   \n",
      "4     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "...                                                 ...    ...   \n",
      "4511  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "4512  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "4513  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "4514  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      1   \n",
      "4515  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      0   \n",
      "\n",
      "                                                  FName  \n",
      "0               02_29_27.272Z Sheik + [C2] Fox (YS).slp  \n",
      "1                         10_33_38 Sheik + Fox (DL).slp  \n",
      "2     01_01_39.822Z [EASY] Fox + [LUST] Sheik (FoD).slp  \n",
      "3                        10_37_27 Sheik + Fox (FoD).slp  \n",
      "4      01_04_11.432Z [EASY] Fox + [LUST] Sheik (PS).slp  \n",
      "...                                                 ...  \n",
      "4511  Sheik vs Fox [YS] Game_001AE988861E_20200307T1...  \n",
      "4512         Sheik vs Fox [YS] Game_20200307T173010.slp  \n",
      "4513         Sheik vs Fox [YS] Game_20200307T173010.slp  \n",
      "4514         Sheik vs Fox [YS] Game_20200304T220922.slp  \n",
      "4515         Sheik vs Fox [YS] Game_20200304T220922.slp  \n",
      "\n",
      "[4516 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory usage of the DataFrame: 1103482 bytes\n"
     ]
    }
   ],
   "source": [
    "# Get memory usage for each column in bytes\n",
    "memory_usage = df.memory_usage(deep=True)\n",
    "\n",
    "# Sum the memory usage values to get the total memory usage of the DataFrame\n",
    "total_memory_usage = memory_usage.sum()\n",
    "\n",
    "print(f\"Total memory usage of the DataFrame: {total_memory_usage} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            TimeSeries  Label  \\\n",
      "0    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "1    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "2    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "3    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "4    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "..                                                 ...    ...   \n",
      "195  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "196  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      1   \n",
      "197  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "198  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...      0   \n",
      "199  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,...      1   \n",
      "\n",
      "                                                FName  \n",
      "0           00_37_01.564Z [314] Fox + Sheik (FoD).slp  \n",
      "1           00_37_01.564Z [314] Fox + Sheik (FoD).slp  \n",
      "2            00_40_07.217Z [314] Fox + Sheik (DL).slp  \n",
      "3            00_40_07.217Z [314] Fox + Sheik (DL).slp  \n",
      "4    00_45_18.826Z [NELL] Fox + [LUST] Sheik (BF).slp  \n",
      "..                                                ...  \n",
      "195                     12_56_25 Sheik + Fox (FD).slp  \n",
      "196                     12_56_34 Sheik + Fox (PS).slp  \n",
      "197                     12_56_34 Sheik + Fox (PS).slp  \n",
      "198                    12_56_38 Fox + Sheik (FoD).slp  \n",
      "199                    12_56_38 Fox + Sheik (FoD).slp  \n",
      "\n",
      "[200 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './Slippi_Public_Dataset_v3/'\n",
    "\n",
    "# List files in the dataset with Sheik\n",
    "slp_files = [file for file in os.listdir(dataset_path) if file.endswith('.slp') and 'Sheik' in file and 'Fox' in file][:100]\n",
    "print(len(slp_files))\n",
    "\n",
    "time_series_list =[]\n",
    "label_list = []\n",
    "ids = []\n",
    "\n",
    "# Load the .slp files\n",
    "for i, slp_file in enumerate(tqdm.tqdm(slp_files)):\n",
    "    \n",
    "    # Get file path and store game variable\n",
    "    file_path = os.path.join(dataset_path, slp_file)\n",
    "    game = slp.Game(file_path)\n",
    "    frames = game.frames\n",
    "\n",
    "    if len(frames) < 300 + frames_per_input:          # Ignore games that are <3600 frames (i.e. <60 seconds)\n",
    "        continue\n",
    "    \n",
    "    # List occupied ports\n",
    "    occupied_ports = [i for i, port in enumerate(game.start.players) if port is not None]\n",
    "    port_1 = occupied_ports[0]\n",
    "    port_2 = occupied_ports[1]    \n",
    "\n",
    "    if (len(occupied_ports)) > 2:   # Ignore games that aren't singles\n",
    "            continue\n",
    "\n",
    "    # Determine characters playing\n",
    "    port_1_character = game.start.players[port_1].character.name\n",
    "    port_2_character = game.start.players[port_2].character.name\n",
    "\n",
    "    frame_data = get_frame_data(frames, port_1)\n",
    "    time_series_list.append(frame_data)\n",
    "    label_list.append(1 if port_1_character == 'SHEIK' else 0)\n",
    "    ids.append(slp_file)\n",
    "    frame_data = get_frame_data(frames, port_2)\n",
    "    time_series_list.append(frame_data)\n",
    "    label_list.append(1 if port_2_character == 'SHEIK' else 0)\n",
    "    ids.append(slp_file)\n",
    "    \n",
    "df = pd.DataFrame({\"TimeSeries\": time_series_list, \"Label\": label_list, \"FName\": ids})\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting feather-format\n",
      "  Downloading feather-format-0.4.1.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pyarrow>=0.4.0 in c:\\users\\jaspa\\.conda\\envs\\slp\\lib\\site-packages (from feather-format) (11.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\jaspa\\.conda\\envs\\slp\\lib\\site-packages (from pyarrow>=0.4.0->feather-format) (1.26.3)\n",
      "Building wheels for collected packages: feather-format\n",
      "  Building wheel for feather-format (setup.py): started\n",
      "  Building wheel for feather-format (setup.py): finished with status 'done'\n",
      "  Created wheel for feather-format: filename=feather_format-0.4.1-py3-none-any.whl size=2453 sha256=f4d3de5a42b814a1ef4c33b0019258f785fe91744d4607b1a2b646679e4ed932\n",
      "  Stored in directory: c:\\users\\jaspa\\appdata\\local\\pip\\cache\\wheels\\77\\5b\\0e\\0e63d10b6353208a085a321ea2eed2578f220a77bb8a4bd7ab\n",
      "Successfully built feather-format\n",
      "Installing collected packages: feather-format\n",
      "Successfully installed feather-format-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install feather-format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the file path where you want to save the pickle file\n",
    "pickle_file_path = 'example.pkl'\n",
    "\n",
    "# Save the DataFrame as a pickle file\n",
    "df.to_pickle(pickle_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Visualization </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2362 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import slp\n",
    "# import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "# Function to process each slp file\n",
    "def process_slp_file(slp_file):\n",
    "    file_path = os.path.join(dataset_path, slp_file)\n",
    "    game = slp.Game(file_path)\n",
    "    frames = game.frames\n",
    "\n",
    "    if len(frames) < 300 + frames_per_input:          # Ignore games that are <3600 frames (i.e. <60 seconds)\n",
    "        print(f\"Ignoring {slp_file} - Game length is less than required.\")\n",
    "        return None\n",
    "    \n",
    "    # List occupied ports\n",
    "    occupied_ports = [i for i, port in enumerate(game.start.players) if port is not None]\n",
    "    port_1 = occupied_ports[0]\n",
    "    port_2 = occupied_ports[1]    \n",
    "\n",
    "    if len(occupied_ports) > 2:   # Ignore games that aren't singles\n",
    "        print(f\"Ignoring {slp_file} - Not a singles game.\")\n",
    "        return None\n",
    "\n",
    "    # Determine characters playing\n",
    "    port_1_character = game.start.players[port_1].character.name\n",
    "    port_2_character = game.start.players[port_2].character.name\n",
    "\n",
    "    frame_data1 = get_frame_data(frames, port_1)\n",
    "    frame_data2 = get_frame_data(frames, port_2)\n",
    "\n",
    "    print(f\"Processed {slp_file}\")\n",
    "    return frame_data1, port_1_character, frame_data2, port_2_character, slp_file\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset_path = './Slippi_Public_Dataset_v3/'\n",
    "    frames_per_input = 300  # You'll need to define this variable\n",
    "\n",
    "    slp_files = [file for file in os.listdir(dataset_path) if file.endswith('.slp') and 'Sheik' in file and 'Fox' in file]\n",
    "    print(f\"Total files to process: {len(slp_files)}\")\n",
    "\n",
    "    time_series_list = []\n",
    "    label_list = []\n",
    "    ids = []\n",
    "\n",
    "    # Create a pool of worker processes\n",
    "    pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "\n",
    "    # Process slp files in parallel\n",
    "    results = pool.map(process_slp_file, slp_files)\n",
    "\n",
    "    # Close the pool of worker processes\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    # Filter out the None values from the results and extract the data\n",
    "    results = [result for result in results if result is not None]\n",
    "    for frame_data1, port_1_character, frame_data2, port_2_character, slp_file in results:\n",
    "        time_series_list.append(frame_data1)\n",
    "        label_list.append(1 if port_1_character == 'SHEIK' else 0)\n",
    "        ids.append(slp_file)\n",
    "        time_series_list.append(frame_data2)\n",
    "        label_list.append(1 if port_2_character == 'SHEIK' else 0)\n",
    "        ids.append(slp_file)\n",
    "\n",
    "    df = pd.DataFrame({\"TimeSeries\": time_series_list, \"Label\": label_list, \"FName\": ids})\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = df[df.duplicated(subset = 'TimeSeries', keep = False)]\n",
    "\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Preprocessing </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "time_series_tensor = torch.tensor(np.array(time_series_list), dtype=torch.float32)\n",
    "label_tensor = torch.tensor(label_list, dtype=torch.float32)\n",
    "\n",
    "channels = 18\n",
    "\n",
    "# Normalize each channel individually\n",
    "scaler = StandardScaler()\n",
    "time_series_normalized = torch.zeros(time_series_tensor.shape)\n",
    "\n",
    "# Iterate over channels\n",
    "# for i in range(channels):\n",
    "#     time_series_normalized[:, :, i] = torch.tensor(scaler.fit_transform(time_series_tensor[:, :, i]))\n",
    "\n",
    "# print(time_series_sensor.shape)\n",
    "# print(time_series_normalized.shape)\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(time_series_normalized, label_tensor, test_size = 0.2, shuffle = True, stratify = label_tensor)\n",
    "\n",
    "print(torch.isnan(time_series_normalized).any())\n",
    "print(torch.isnan(label_tensor).any())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
